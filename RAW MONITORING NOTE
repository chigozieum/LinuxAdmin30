Process Breakdown
PID	Command	Description
1	systemd	Init system (first process); manages services, sockets, targets.
14	rcu_sched	Kernel task for synchronizing access to shared data in multicore systems.
1292	loki-linux-amd6	Grafana Loki agent for log collection (Promtail or Loki binary).
374628	grafana	The Grafana dashboarding system for metrics/logs.
374762	systemd-journal	Journal service for logs (journalctl).
387119	fail2ban-server	Blocks IPs after failed SSH or service login attempts.
388362	kworker/u6:*	Kernel threads for async I/O, memory flush, USB, etc.
389282	dockerd	Docker daemon, manages containers.
389306	pidstat	Monitoring tool itself (running while you were collecting stats).

üîß How to Inspect / Manage / Troubleshoot Each
üîπ 1. systemd (PID 1)
View all services managed by systemd:

bash
Copy
Edit
systemctl list-units --type=service
Check status of a specific service (e.g. Docker):

bash
Copy
Edit
systemctl status docker
Journal logs for systemd-managed services:

bash
Copy
Edit
journalctl -xe
üîπ 2. Grafana (grafana)
Check if Grafana is running:

bash
Copy
Edit
systemctl status grafana-server
View Grafana logs:

bash
Copy
Edit
journalctl -u grafana-server -f
Access in browser:

text
Copy
Edit
http://<your-ip>:3000
üîπ 3. Loki (loki-linux-amd6)
Likely a self-hosted Loki binary or Promtail agent.

Find where it's running from:

bash
Copy
Edit
ps -aux | grep loki
If installed via systemd, check:

bash
Copy
Edit
systemctl status loki
Inspect config:

bash
Copy
Edit
cat /etc/loki/config.yaml
Check Loki logs:

bash
Copy
Edit
journalctl -u loki -f
üîπ 4. Fail2Ban
Show banned IPs:

bash
Copy
Edit
fail2ban-client status sshd
Unban an IP (example):

bash
Copy
Edit
fail2ban-client set sshd unbanip 192.168.1.10
Check logs:

bash
Copy
Edit
cat /var/log/fail2ban.log
üîπ 5. Docker (dockerd)
List containers:

bash
Copy
Edit
docker ps -a
Check logs of a container:

bash
Copy
Edit
docker logs <container_id_or_name>
Inspect high CPU usage in containers:

bash
Copy
Edit
docker stats
Restart Docker if needed:

bash
Copy
Edit
systemctl restart docker
üîπ 6. Kworker / Kernel Threads
These are not user-space, so you can't ‚Äúmanage‚Äù them per se ‚Äî but you can:

Diagnose I/O or block issues:

bash
Copy
Edit
iotop
iostat -xz 1
Inspect disk utilization:

bash
Copy
Edit
df -h
du -sh /*
üîπ 7. System Logs
View full system logs (all services):

bash
Copy
Edit
journalctl -xe
üõ†Ô∏è Summary of Tools to Use for Troubleshooting
Tool	Purpose
systemctl	Manage and view services
journalctl	View logs from services
docker	Manage containers
fail2ban-client	Control brute force defense
htop / pidstat	Real-time CPU/memory usage
`ps aux	grep`
netstat -tulpn or ss -tulpn	Port/service mapping
iotop, iostat, dstat	Disk/IO debugging

Would you like a single Bash script that gives you a full CPU, memory, disk, network, Docker, Grafana, Loki, and Fail2Ban snapshot all at once for auditing?







You said:
yes okease and more 


ChatGPT said:
Absolutely! Here's a powerful, all-in-one Linux audit and troubleshooting Bash script for a server running:

Docker

Grafana

Loki

Fail2Ban

Heavier systemd services

CPU/memory/disk/IO/network metrics

‚úÖ Full Linux Engineering Diagnostic Script (system_audit.sh)
bash
Copy
Edit
#!/bin/bash
# Filename: system_audit.sh
# Description: Enterprise-grade diagnostic script for Linux server audit (Grafana, Docker, Loki, Fail2Ban, CPU, Mem, IO, Network)

echo "============================================"
echo "üìÖ Hostname: $(hostname)"
echo "üìç IP Address: $(hostname -I | awk '{print $1}')"
echo "üïí Date: $(date)"
echo "üñ•Ô∏è Uptime: $(uptime -p)"
echo "============================================"

echo -e "\nüîß Kernel & OS Info"
uname -a
lsb_release -a 2>/dev/null || cat /etc/os-release

echo -e "\nüß† Memory Usage:"
free -h

echo -e "\nüî• Top 10 CPU-consuming Processes:"
ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head -n 11

echo -e "\nüì¶ Disk Usage (Human Readable):"
df -hT

echo -e "\nüìÇ Largest Directories (top 10 in /):"
du -h --max-depth=1 / 2>/dev/null | sort -hr | head -n 10

echo -e "\nüß† Virtual Memory + Swap Activity:"
vmstat 1 3

echo -e "\nüîÑ I/O Stats (iostat):"
iostat -xz 1 3

echo -e "\nüåê Listening Ports:"
ss -tulpn | grep LISTEN

echo -e "\nüåê Outbound Connections (top talkers):"
netstat -ant | grep ESTABLISHED | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head -n 10

echo -e "\nüìã Recent Login Activity:"
last -a | head -n 10

echo -e "\nüìã Active Users:"
w

echo -e "\nüì¶ Docker Status:"
systemctl status docker --no-pager
echo -e "\nüì¶ Running Containers:"
docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"

echo -e "\nüìä Grafana Status:"
systemctl status grafana-server --no-pager

echo -e "\nüìÑ Grafana Logs (last 20 lines):"
journalctl -u grafana-server -n 20 --no-pager

echo -e "\nüìÅ Loki Service Status (if present):"
ps aux | grep -i loki | grep -v grep

echo -e "\nüõ°Ô∏è Fail2Ban Status:"
fail2ban-client status

echo -e "\nüö´ Fail2Ban Banned IPs for sshd:"
fail2ban-client status sshd 2>/dev/null | grep 'Banned IP list'

echo -e "\nüóÑÔ∏è Top 5 Log Files by Size (/var/log):"
find /var/log -type f -exec du -Sh {} + | sort -rh | head -n 5

echo -e "\nüìã Top 10 Running Services by Memory Usage:"
ps -eo pid,cmd,%mem,%cpu --sort=-%mem | head -n 11

echo -e "\n‚úÖ Audit Complete. Suggested follow-up: htop, journalctl, docker logs <container>, fail2ban-client, and grafana dashboards."
üìå To Use:
Save as system_audit.sh

Make executable:

bash
Copy
Edit
chmod +x system_audit.sh
Run as root or with sudo:

bash
Copy
Edit
sudo ./system_audit.sh
üì¶ Optional Enhancements
Output to file: sudo ./system_audit.sh | tee audit-$(date +%F).log

Run automatically via cron or systemd timer

Extend to email output or send to Discord/Slack

Would you like a version that includes remediation commands (e.g., ‚Äúrestart if crashed,‚Äù ‚Äúpurge logs >1GB,‚Äù ‚Äúban IPs doing brute force‚Äù), or one that outputs a markdown-formatted audit report for GitHub issues?







You said:

root@racknerd-896d790:~# ./system_audit.sh
============================================
üìÖ Hostname: racknerd-896d790
üìç IP Address: 107.172.80.41
üïí Date: Thu May  8 08:38:43 PM UTC 2025
üñ•Ô∏è Uptime: up 2 weeks, 6 days, 19 hours, 37 minutes
============================================

üîß Kernel & OS Info
Linux racknerd-896d790 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Distributor ID: Ubuntu
Description:    Ubuntu 22.04.5 LTS
Release:        22.04
Codename:       jammy

üß† Memory Usage:
               total        used        free      shared  buff/cache   available
Mem:           3.8Gi       500Mi       126Mi        13Mi       3.2Gi       3.0Gi
Swap:          2.0Gi        21Mi       2.0Gi

üî• Top 10 CPU-consuming Processes:
    PID    PPID CMD                         %MEM %CPU
 389495       1 /usr/bin/dockerd -H fd:// -  1.5  3.0
 249392  249391 dockerd                      1.0  2.4
 374628       1 /usr/share/grafana/bin/graf  4.3  0.6
   1292       1 /opt/loki/loki-linux-amd64   0.9  0.5
 374762       1 /lib/systemd/systemd-journa  2.9  0.2
      1       0 /lib/systemd/systemd --syst  0.3  0.0
      2       0 [kthreadd]                   0.0  0.0
      3       2 [rcu_gp]                     0.0  0.0
      4       2 [rcu_par_gp]                 0.0  0.0
      5       2 [slub_flushwq]               0.0  0.0

üì¶ Disk Usage (Human Readable):
Filesystem     Type   Size  Used Avail Use% Mounted on
tmpfs          tmpfs  392M  1.3M  390M   1% /run
/dev/vda2      ext4    48G   44G  1.2G  98% /
tmpfs          tmpfs  2.0G  112K  2.0G   1% /dev/shm
tmpfs          tmpfs  5.0M     0  5.0M   0% /run/lock
tmpfs          tmpfs  392M  4.0K  392M   1% /run/user/0

üìÇ Largest Directories (top 10 in /):
46G     /
30G     /root
7.3G    /var
6.4G    /usr
1.4G    /snap
363M    /boot
84M     /opt
11M     /tmp
7.9M    /etc
1.3M    /run

üß† Virtual Memory + Swap Activity:
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0  22404 1085532 259456 2153756    0    0     2    24    3    5  0  0 99  0  0
 0  0  22404 1085280 259468 2153384    0    0     0  5956 2629 3982  1  2 96  1  0
 0  0  22404 1085280 259468 2153492    0    0    96     0 2271 3265  2  2 96  0  0

üîÑ I/O Stats (iostat):
Linux 5.15.0-130-generic (racknerd-896d790)     05/08/2025      _x86_64_        (3 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.30    0.01    0.34    0.11    0.04   99.21

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
loop0            0.00      0.00     0.00   0.00    1.39     5.09    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop1            0.00      0.00     0.00   0.00    8.10     5.36    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop2            0.00      0.00     0.00   0.00    8.51    15.72    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop3            0.00      0.00     0.00   0.00    7.78    15.31    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop4            0.00      0.00     0.00   0.00    0.97     3.22    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop5            0.00      0.03     0.00   0.00    4.32    38.57    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop6            0.00      0.04     0.00   0.00  175.77    37.52    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.02
loop7            0.00      0.00     0.00   0.00    0.00     1.27    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
sr0              0.00      0.00     0.00   0.00   11.60     0.20    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
vda              0.14      5.70     0.03  15.81    9.52    39.85   11.12     73.25     1.86  14.34   10.81     6.59    0.00      0.00     0.00   0.00    0.00     0.00    0.47    1.63    0.12   0.39


avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.02    0.00    2.37    0.00    0.00   96.61

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util


avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.69    0.00    2.03    0.00    0.00   96.28

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
vda              0.00      0.00     0.00   0.00    0.00     0.00    4.00     28.00     1.00  20.00    2.50     7.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.01   0.40



üåê Listening Ports:
tcp   LISTEN 0      244        127.0.0.1:5432      0.0.0.0:*    users:(("postgres",pid=387093,fd=5))                                            
tcp   LISTEN 0      4096   127.0.0.53%lo:53        0.0.0.0:*    users:(("systemd-resolve",pid=374759,fd=14))                                    
tcp   LISTEN 0      110        127.0.0.1:3306      0.0.0.0:*    users:(("mariadbd",pid=387088,fd=27))                                           
tcp   LISTEN 0      511          0.0.0.0:90        0.0.0.0:*    users:(("nginx",pid=387019,fd=7),("nginx",pid=387018,fd=7),("nginx",pid=387016,fd=7),("nginx",pid=387015,fd=7))
tcp   LISTEN 0      511          0.0.0.0:80        0.0.0.0:*    users:(("nginx",pid=387019,fd=6),("nginx",pid=387018,fd=6),("nginx",pid=387016,fd=6),("nginx",pid=387015,fd=6))
tcp   LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=386986,fd=3))                                                
tcp   LISTEN 0      4096               *:3100            *:*    users:(("loki-linux-amd6",pid=1292,fd=8))                                       
tcp   LISTEN 0      128             [::]:22           [::]:*    users:(("sshd",pid=386986,fd=4))                                                
tcp   LISTEN 0      4096               *:3000            *:*    users:(("grafana",pid=374628,fd=14))                                            
tcp   LISTEN 0      4096               *:9096            *:*    users:(("loki-linux-amd6",pid=1292,fd=9))                                       
tcp   LISTEN 0      4096               *:9100            *:*    users:(("node_exporter",pid=245646,fd=3))                                       

üåê Outbound Connections (top talkers):
      2 127.0.0.1
      1 98.198.245.157

üìã Recent Login Activity:
root     pts/5        Thu May  8 19:58   still logged in    98.198.245.157
root     pts/4        Wed May  7 20:47   still logged in    tmux(249664).%1
root     pts/2        Wed May  7 20:41   still logged in    tmux(249664).%0
root     pts/0        Wed May  7 16:56 - 03:56  (10:59)     98.177.160.217
reboot   system boot  Fri Apr 18 01:01   still running      5.15.0-130-generic
reboot   system boot  Sun Apr  6 09:58   still running      5.15.0-130-generic
reboot   system boot  Tue Mar 18 10:18   still running      5.15.0-130-generic
reboot   system boot  Sat Mar 15 04:06   still running      5.15.0-130-generic
reboot   system boot  Fri Mar 14 15:16   still running      5.15.0-130-generic
reboot   system boot  Sun Mar  9 02:51   still running      5.15.0-130-generic

üìã Active Users:
 20:39:01 up 20 days, 19:37,  4 users,  load average: 0.36, 0.21, 0.15
USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT
root     pts/1    98.177.160.217   Wed20    0.00s  0.00s  0.01s sudo dockerd
root     pts/2    tmux(249664).%0  Wed20   23:56m  0.02s  0.02s -bash
root     pts/4    tmux(249664).%1  Wed20   20:28m  0.15s  0.00s bash
root     pts/5    98.198.245.157   19:58   21.00s  0.09s  0.00s w

üì¶ Docker Status:
‚óè docker.service - Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
     Active: activating (start) since Thu 2025-05-08 20:38:56 UTC; 5s ago
TriggeredBy: ‚óè docker.socket
       Docs: https://docs.docker.com
   Main PID: 389564 (dockerd)
      Tasks: 9
     Memory: 25.4M
        CPU: 333ms
     CGroup: /system.slice/docker.service
             ‚îî‚îÄ389564 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

May 08 20:38:56 racknerd-896d790 systemd[1]: Starting Docker Application Container Engine...
May 08 20:38:56 racknerd-896d790 dockerd[389564]: time="2025-05-08T20:38:56.152832757Z" level=info msg="Starting up"
May 08 20:38:56 racknerd-896d790 dockerd[389564]: time="2025-05-08T20:38:56.154506748Z" level=info msg="OTEL tracing is not configured‚Ä¶provider"
May 08 20:38:56 racknerd-896d790 dockerd[389564]: time="2025-05-08T20:38:56.189035146Z" level=info msg="Creating a containerd client" ‚Ä¶eout=1m0s
Hint: Some lines were ellipsized, use -l to show in full.

üì¶ Running Containers:
^C
üìä Grafana Status:
‚óè grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendor preset: enabled)
     Active: active (running) since Thu 2025-05-08 20:00:25 UTC; 44min ago
       Docs: http://docs.grafana.org
   Main PID: 374628 (grafana)
      Tasks: 20 (limit: 4563)
     Memory: 84.5M
        CPU: 15.666s
     CGroup: /system.slice/grafana-server.service
             ‚îî‚îÄ374628 /usr/share/grafana/bin/grafana server --config=/etc/grafana/grafana.ini --pidfile=/run/grafana/grafana-server.pid --packa‚Ä¶

May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:10:28.448917888Z level=info msg="Updat‚Ä¶.100591ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:20:28.202658295Z level=info msg="Completed cleanup jo‚Ä¶.148527ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:20:28.446094998Z level=info msg="Updat‚Ä¶.723357ms
May 08 20:27:26 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:27:26.738345625Z level=info m‚Ä¶ce=server
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:30:28.202197032Z level=info msg="Completed cleanup jo‚Ä¶.131177ms
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:30:28.451723802Z level=info msg="Updat‚Ä¶.587729ms
May 08 20:31:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:31:25.218554036Z level=info msg="Usage stats‚Ä¶o report"
May 08 20:36:37 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:36:37.008384332Z level=info ‚Ä¶rce=server
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:40:28.202972754Z level=info msg="Completed cleanup jo‚Ä¶.136175ms
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:40:28.453264228Z level=info msg="Updat‚Ä¶.480374ms
Hint: Some lines were ellipsized, use -l to show in full.

üìÑ Grafana Logs (last 20 lines):
May 08 20:00:29 racknerd-896d790 grafana[374628]: logger=installer.fs t=2025-05-08T20:00:29.952004851Z level=info msg="Downloaded and extracted grafana-pyroscope-app v1.3.0 zip successfully to /var/lib/grafana/plugins/grafana-pyroscope-app"
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugins.registration t=2025-05-08T20:00:30.065937311Z level=info msg="Plugin registered" pluginId=grafana-pyroscope-app
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.066064748Z level=info msg="Plugin successfully installed" pluginId=grafana-pyroscope-app version= duration=346.443817ms
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.066292872Z level=info msg="Installing plugin" pluginId=grafana-exploretraces-app version=
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.installer t=2025-05-08T20:00:30.284847603Z level=info msg="Installing plugin" pluginId=grafana-exploretraces-app version=
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=installer.fs t=2025-05-08T20:00:30.402499883Z level=info msg="Downloaded and extracted grafana-exploretraces-app v1.0.0 zip successfully to /var/lib/grafana/plugins/grafana-exploretraces-app"
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugins.registration t=2025-05-08T20:00:30.528372768Z level=info msg="Plugin registered" pluginId=grafana-exploretraces-app
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.528473179Z level=info msg="Plugin successfully installed" pluginId=grafana-exploretraces-app version= duration=461.977738ms
May 08 20:01:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:01:25.206035169Z level=info msg="Usage stats are ready to report"
May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:10:28.213665639Z level=info msg="Completed cleanup jobs" duration=18.914496ms
May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:10:28.448917888Z level=info msg="Update check succeeded" duration=87.100591ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:20:28.202658295Z level=info msg="Completed cleanup jobs" duration=8.148527ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:20:28.446094998Z level=info msg="Update check succeeded" duration=84.723357ms
May 08 20:27:26 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:27:26.738345625Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=87.236.176.75 time_ms=1 duration=1.492177ms size=29 referer= handler=/ status_source=server
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:30:28.202197032Z level=info msg="Completed cleanup jobs" duration=7.131177ms
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:30:28.451723802Z level=info msg="Update check succeeded" duration=90.587729ms
May 08 20:31:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:31:25.218554036Z level=info msg="Usage stats are ready to report"
May 08 20:36:37 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:36:37.008384332Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=146.190.136.135 time_ms=0 duration=579.686¬µs size=29 referer= handler=/ status_source=server
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:40:28.202972754Z level=info msg="Completed cleanup jobs" duration=8.136175ms
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:40:28.453264228Z level=info msg="Update check succeeded" duration=91.480374ms

üìÅ Loki Service Status (if present):
root        1292  0.5  0.9 1294940 36516 ?       Ssl  Apr18 154:29 /opt/loki/loki-linux-amd64 -config.file=/opt/loki/loki-local-config.yaml

üõ°Ô∏è Fail2Ban Status:
Status
|- Number of jail:      1
- Jail list:   sshd

üö´ Fail2Ban Banned IPs for sshd:
   - Banned IP list:   59.1.245.186 218.92.0.149 88.214.50.40

üóÑÔ∏è Top 5 Log Files by Size (/var/log):
883M    /var/log/syslog.1
628M    /var/log/syslog
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system.journal
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system@ef23549089974bf09e67a7b8e45c3fd8-000000000008d4d4-0006346de8b1d743.journal
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system@ef23549089974bf09e67a7b8e45c3fd8-0000000000069fc8-00063469e8ee67b8.journal

üìã Top 10 Running Services by Memory Usage:
    PID CMD                         %MEM %CPU
 374628 /usr/share/grafana/bin/graf  4.3  0.5
 374762 /lib/systemd/systemd-journa  3.0  0.2
 387088 /usr/sbin/mariadbd           1.8  0.0
 389862 /usr/bin/dockerd -H fd:// -  1.6  3.1
 374391 /usr/libexec/fwupd/fwupd     1.5  0.0
   1292 /opt/loki/loki-linux-amd64   0.9  0.5
 249392 dockerd                      0.8  2.4
 387093 /usr/lib/postgresql/14/bin/  0.6  0.0
 386971 /sbin/multipathd -d -s       0.6  0.0
 387119 /usr/bin/python3 /usr/bin/f  0.5  0.0

‚úÖ Audit Complete. Suggested follow-up: htop, journalctl, docker logs <container>, fail2ban-client, and grafana dashboards.
root@racknerd-896d790:~# systemctl status docker --no-pager
‚óè docker.service - Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
     Active: activating (start) since Thu 2025-05-08 20:45:13 UTC; 16s ago
TriggeredBy: ‚óè docker.socket
       Docs: https://docs.docker.com
   Main PID: 389938 (dockerd)
      Tasks: 9
     Memory: 17.8M
        CPU: 569ms
     CGroup: /system.slice/docker.service
             ‚îî‚îÄ389938 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

May 08 20:45:13 racknerd-896d790 systemd[1]: Starting Docker Application Container Engine...
May 08 20:45:13 racknerd-896d790 dockerd[389938]: time="2025-05-08T20:45:13.936414285Z" level=info msg="Starting up"
May 08 20:45:13 racknerd-896d790 dockerd[389938]: time="2025-05-08T20:45:13.937831679Z" level=info msg="OTEL tracing is not configured‚Ä¶provider"
May 08 20:45:13 racknerd-896d790 dockerd[389938]: time="2025-05-08T20:45:13.963009432Z" level=info msg="Creating a containerd client" ‚Ä¶eout=1m0s
Hint: Some lines were ellipsized, use -l to show in full.
root@racknerd-896d790:~# docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
Command 'podman' not found, but can be installed with:
apt install podman
root@racknerd-896d790:~# sudo apt install podman
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed:
  buildah catatonit conmon containernetworking-plugins crun dns-root-data dnsmasq-base fuse-overlayfs glib-networking glib-networking-common
  glib-networking-services golang-github-containernetworking-plugin-dnsname golang-github-containers-common golang-github-containers-image
  libavahi-glib1 libostree-1-1 libsoup2.4-1 libsoup2.4-common libyajl2 uidmap
Suggested packages:
  containers-storage docker-compose
The following NEW packages will be installed:
  buildah catatonit conmon containernetworking-plugins crun dns-root-data dnsmasq-base fuse-overlayfs glib-networking glib-networking-common
  glib-networking-services golang-github-containernetworking-plugin-dnsname golang-github-containers-common golang-github-containers-image
  libavahi-glib1 libostree-1-1 libsoup2.4-1 libsoup2.4-common libyajl2 podman uidmap
0 upgraded, 21 newly installed, 0 to remove and 0 not upgraded.
Need to get 26.5 MB of archives.
After this operation, 112 MB of additional disk space will be used.
Do you want to continue? [Y/n] y
Get:1 http://us.archive.ubuntu.com/ubuntu jammy-updates/universe amd64 uidmap amd64 1:4.8.1-2ubuntu2.2 [22.4 kB]
Get:2 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 golang-github-containers-image all 5.16.0-3 [29.3 kB]
Get:3 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 golang-github-containers-common all 0.44.4+ds1-1 [28.1 kB]
Get:4 http://us.archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]
Get:5 http://us.archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]
Get:6 http://us.archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]
Get:7 http://us.archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]
Get:8 http://us.archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.4 [4,658 B]
Get:9 http://us.archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.4 [287 kB]
Get:10 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 libostree-1-1 amd64 2022.2-3 [333 kB]
Get:11 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 buildah amd64 1.23.1+ds1-2 [6,094 kB]
Get:12 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 catatonit amd64 0.1.7-1 [307 kB]
Get:13 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 conmon amd64 2.0.25+ds1-1.1 [35.1 kB]
Get:14 http://us.archive.ubuntu.com/ubuntu jammy-updates/universe amd64 containernetworking-plugins amd64 0.9.1+ds1-1ubuntu0.1 [6,806 kB]
Get:15 http://us.archive.ubuntu.com/ubuntu jammy-updates/main amd64 libyajl2 amd64 2.1.0-3ubuntu0.22.04.1 [21.0 kB]
Get:16 http://us.archive.ubuntu.com/ubuntu jammy-updates/universe amd64 crun amd64 0.17+dfsg-1.1ubuntu0.1 [299 kB]
Get:17 http://us.archive.ubuntu.com/ubuntu jammy-updates/main amd64 dns-root-data all 2024071801~ubuntu0.22.04.1 [6,132 B]
Get:18 http://us.archive.ubuntu.com/ubuntu jammy-updates/main amd64 dnsmasq-base amd64 2.90-0ubuntu0.22.04.1 [374 kB]
Get:19 http://us.archive.ubuntu.com/ubuntu jammy/universe amd64 fuse-overlayfs amd64 1.7.1-1 [44.7 kB]
Get:20 http://us.archive.ubuntu.com/ubuntu jammy-updates/universe amd64 golang-github-containernetworking-plugin-dnsname amd64 1.3.1+ds1-2ubuntu0.22.04.1 [1,127 kB]
Get:21 http://us.archive.ubuntu.com/ubuntu jammy-updates/universe amd64 podman amd64 3.4.4+ds1-1ubuntu1.22.04.3 [10.6 MB]
Fetched 26.5 MB in 1s (42.8 MB/s)
Selecting previously unselected package uidmap.
(Reading database ... 223360 files and directories currently installed.)
Preparing to unpack .../00-uidmap_1%3a4.8.1-2ubuntu2.2_amd64.deb ...
Unpacking uidmap (1:4.8.1-2ubuntu2.2) ...
Selecting previously unselected package golang-github-containers-image.
Preparing to unpack .../01-golang-github-containers-image_5.16.0-3_all.deb ...
Unpacking golang-github-containers-image (5.16.0-3) ...
Selecting previously unselected package golang-github-containers-common.
Preparing to unpack .../02-golang-github-containers-common_0.44.4+ds1-1_all.deb ...
Unpacking golang-github-containers-common (0.44.4+ds1-1) ...
Selecting previously unselected package libavahi-glib1:amd64.
Preparing to unpack .../03-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...
Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...
Selecting previously unselected package glib-networking-common.
Preparing to unpack .../04-glib-networking-common_2.72.0-1_all.deb ...
Unpacking glib-networking-common (2.72.0-1) ...
Selecting previously unselected package glib-networking-services.
Preparing to unpack .../05-glib-networking-services_2.72.0-1_amd64.deb ...
Unpacking glib-networking-services (2.72.0-1) ...
Selecting previously unselected package glib-networking:amd64.
Preparing to unpack .../06-glib-networking_2.72.0-1_amd64.deb ...
Unpacking glib-networking:amd64 (2.72.0-1) ...
Selecting previously unselected package libsoup2.4-common.
Preparing to unpack .../07-libsoup2.4-common_2.74.2-3ubuntu0.4_all.deb ...
Unpacking libsoup2.4-common (2.74.2-3ubuntu0.4) ...
Selecting previously unselected package libsoup2.4-1:amd64.
Preparing to unpack .../08-libsoup2.4-1_2.74.2-3ubuntu0.4_amd64.deb ...
Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.4) ...
Selecting previously unselected package libostree-1-1:amd64.
Preparing to unpack .../09-libostree-1-1_2022.2-3_amd64.deb ...
Unpacking libostree-1-1:amd64 (2022.2-3) ...
Selecting previously unselected package buildah.
Preparing to unpack .../10-buildah_1.23.1+ds1-2_amd64.deb ...
Unpacking buildah (1.23.1+ds1-2) ...
Selecting previously unselected package catatonit.
Preparing to unpack .../11-catatonit_0.1.7-1_amd64.deb ...
Unpacking catatonit (0.1.7-1) ...
Selecting previously unselected package conmon.
Preparing to unpack .../12-conmon_2.0.25+ds1-1.1_amd64.deb ...
Unpacking conmon (2.0.25+ds1-1.1) ...
Selecting previously unselected package containernetworking-plugins.
Preparing to unpack .../13-containernetworking-plugins_0.9.1+ds1-1ubuntu0.1_amd64.deb ...
Unpacking containernetworking-plugins (0.9.1+ds1-1ubuntu0.1) ...
Selecting previously unselected package libyajl2:amd64.
Preparing to unpack .../14-libyajl2_2.1.0-3ubuntu0.22.04.1_amd64.deb ...
Unpacking libyajl2:amd64 (2.1.0-3ubuntu0.22.04.1) ...
Selecting previously unselected package crun.
Preparing to unpack .../15-crun_0.17+dfsg-1.1ubuntu0.1_amd64.deb ...
Unpacking crun (0.17+dfsg-1.1ubuntu0.1) ...
Selecting previously unselected package dns-root-data.
Preparing to unpack .../16-dns-root-data_2024071801~ubuntu0.22.04.1_all.deb ...
Unpacking dns-root-data (2024071801~ubuntu0.22.04.1) ...
Selecting previously unselected package dnsmasq-base.
Preparing to unpack .../17-dnsmasq-base_2.90-0ubuntu0.22.04.1_amd64.deb ...
Unpacking dnsmasq-base (2.90-0ubuntu0.22.04.1) ...
Selecting previously unselected package fuse-overlayfs.
Preparing to unpack .../18-fuse-overlayfs_1.7.1-1_amd64.deb ...
Unpacking fuse-overlayfs (1.7.1-1) ...
Selecting previously unselected package golang-github-containernetworking-plugin-dnsname.
Preparing to unpack .../19-golang-github-containernetworking-plugin-dnsname_1.3.1+ds1-2ubuntu0.22.04.1_amd64.deb ...
Unpacking golang-github-containernetworking-plugin-dnsname (1.3.1+ds1-2ubuntu0.22.04.1) ...
Selecting previously unselected package podman.
Preparing to unpack .../20-podman_3.4.4+ds1-1ubuntu1.22.04.3_amd64.deb ...
Unpacking podman (3.4.4+ds1-1ubuntu1.22.04.3) ...
Setting up uidmap (1:4.8.1-2ubuntu2.2) ...
Setting up libyajl2:amd64 (2.1.0-3ubuntu0.22.04.1) ...
Setting up dnsmasq-base (2.90-0ubuntu0.22.04.1) ...
Setting up dns-root-data (2024071801~ubuntu0.22.04.1) ...
Setting up golang-github-containers-image (5.16.0-3) ...
Setting up conmon (2.0.25+ds1-1.1) ...
Setting up containernetworking-plugins (0.9.1+ds1-1ubuntu0.1) ...
Setting up catatonit (0.1.7-1) ...
Setting up golang-github-containernetworking-plugin-dnsname (1.3.1+ds1-2ubuntu0.22.04.1) ...
Setting up libsoup2.4-common (2.74.2-3ubuntu0.4) ...
Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...
Setting up fuse-overlayfs (1.7.1-1) ...
Setting up golang-github-containers-common (0.44.4+ds1-1) ...
Setting up glib-networking-common (2.72.0-1) ...
Setting up glib-networking-services (2.72.0-1) ...
Setting up crun (0.17+dfsg-1.1ubuntu0.1) ...
Setting up podman (3.4.4+ds1-1ubuntu1.22.04.3) ...
Created symlink /etc/systemd/user/default.target.wants/podman.service ‚Üí /usr/lib/systemd/user/podman.service.
Created symlink /etc/systemd/user/sockets.target.wants/podman.socket ‚Üí /usr/lib/systemd/user/podman.socket.
Created symlink /etc/systemd/system/default.target.wants/podman.service ‚Üí /lib/systemd/system/podman.service.
Created symlink /etc/systemd/system/sockets.target.wants/podman.socket ‚Üí /lib/systemd/system/podman.socket.
Created symlink /etc/systemd/system/default.target.wants/podman-auto-update.service ‚Üí /lib/systemd/system/podman-auto-update.service.
Created symlink /etc/systemd/system/timers.target.wants/podman-auto-update.timer ‚Üí /lib/systemd/system/podman-auto-update.timer.
Created symlink /etc/systemd/system/default.target.wants/podman-restart.service ‚Üí /lib/systemd/system/podman-restart.service.
Setting up glib-networking:amd64 (2.72.0-1) ...
Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.4) ...
Setting up libostree-1-1:amd64 (2022.2-3) ...
Setting up buildah (1.23.1+ds1-2) ...
Processing triggers for libc-bin (2.35-0ubuntu3.9) ...
Processing triggers for man-db (2.10.2-1) ...
Processing triggers for dbus (1.12.20-2ubuntu4.1) ...
Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.4) ...
Scanning processes...
Scanning candidates...
Scanning linux images...

Restarting services...
 systemctl restart cron.service
Service restarts being deferred:
 /etc/needrestart/restart.d/dbus.service
 systemctl restart getty@tty1.service
 systemctl restart systemd-logind.service
 systemctl restart unattended-upgrades.service
 systemctl restart user@0.service

No containers need to be restarted.

No user sessions are running outdated binaries.

No VM guests are running outdated hypervisor (qemu) binaries on this host.
root@racknerd-896d790:~# docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
NAMES       IMAGE       STATUS
root@racknerd-896d790:~# ./system_audit.sh
============================================
üìÖ Hostname: racknerd-896d790
üìç IP Address: 107.172.80.41
üïí Date: Thu May  8 08:46:50 PM UTC 2025
üñ•Ô∏è Uptime: up 2 weeks, 6 days, 19 hours, 45 minutes
============================================

üîß Kernel & OS Info
Linux racknerd-896d790 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Distributor ID: Ubuntu
Description:    Ubuntu 22.04.5 LTS
Release:        22.04
Codename:       jammy

üß† Memory Usage:
               total        used        free      shared  buff/cache   available
Mem:           3.8Gi       529Mi       725Mi        13Mi       2.6Gi       2.9Gi
Swap:          2.0Gi        21Mi       2.0Gi

üî• Top 10 CPU-consuming Processes:
    PID    PPID CMD                         %MEM %CPU
 390832       1 /usr/bin/dockerd -H fd:// -  1.6  3.0
 249392  249391 dockerd                      0.8  2.4
   1292       1 /opt/loki/loki-linux-amd64   0.9  0.5
 374628       1 /usr/share/grafana/bin/graf  4.3  0.5
 374762       1 /lib/systemd/systemd-journa  3.1  0.2
      1       0 /lib/systemd/systemd --syst  0.3  0.0
      2       0 [kthreadd]                   0.0  0.0
      3       2 [rcu_gp]                     0.0  0.0
      4       2 [rcu_par_gp]                 0.0  0.0
      5       2 [slub_flushwq]               0.0  0.0

üì¶ Disk Usage (Human Readable):
Filesystem     Type   Size  Used Avail Use% Mounted on
tmpfs          tmpfs  392M  1.4M  390M   1% /run
/dev/vda2      ext4    48G   44G  1.1G  98% /
tmpfs          tmpfs  2.0G  112K  2.0G   1% /dev/shm
tmpfs          tmpfs  5.0M     0  5.0M   0% /run/lock
tmpfs          tmpfs  392M  4.0K  392M   1% /run/user/0

üìÇ Largest Directories (top 10 in /):
46G     /
30G     /root
7.3G    /var
6.5G    /usr
1.4G    /snap
363M    /boot
84M     /opt
11M     /tmp
7.9M    /etc
1.4M    /run

üß† Virtual Memory + Swap Activity:
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0  22404 684748 263336 2508112    0    0     2    25    3    5  0  0 99  0  0
 0  0  22404 684748 263340 2507740    0    0     0   188 1851 2907  1  3 96  0  0
 0  0  22404 684748 263340 2507740    0    0     0     0 2019 3193  1  1 98  0  0

üîÑ I/O Stats (iostat):
Linux 5.15.0-130-generic (racknerd-896d790)     05/08/2025      _x86_64_        (3 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.30    0.01    0.34    0.11    0.04   99.20

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
loop0            0.00      0.00     0.00   0.00    1.26     4.86    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop1            0.00      0.00     0.00   0.00    8.10     5.36    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop2            0.00      0.00     0.00   0.00    8.51    15.72    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop3            0.00      0.00     0.00   0.00    7.78    15.31    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop4            0.00      0.00     0.00   0.00    0.86     3.15    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop5            0.00      0.03     0.00   0.00    4.32    38.57    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop6            0.00      0.04     0.00   0.00  166.59    37.48    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.02
loop7            0.00      0.00     0.00   0.00    0.00     1.27    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
sr0              0.00      0.00     0.00   0.00   11.60     0.20    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
vda              0.15      5.80     0.03  15.57    9.36    39.78   11.13     73.38     1.87  14.36   10.81     6.60    0.00      0.00     0.00   0.00    0.00     0.00    0.47    1.62    0.12   0.39


avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.01    0.00    1.35    0.00    0.00   97.64

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util


avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.36    0.00    1.02    0.00    0.00   97.63

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util



üåê Listening Ports:
tcp   LISTEN 0      244        127.0.0.1:5432      0.0.0.0:*    users:(("postgres",pid=387093,fd=5))                                            
tcp   LISTEN 0      4096   127.0.0.53%lo:53        0.0.0.0:*    users:(("systemd-resolve",pid=374759,fd=14))                                    
tcp   LISTEN 0      110        127.0.0.1:3306      0.0.0.0:*    users:(("mariadbd",pid=387088,fd=27))                                           
tcp   LISTEN 0      511          0.0.0.0:90        0.0.0.0:*    users:(("nginx",pid=387019,fd=7),("nginx",pid=387018,fd=7),("nginx",pid=387016,fd=7),("nginx",pid=387015,fd=7))
tcp   LISTEN 0      511          0.0.0.0:80        0.0.0.0:*    users:(("nginx",pid=387019,fd=6),("nginx",pid=387018,fd=6),("nginx",pid=387016,fd=6),("nginx",pid=387015,fd=6))
tcp   LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=386986,fd=3))                                                
tcp   LISTEN 0      4096               *:3100            *:*    users:(("loki-linux-amd6",pid=1292,fd=8))                                       
tcp   LISTEN 0      128             [::]:22           [::]:*    users:(("sshd",pid=386986,fd=4))                                                
tcp   LISTEN 0      4096               *:3000            *:*    users:(("grafana",pid=374628,fd=14))                                            
tcp   LISTEN 0      4096               *:9096            *:*    users:(("loki-linux-amd6",pid=1292,fd=9))                                       
tcp   LISTEN 0      4096               *:9100            *:*    users:(("node_exporter",pid=245646,fd=3))                                       

üåê Outbound Connections (top talkers):
      2 127.0.0.1
      1 98.198.245.157

üìã Recent Login Activity:
root     pts/5        Thu May  8 19:58   still logged in    98.198.245.157
root     pts/4        Wed May  7 20:47   still logged in    tmux(249664).%1
root     pts/2        Wed May  7 20:41   still logged in    tmux(249664).%0
root     pts/0        Wed May  7 16:56 - 03:56  (10:59)     98.177.160.217
reboot   system boot  Fri Apr 18 01:01   still running      5.15.0-130-generic
reboot   system boot  Sun Apr  6 09:58   still running      5.15.0-130-generic
reboot   system boot  Tue Mar 18 10:18   still running      5.15.0-130-generic
reboot   system boot  Sat Mar 15 04:06   still running      5.15.0-130-generic
reboot   system boot  Fri Mar 14 15:16   still running      5.15.0-130-generic
reboot   system boot  Sun Mar  9 02:51   still running      5.15.0-130-generic

üìã Active Users:
 20:46:57 up 20 days, 19:45,  4 users,  load average: 0.42, 0.18, 0.13
USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT
root     pts/1    98.177.160.217   Wed20    0.00s  0.00s  0.01s sudo dockerd
root     pts/2    tmux(249664).%0  Wed20   24:04m  0.02s  0.02s -bash
root     pts/4    tmux(249664).%1  Wed20   20:36m  0.15s  0.00s bash
root     pts/5    98.198.245.157   19:58    9.00s  0.10s  0.00s w

üì¶ Docker Status:
‚óè docker.service - Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
     Active: activating (start) since Thu 2025-05-08 20:46:16 UTC; 41s ago
TriggeredBy: ‚óè docker.socket
       Docs: https://docs.docker.com
   Main PID: 390832 (dockerd)
      Tasks: 9
     Memory: 19.7M
        CPU: 1.264s
     CGroup: /system.slice/docker.service
             ‚îî‚îÄ390832 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

May 08 20:46:16 racknerd-896d790 systemd[1]: Starting Docker Application Container Engine...
May 08 20:46:16 racknerd-896d790 dockerd[390832]: time="2025-05-08T20:46:16.661520509Z" level=info msg="Starting up"
May 08 20:46:16 racknerd-896d790 dockerd[390832]: time="2025-05-08T20:46:16.663011553Z" level=info msg="OTEL tracing is not configured‚Ä¶provider"
May 08 20:46:16 racknerd-896d790 dockerd[390832]: time="2025-05-08T20:46:16.686912532Z" level=info msg="Creating a containerd client" ‚Ä¶eout=1m0s
Hint: Some lines were ellipsized, use -l to show in full.

üì¶ Running Containers:
^C
üìä Grafana Status:
‚óè grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendor preset: enabled)
     Active: active (running) since Thu 2025-05-08 20:00:25 UTC; 47min ago
       Docs: http://docs.grafana.org
   Main PID: 374628 (grafana)
      Tasks: 20 (limit: 4563)
     Memory: 84.8M
        CPU: 16.324s
     CGroup: /system.slice/grafana-server.service
             ‚îî‚îÄ374628 /usr/share/grafana/bin/grafana server --config=/etc/grafana/grafana.ini --pidfile=/run/grafana/grafana-server.pid --packa‚Ä¶

May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:10:28.448917888Z level=info msg="Updat‚Ä¶.100591ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:20:28.202658295Z level=info msg="Completed cleanup jo‚Ä¶.148527ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:20:28.446094998Z level=info msg="Updat‚Ä¶.723357ms
May 08 20:27:26 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:27:26.738345625Z level=info m‚Ä¶ce=server
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:30:28.202197032Z level=info msg="Completed cleanup jo‚Ä¶.131177ms
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:30:28.451723802Z level=info msg="Updat‚Ä¶.587729ms
May 08 20:31:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:31:25.218554036Z level=info msg="Usage stats‚Ä¶o report"
May 08 20:36:37 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:36:37.008384332Z level=info ‚Ä¶rce=server
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:40:28.202972754Z level=info msg="Completed cleanup jo‚Ä¶.136175ms
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:40:28.453264228Z level=info msg="Updat‚Ä¶.480374ms
Hint: Some lines were ellipsized, use -l to show in full.

üìÑ Grafana Logs (last 20 lines):
May 08 20:00:29 racknerd-896d790 grafana[374628]: logger=installer.fs t=2025-05-08T20:00:29.952004851Z level=info msg="Downloaded and extracted grafana-pyroscope-app v1.3.0 zip successfully to /var/lib/grafana/plugins/grafana-pyroscope-app"
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugins.registration t=2025-05-08T20:00:30.065937311Z level=info msg="Plugin registered" pluginId=grafana-pyroscope-app
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.066064748Z level=info msg="Plugin successfully installed" pluginId=grafana-pyroscope-app version= duration=346.443817ms
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.066292872Z level=info msg="Installing plugin" pluginId=grafana-exploretraces-app version=
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.installer t=2025-05-08T20:00:30.284847603Z level=info msg="Installing plugin" pluginId=grafana-exploretraces-app version=
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=installer.fs t=2025-05-08T20:00:30.402499883Z level=info msg="Downloaded and extracted grafana-exploretraces-app v1.0.0 zip successfully to /var/lib/grafana/plugins/grafana-exploretraces-app"
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugins.registration t=2025-05-08T20:00:30.528372768Z level=info msg="Plugin registered" pluginId=grafana-exploretraces-app
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.528473179Z level=info msg="Plugin successfully installed" pluginId=grafana-exploretraces-app version= duration=461.977738ms
May 08 20:01:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:01:25.206035169Z level=info msg="Usage stats are ready to report"
May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:10:28.213665639Z level=info msg="Completed cleanup jobs" duration=18.914496ms
May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:10:28.448917888Z level=info msg="Update check succeeded" duration=87.100591ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:20:28.202658295Z level=info msg="Completed cleanup jobs" duration=8.148527ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:20:28.446094998Z level=info msg="Update check succeeded" duration=84.723357ms
May 08 20:27:26 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:27:26.738345625Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=87.236.176.75 time_ms=1 duration=1.492177ms size=29 referer= handler=/ status_source=server
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:30:28.202197032Z level=info msg="Completed cleanup jobs" duration=7.131177ms
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:30:28.451723802Z level=info msg="Update check succeeded" duration=90.587729ms
May 08 20:31:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:31:25.218554036Z level=info msg="Usage stats are ready to report"
May 08 20:36:37 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:36:37.008384332Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=146.190.136.135 time_ms=0 duration=579.686¬µs size=29 referer= handler=/ status_source=server
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:40:28.202972754Z level=info msg="Completed cleanup jobs" duration=8.136175ms
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:40:28.453264228Z level=info msg="Update check succeeded" duration=91.480374ms

üìÅ Loki Service Status (if present):
root        1292  0.5  0.9 1294940 36516 ?       Ssl  Apr18 154:29 /opt/loki/loki-linux-amd64 -config.file=/opt/loki/loki-local-config.yaml

üõ°Ô∏è Fail2Ban Status:
Status
|- Number of jail:      1
- Jail list:   sshd

üö´ Fail2Ban Banned IPs for sshd:
   - Banned IP list:   59.1.245.186 218.92.0.149 88.214.50.40

üóÑÔ∏è Top 5 Log Files by Size (/var/log):
883M    /var/log/syslog.1
628M    /var/log/syslog
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system.journal
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system@ef23549089974bf09e67a7b8e45c3fd8-000000000008d4d4-0006346de8b1d743.journal
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system@ef23549089974bf09e67a7b8e45c3fd8-0000000000069fc8-00063469e8ee67b8.journal

üìã Top 10 Running Services by Memory Usage:
    PID CMD                         %MEM %CPU
 374628 /usr/share/grafana/bin/graf  4.3  0.5
 374762 /lib/systemd/systemd-journa  3.1  0.2
 387088 /usr/sbin/mariadbd           1.8  0.0
 374391 /usr/libexec/fwupd/fwupd     1.5  0.0
 390979 /usr/bin/dockerd -H fd:// -  1.5  3.5
   1292 /opt/loki/loki-linux-amd64   0.9  0.5
 249392 dockerd                      0.8  2.4
 387093 /usr/lib/postgresql/14/bin/  0.6  0.0
 386971 /sbin/multipathd -d -s       0.6  0.0
 387119 /usr/bin/python3 /usr/bin/f  0.5  0.0

‚úÖ Audit Complete. Suggested follow-up: htop, journalctl, docker logs <container>, fail2ban-client, and grafana dashboards.
root@racknerd-896d790:~#  the script stops running at running containers


ChatGPT said:
Thanks for the detailed report ‚Äî your audit script works perfectly up until docker ps, where it freezes or hangs at:

bash
Copy
Edit
üì¶ Running Containers:
^C
This usually means that the docker ps command is waiting indefinitely for a response from the Docker daemon, which is not yet ready or stuck in a bad state.

üõ†Ô∏è Fix: Add a Timeout and Failover to Avoid Hanging
Replace:

bash
Copy
Edit
docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
With this safe, timeout-controlled command:

bash
Copy
Edit
echo -e "\nüì¶ Running Containers:"
timeout 5s docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}" || echo "‚ö†Ô∏è  Docker not responding or no containers running"
This will wait 5 seconds max for Docker to respond, then print a fallback message if it's stuck or unresponsive.

‚úÖ Optional: Add More Robust Docker Health Check
Right before this line, you can even check whether the daemon is healthy:

bash
Copy
Edit
docker info > /dev/null 2>&1
if [ $? -ne 0 ]; then
  echo "üö® Docker daemon is not responding."
else
  timeout 5s docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
fi
‚úÖ Bonus: Automatically Restart Docker If It‚Äôs Dead
If you want the script to auto-recover Docker, add:

bash
Copy
Edit
if ! docker info > /dev/null 2>&1; then
  echo "üîÅ Restarting Docker..."
  systemctl restart docker
  sleep 3
  docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}" || echo "‚ö†Ô∏è Still no response after restart."
fi
‚úÖ Let Me Know If You Want:
Markdown-export version of this audit

A cron version that runs weekly and sends you a .log or email

Full cleanup logic for /var/log to free up space (you're at 98% disk usage!)

Would you like the entire script patched with these Docker improvements and Markdown export for GitHub audits?







You said:
 ./system_audit.sh
============================================
üìÖ Hostname: racknerd-896d790
üìç IP Address: 107.172.80.41
üïí Date: Thu May  8 08:51:36 PM UTC 2025
üñ•Ô∏è Uptime: up 2 weeks, 6 days, 19 hours, 50 minutes
============================================

üîß Kernel & OS Info
Linux racknerd-896d790 5.15.0-130-generic #140-Ubuntu SMP Wed Dec 18 17:59:53 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
Distributor ID: Ubuntu
Description:    Ubuntu 22.04.5 LTS
Release:        22.04
Codename:       jammy

üß† Memory Usage:
               total        used        free      shared  buff/cache   available
Mem:           3.8Gi       544Mi       655Mi        13Mi       2.6Gi       2.9Gi
Swap:          2.0Gi        21Mi       2.0Gi

üî• Top 10 CPU-consuming Processes:
    PID    PPID CMD                         %MEM %CPU
 391256       1 /usr/bin/dockerd -H fd:// -  1.5  4.8
 249392  249391 dockerd                      0.8  2.4
   1292       1 /opt/loki/loki-linux-amd64   0.9  0.5
 374628       1 /usr/share/grafana/bin/graf  4.3  0.5
 374762       1 /lib/systemd/systemd-journa  3.2  0.2
      1       0 /lib/systemd/systemd --syst  0.3  0.0
      2       0 [kthreadd]                   0.0  0.0
      3       2 [rcu_gp]                     0.0  0.0
      4       2 [rcu_par_gp]                 0.0  0.0
      5       2 [slub_flushwq]               0.0  0.0

üì¶ Disk Usage (Human Readable):
Filesystem     Type   Size  Used Avail Use% Mounted on
tmpfs          tmpfs  392M  1.4M  390M   1% /run
/dev/vda2      ext4    48G   44G  1.1G  98% /
tmpfs          tmpfs  2.0G  112K  2.0G   1% /dev/shm
tmpfs          tmpfs  5.0M     0  5.0M   0% /run/lock
tmpfs          tmpfs  392M  4.0K  392M   1% /run/user/0

üìÇ Largest Directories (top 10 in /):
46G     /
30G     /root
7.3G    /var
6.5G    /usr
1.4G    /snap
363M    /boot
84M     /opt
11M     /tmp
7.9M    /etc
1.4M    /run

üß† Virtual Memory + Swap Activity:
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0  22404 669536 263788 2513468    0    0     2    25    3    6  0  0 99  0  0
 0  0  22404 669536 263788 2513232    0    0     0     0 2031 2927  2  2 96  0  0
 0  0  22404 669536 263788 2513232    0    0     0     0 1961 2916  1  1 98  0  0

üîÑ I/O Stats (iostat):
Linux 5.15.0-130-generic (racknerd-896d790)     05/08/2025      _x86_64_        (3 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.30    0.01    0.34    0.11    0.04   99.20

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
loop0            0.00      0.00     0.00   0.00    1.07     4.51    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop1            0.00      0.00     0.00   0.00    8.10     5.36    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop2            0.00      0.00     0.00   0.00    8.51    15.72    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop3            0.00      0.00     0.00   0.00    7.78    15.31    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop4            0.00      0.00     0.00   0.00    0.71     3.06    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop5            0.00      0.03     0.00   0.00    4.32    38.57    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
loop6            0.00      0.04     0.00   0.00  166.51    37.50    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.02
loop7            0.00      0.00     0.00   0.00    0.00     1.27    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
sr0              0.00      0.00     0.00   0.00   11.60     0.20    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.00
vda              0.15      5.80     0.03  15.57    9.36    39.78   11.13     73.39     1.87  14.36   10.80     6.60    0.00      0.00     0.00   0.00    0.00     0.00    0.47    1.62    0.12   0.39


avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           1.00    0.00    2.34    0.00    0.00   96.66

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
vda              0.00      0.00     0.00   0.00    0.00     0.00    6.00     88.00    14.00  70.00    0.33    14.67    0.00      0.00     0.00   0.00    0.00     0.00    2.00    0.00    0.00   1.20


avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           0.67    0.00    0.67    0.00    0.00   98.66

Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util



üåê Listening Ports:
tcp   LISTEN 0      244        127.0.0.1:5432      0.0.0.0:*    users:(("postgres",pid=387093,fd=5))                                            
tcp   LISTEN 0      4096   127.0.0.53%lo:53        0.0.0.0:*    users:(("systemd-resolve",pid=374759,fd=14))                                    
tcp   LISTEN 0      110        127.0.0.1:3306      0.0.0.0:*    users:(("mariadbd",pid=387088,fd=27))                                           
tcp   LISTEN 0      511          0.0.0.0:90        0.0.0.0:*    users:(("nginx",pid=387019,fd=7),("nginx",pid=387018,fd=7),("nginx",pid=387016,fd=7),("nginx",pid=387015,fd=7))
tcp   LISTEN 0      511          0.0.0.0:80        0.0.0.0:*    users:(("nginx",pid=387019,fd=6),("nginx",pid=387018,fd=6),("nginx",pid=387016,fd=6),("nginx",pid=387015,fd=6))
tcp   LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=386986,fd=3))                                                
tcp   LISTEN 0      4096               *:3100            *:*    users:(("loki-linux-amd6",pid=1292,fd=8))                                       
tcp   LISTEN 0      128             [::]:22           [::]:*    users:(("sshd",pid=386986,fd=4))                                                
tcp   LISTEN 0      4096               *:3000            *:*    users:(("grafana",pid=374628,fd=14))                                            
tcp   LISTEN 0      4096               *:9096            *:*    users:(("loki-linux-amd6",pid=1292,fd=9))                                       
tcp   LISTEN 0      4096               *:9100            *:*    users:(("node_exporter",pid=245646,fd=3))                                       

üåê Outbound Connections (top talkers):
      2 127.0.0.1
      1 98.198.245.157
      1 34.120.177.193

üìã Recent Login Activity:
root     pts/5        Thu May  8 19:58   still logged in    98.198.245.157
root     pts/4        Wed May  7 20:47   still logged in    tmux(249664).%1
root     pts/2        Wed May  7 20:41   still logged in    tmux(249664).%0
root     pts/0        Wed May  7 16:56 - 03:56  (10:59)     98.177.160.217
reboot   system boot  Fri Apr 18 01:01   still running      5.15.0-130-generic
reboot   system boot  Sun Apr  6 09:58   still running      5.15.0-130-generic
reboot   system boot  Tue Mar 18 10:18   still running      5.15.0-130-generic
reboot   system boot  Sat Mar 15 04:06   still running      5.15.0-130-generic
reboot   system boot  Fri Mar 14 15:16   still running      5.15.0-130-generic
reboot   system boot  Sun Mar  9 02:51   still running      5.15.0-130-generic

üìã Active Users:
 20:51:43 up 20 days, 19:50,  4 users,  load average: 0.59, 0.29, 0.17
USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT
root     pts/1    98.177.160.217   Wed20    0.00s  0.00s  0.01s sudo dockerd
root     pts/2    tmux(249664).%0  Wed20   24:09m  0.02s  0.02s -bash
root     pts/4    tmux(249664).%1  Wed20   20:41m  0.15s  0.00s bash
root     pts/5    98.198.245.157   19:58    7.00s  0.11s  0.00s w

üì¶ Docker Status:
‚óè docker.service - Docker Application Container Engine
     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
     Active: activating (start) since Thu 2025-05-08 20:51:31 UTC; 11s ago
TriggeredBy: ‚óè docker.socket
       Docs: https://docs.docker.com
   Main PID: 391256 (dockerd)
      Tasks: 9
     Memory: 17.3M
        CPU: 487ms
     CGroup: /system.slice/docker.service
             ‚îî‚îÄ391256 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock

May 08 20:51:31 racknerd-896d790 systemd[1]: Starting Docker Application Container Engine...
May 08 20:51:31 racknerd-896d790 dockerd[391256]: time="2025-05-08T20:51:31.690338320Z" level=info msg="Starting up"
May 08 20:51:31 racknerd-896d790 dockerd[391256]: time="2025-05-08T20:51:31.691651806Z" level=info msg="OTEL tracing is not configured‚Ä¶provider"
May 08 20:51:31 racknerd-896d790 dockerd[391256]: time="2025-05-08T20:51:31.720532127Z" level=info msg="Creating a containerd client" ‚Ä¶eout=1m0s
Hint: Some lines were ellipsized, use -l to show in full.

üì¶ Running Containers:
‚ö†Ô∏è  Docker not responding or no containers running

üìä Grafana Status:
‚óè grafana-server.service - Grafana instance
     Loaded: loaded (/lib/systemd/system/grafana-server.service; enabled; vendor preset: enabled)
     Active: active (running) since Thu 2025-05-08 20:00:25 UTC; 51min ago
       Docs: http://docs.grafana.org
   Main PID: 374628 (grafana)
      Tasks: 20 (limit: 4563)
     Memory: 85.7M
        CPU: 17.393s
     CGroup: /system.slice/grafana-server.service
             ‚îî‚îÄ374628 /usr/share/grafana/bin/grafana server --config=/etc/grafana/grafana.ini --pidfile=/run/grafana/grafana-server.pid --packa‚Ä¶

May 08 20:27:26 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:27:26.738345625Z level=info m‚Ä¶ce=server
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:30:28.202197032Z level=info msg="Completed cleanup jo‚Ä¶.131177ms
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:30:28.451723802Z level=info msg="Updat‚Ä¶.587729ms
May 08 20:31:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:31:25.218554036Z level=info msg="Usage stats‚Ä¶o report"
May 08 20:36:37 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:36:37.008384332Z level=info ‚Ä¶rce=server
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:40:28.202972754Z level=info msg="Completed cleanup jo‚Ä¶.136175ms
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:40:28.453264228Z level=info msg="Updat‚Ä¶.480374ms
May 08 20:50:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:50:28.204029369Z level=info msg="Completed cleanup jo‚Ä¶.092154ms
May 08 20:50:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:50:28.451636473Z level=info msg="Updat‚Ä¶.534405ms
May 08 20:51:08 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:51:08.902692336Z level=info m‚Ä¶ce=server
Hint: Some lines were ellipsized, use -l to show in full.

üìÑ Grafana Logs (last 20 lines):
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.066292872Z level=info msg="Installing plugin" pluginId=grafana-exploretraces-app version=
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.installer t=2025-05-08T20:00:30.284847603Z level=info msg="Installing plugin" pluginId=grafana-exploretraces-app version=
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=installer.fs t=2025-05-08T20:00:30.402499883Z level=info msg="Downloaded and extracted grafana-exploretraces-app v1.0.0 zip successfully to /var/lib/grafana/plugins/grafana-exploretraces-app"
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugins.registration t=2025-05-08T20:00:30.528372768Z level=info msg="Plugin registered" pluginId=grafana-exploretraces-app
May 08 20:00:30 racknerd-896d790 grafana[374628]: logger=plugin.backgroundinstaller t=2025-05-08T20:00:30.528473179Z level=info msg="Plugin successfully installed" pluginId=grafana-exploretraces-app version= duration=461.977738ms
May 08 20:01:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:01:25.206035169Z level=info msg="Usage stats are ready to report"
May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:10:28.213665639Z level=info msg="Completed cleanup jobs" duration=18.914496ms
May 08 20:10:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:10:28.448917888Z level=info msg="Update check succeeded" duration=87.100591ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:20:28.202658295Z level=info msg="Completed cleanup jobs" duration=8.148527ms
May 08 20:20:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:20:28.446094998Z level=info msg="Update check succeeded" duration=84.723357ms
May 08 20:27:26 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:27:26.738345625Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=87.236.176.75 time_ms=1 duration=1.492177ms size=29 referer= handler=/ status_source=server
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:30:28.202197032Z level=info msg="Completed cleanup jobs" duration=7.131177ms
May 08 20:30:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:30:28.451723802Z level=info msg="Update check succeeded" duration=90.587729ms
May 08 20:31:25 racknerd-896d790 grafana[374628]: logger=infra.usagestats t=2025-05-08T20:31:25.218554036Z level=info msg="Usage stats are ready to report"
May 08 20:36:37 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:36:37.008384332Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=146.190.136.135 time_ms=0 duration=579.686¬µs size=29 referer= handler=/ status_source=server
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:40:28.202972754Z level=info msg="Completed cleanup jobs" duration=8.136175ms
May 08 20:40:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:40:28.453264228Z level=info msg="Update check succeeded" duration=91.480374ms
May 08 20:50:28 racknerd-896d790 grafana[374628]: logger=cleanup t=2025-05-08T20:50:28.204029369Z level=info msg="Completed cleanup jobs" duration=9.092154ms
May 08 20:50:28 racknerd-896d790 grafana[374628]: logger=plugins.update.checker t=2025-05-08T20:50:28.451636473Z level=info msg="Update check succeeded" duration=90.534405ms
May 08 20:51:08 racknerd-896d790 grafana[374628]: logger=context userId=0 orgId=0 uname= t=2025-05-08T20:51:08.902692336Z level=info msg="Request Completed" method=GET path=/ status=302 remote_addr=185.226.197.44 time_ms=1 duration=1.05125ms size=29 referer= handler=/ status_source=server

üìÅ Loki Service Status (if present):
root        1292  0.5  0.9 1294940 36516 ?       Ssl  Apr18 154:31 /opt/loki/loki-linux-amd64 -config.file=/opt/loki/loki-local-config.yaml

üõ°Ô∏è Fail2Ban Status:
Status
|- Number of jail:      1
- Jail list:   sshd

üö´ Fail2Ban Banned IPs for sshd:
   - Banned IP list:   218.92.0.149 88.214.50.40 185.216.132.243

üóÑÔ∏è Top 5 Log Files by Size (/var/log):
883M    /var/log/syslog.1
629M    /var/log/syslog
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system.journal
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system@ef23549089974bf09e67a7b8e45c3fd8-000000000008d4d4-0006346de8b1d743.journal
129M    /var/log/journal/985b7b1f0ece90cd85d83edea87d03f6/system@ef23549089974bf09e67a7b8e45c3fd8-0000000000069fc8-00063469e8ee67b8.journal

üìã Top 10 Running Services by Memory Usage:
    PID CMD                         %MEM %CPU
 374628 /usr/share/grafana/bin/graf  4.3  0.5
 374762 /lib/systemd/systemd-journa  3.2  0.2
 387088 /usr/sbin/mariadbd           1.8  0.0
 374391 /usr/libexec/fwupd/fwupd     1.5  0.0
 391256 /usr/bin/dockerd -H fd:// -  1.5  3.2
   1292 /opt/loki/loki-linux-amd64   0.9  0.5
 249392 dockerd                      0.8  2.4
 387093 /usr/lib/postgresql/14/bin/  0.6  0.0
 386971 /sbin/multipathd -d -s       0.6  0.0
 387119 /usr/bin/python3 /usr/bin/f  0.5  0.0

‚úÖ Audit Complete. Suggested follow-up: htop, journalctl, docker logs <container>, fail2ban-client, and grafana dashboards.
root@racknerd-896d790:~#  explain the above to an interviewer and land the linux admin job


ChatGPT said:
Absolutely, here‚Äôs how you can confidently walk an interviewer through the full system audit output and demonstrate your real-world Linux admin capabilities ‚Äî this is interview gold when done right.

üß† How to Explain This System Audit Output and Win the Job
üí¨ 1. Host & OS Overview
‚ÄúFirst, I performed a full system audit to assess uptime, kernel version, and OS baseline. The server has been up for nearly 3 weeks, running Ubuntu 22.04.5 LTS with kernel 5.15 ‚Äî this confirms a stable environment with long-term support. I always begin here to verify if we‚Äôre within security patching windows and kernel compatibility.‚Äù

üí¨ 2. Memory Health & Swap
‚ÄúMemory usage is solid ‚Äî 3.8GB total with only ~500MB actively used. Swap usage is minimal (~21MB), which tells me we‚Äôre not memory starved. If swap was climbing aggressively, I‚Äôd flag a memory leak or misconfigured app container.‚Äù

üí¨ 3. CPU Process Load
‚ÄúDocker‚Äôs daemon is the highest consumer, which is expected in a containerized environment. I confirmed this using ps -eo pid,ppid,cmd,%mem,%cpu. No rogue processes. I also noted that Grafana and Loki were running as expected and consuming reasonable CPU.‚Äù

üí¨ 4. Disk Usage Red Flag
‚ÄúDisk is 98% full ‚Äî /root is consuming 30GB. I‚Äôd jump in and run du -sh /root/* to investigate logs, backups, or temp files. A full disk is a production risk, so my immediate next step would be to automate cleanup or offload logs with logrotate and S3 rsync.‚Äù

üí¨ 5. I/O & System Wait
‚ÄúI/O wait is practically zero and overall CPU idle is 96‚Äì99%. This server is not I/O bound. I validated this using iostat, which shows the disk queue (aqu-sz) and utilization are healthy. No urgent action is needed here.‚Äù

üí¨ 6. Open Ports & Network Listening
‚ÄúI validated critical services are listening correctly: PostgreSQL on 5432, MariaDB on 3306, Grafana on 3000, Loki on 3100/9096, and Node Exporter on 9100. I used ss -tulpn and cross-referenced with systemd. This confirms the observability stack is alive and reachable.‚Äù

üí¨ 7. Docker Health & Delay
‚ÄúDocker was initially stuck in activating state, likely due to restart loops or dead containers. I added a timeout wrapper to prevent script hangs and fallback gracefully. This kind of defensive scripting is what I do to make audit pipelines resilient in cron or CI/CD runs.‚Äù

üí¨ 8. Grafana & Loki Running Clean
‚ÄúGrafana logs show it‚Äôs registering plugins successfully and performing scheduled cleanups. Loki is also alive and scraping logs. I‚Äôd next check the dashboards and alert rules.‚Äù

üí¨ 9. Fail2Ban: Security Observability
‚ÄúFail2Ban is protecting SSH via the sshd jail and has actively banned brute force IPs like 218.92.0.149 and 185.216.132.243. I can automate unbanning or whitelisting from a script if necessary. This confirms active SSH hardening.‚Äù

üí¨ 10. Log File Oversized Warning
‚ÄúSyslog files are massive (~1.5GB total). I‚Äôd configure logrotate immediately, and optionally forward logs to Loki or a remote ELK/SIEM to prevent local overflow. This also explains part of /var's 7GB usage.‚Äù

üí¨ 11. Final Summary
‚ÄúThis audit shows that all services are online, performance is stable, but we need immediate disk space cleanup and Docker daemon health validation. I can containerize this script and schedule it via cron or systemd.timer, or even push results to a GitHub Issues tracker via webhook for centralized reporting.‚Äù

üíº Then Say This to the Interviewer:
‚ÄúThis is a snapshot of how I audit and troubleshoot Linux systems in live production environments. If I were on your team, I‚Äôd automate these diagnostics, trigger remediation steps like log compression and container cleanup, and ensure alerting is in place for disk thresholds, CPU spikes, and service restarts. Would you like me to walk you through how I'd write that CI/CD pipeline or systemd timer next?‚Äù

Would you like me to generate a printable interview cheat sheet, email-ready report, or GitHub markdown export of this entire system audit?







You said:
yes please start with the first 


ChatGPT said:

Analyzed
python
Always show details

Copy
from datetime import datetime
import textwrap

# Generate the printable interview cheat sheet
hostname = "racknerd-896d790"
ip_address = "107.172.80.41"
date_now = datetime.utcnow().strftime("%A, %B %d %Y at %I:%M %p UTC")

cheat_sheet = f"""
# üß† Linux Admin Interview Cheat Sheet: System Audit Review

**üñ•Ô∏è Host:** `{hostname}`  
**üåê IP Address:** `{ip_address}`  
**üóìÔ∏è Audit Time:** {date_now}

---

## üîß 1. Host & OS Health

‚úÖ **OS:** Ubuntu 22.04.5 LTS  
‚úÖ **Kernel:** 5.15.0-130-generic  
‚úÖ **Uptime:** Nearly 3 weeks

üí° *Explanation:*  
System uptime shows long stability. Ubuntu LTS ensures security support.  
I always start by confirming OS version and patch level for compliance.

---

## üß† 2. Memory & Swap

- **Total RAM:** 3.8GiB  
- **Used:** ~544MiB  
- **Swap Usage:** 21MiB

üí° *Explanation:*  
Minimal swap activity = healthy memory usage. No leaks or overcommit.

---

## üî• 3. Top CPU Consumers

| PID     | CMD               | %MEM | %CPU |
|---------|-------------------|------|------|
| 391256  | dockerd           | 1.5  | 4.8  |
| 249392  | docker container  | 0.8  | 2.4  |
| 374628  | grafana           | 4.3  | 0.5  |
| 1292    | loki              | 0.9  | 0.5  |

üí° *Explanation:*  
Expected load from Grafana + Docker. No anomalies found.

---

## üì¶ 4. Disk Usage

- **/dev/vda2:** 98% full  
- **Top Usage:** `/root` (30GB), `/var` (7.3GB)

üí° *Red Flag:*  
Urgent cleanup needed. Recommend `du -sh /root/*` and `logrotate`.

---

## üîÅ 5. CPU & IO Health

- **Idle:** 96‚Äì99%  
- **IOWait:** Near 0%

üí° *Explanation:*  
System is not IO or CPU bound. Stable performance confirmed.

---

## üåê 6. Listening Ports

Services actively listening:
- Postgres (5432)
- MariaDB (3306)
- Grafana (3000)
- Loki (3100, 9096)
- Nginx (80, 90)
- Node Exporter (9100)

üí° *Explanation:*  
Validated active observability and database services.

---

## üê≥ 7. Docker Health

- Status: *Activating...*  
- Action: `systemctl status docker -l`, then `journalctl -u docker`

üí° *Fix:*  
Check for dead containers or locked socket file.

---

## üìä 8. Grafana Status

- Running since: ~1 hour  
- Plugins: Loaded successfully  
- Memory: 85MB

üí° *Explanation:*  
Clean startup. All Grafana logs show routine activity and plugin health.

---

## üîê 9. Fail2Ban Security

- Jail Active: `sshd`  
- Banned IPs: 3 known threats

üí° *Explanation:*  
System actively bans brute-force IPs. Security in place.

---

## üßπ 10. Logs and Cleanup

- `/var/log/syslog`: ~1.5GB  
- Action: Setup `logrotate` and forward logs to Loki or ELK.

üí° *Explanation:*  
Log size explains disk pressure. Clean or archive weekly.

---

## ‚úÖ Final Recommendation

üìå **Automate Audit:** Cron + email output  
üìå **Docker Fix:** Restart or analyze socket  
üìå **Disk Cleanup:** Compress logs and prune `/root`  
üìå **Add Alerting:** For disk > 90%, service down, SSH brute-force

---

**üë®‚Äçüíª Ready for Interview Use!**
Print this, walk your interviewer through each section clearly, and offer remediation steps. You're proving you're ready to manage production.

"""

# Save to file
cheat_sheet_path = "/mnt/data/Linux_Admin_Interview_Cheat_Sheet.md"
with open(cheat_sheet_path, "w") as f:
    f.write(textwrap.dedent(cheat_sheet))

cheat_sheet_path
Result
'/mnt/data/Linux_Admin_Interview_Cheat_Sheet.md'
Your Linux Admin Interview Cheat Sheet has been prepared using the system audit logs.

üìÑ Click here to download the Markdown file

It‚Äôs structured section-by-section to guide your interviewer through real system diagnostics, insights, and your professional response. Would you like a PDF version too? 







You said:
i have all these services running on my system how can i trouble shoot them end to end and as well check them out 


ChatGPT said:
To troubleshoot all the services running on your Linux system end-to-end, here's a complete checklist and command set organized by category. These commands help **check status, logs, performance, ports,







You said:


üåê Listening Ports:
tcp   LISTEN 0      244        127.0.0.1:5432      0.0.0.0:*    users:(("postgres",pid=387093,fd=5))                                            
tcp   LISTEN 0      4096   127.0.0.53%lo:53        0.0.0.0:*    users:(("systemd-resolve",pid=374759,fd=14))                                    
tcp   LISTEN 0      110        127.0.0.1:3306      0.0.0.0:*    users:(("mariadbd",pid=387088,fd=27))                                           
tcp   LISTEN 0      511          0.0.0.0:90        0.0.0.0:*    users:(("nginx",pid=387019,fd=7),("nginx",pid=387018,fd=7),("nginx",pid=387016,fd=7),("nginx",pid=387015,fd=7))
tcp   LISTEN 0      511          0.0.0.0:80        0.0.0.0:*    users:(("nginx",pid=387019,fd=6),("nginx",pid=387018,fd=6),("nginx",pid=387016,fd=6),("nginx",pid=387015,fd=6))
tcp   LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=386986,fd=3))                                                
tcp   LISTEN 0      4096               *:3100            *:*    users:(("loki-linux-amd6",pid=1292,fd=8))                                       
tcp   LISTEN 0      128             [::]:22           [::]:*    users:(("sshd",pid=386986,fd=4))                                                
tcp   LISTEN 0      4096               *:3000            *:*    users:(("grafana",pid=374628,fd=14))                                            
tcp   LISTEN 0      4096               *:9096            *:*    users:(("loki-linux-amd6",pid=1292,fd=9))                                       
tcp   LISTEN 0      4096               *:9100            *:*    users:(("node_exporter",pid=245646,fd=3))                                       
   i have all these services running on my system how can i trouble shoot them end to end and as well check them out   also do i have more services and how can i find out 


ChatGPT said:
Here‚Äôs a full Linux Administrator playbook to check, verify, and troubleshoot all the services you've listed and discover any additional ones. We'll go one-by-one through the services listening on your system, and I‚Äôll also show how to discover all others, whether they‚Äôre running or failed.

‚úÖ 1. PostgreSQL (127.0.0.1:5432)
bash
Copy
Edit
# Check service status
systemctl status postgresql

# Confirm process PID and port
ss -plnt | grep 5432
ps -fp $(pidof postgres)

# Test connection to DB
sudo -u postgres psql -c '\l'

# View logs
journalctl -u postgresql -n 50 --no-pager
‚úÖ 2. systemd-resolved DNS Stub (127.0.0.53:53)
bash
Copy
Edit
# Status and logs
systemctl status systemd-resolved
journalctl -u systemd-resolved -n 50 --no-pager

# Test DNS resolution via stub
dig @127.0.0.53 google.com
‚úÖ 3. MariaDB (127.0.0.1:3306)
bash
Copy
Edit
# Service status
systemctl status mariadb

# Test login
mysql -u root -p

# Check logs
journalctl -u mariadb -n 50 --no-pager
tail -n 50 /var/log/mysql/error.log  # or /var/log/mysql/mariadb.log
‚úÖ 4. Nginx (Web Server) (Ports 80, 90)
bash
Copy
Edit
# Status and config
systemctl status nginx
nginx -t  # test config

# Show open ports and workers
ss -plnt | grep nginx
ps aux | grep nginx

# View logs
tail -n 50 /var/log/nginx/access.log
tail -n 50 /var/log/nginx/error.log
‚úÖ 5. SSHD (SSH Daemon) (Port 22)
bash
Copy
Edit
# Service status
systemctl status sshd

# Logs for failed or suspicious logins
journalctl -u sshd -n 50 --no-pager
grep "Failed password" /var/log/auth.log

# Check current active SSH sessions
who
w
‚úÖ 6. Loki (Logging System) (Ports 3100, 9096)
bash
Copy
Edit
# Confirm it's running
ps -fp 1292
lsof -i :3100
lsof -i :9096

# Check its config
cat /opt/loki/loki-local-config.yaml

# Logs
journalctl -u loki.service -n 50  # if using systemd
‚úÖ 7. Grafana (Monitoring Dashboard) (Port 3000)
bash
Copy
Edit
# Service check
systemctl status grafana-server

# Logs
journalctl -u grafana-server -n 50 --no-pager
cat /var/log/grafana/grafana.log

# Open in browser
http://<your_ip>:3000
‚úÖ 8. Node Exporter (Prometheus Metrics) (Port 9100)
bash
Copy
Edit
# Confirm running
systemctl status node_exporter  # or check manual start command

# Test endpoint
curl http://localhost:9100/metrics | head
üîç Check for All Services Running or Failed
bash
Copy
Edit
# All active services
systemctl list-units --type=service --state=running

# Failed services
systemctl --failed

# All listening ports and associated services
ss -plnt

# Services enabled to start at boot
systemctl list-unit-files --state=enabled
üß† Bonus Tips
Check top memory/cpu usage:

bash
Copy
Edit
ps aux --sort=-%mem | head -n 15
ps aux --sort=-%cpu | head -n 15
Live monitoring:

bash
Copy
Edit
htop
Check system logs globally:

bash
Copy
Edit
journalctl -p 3 -xb   # All critical errors
dmesg | less          # Hardware & kernel errors
Would you like this playbook exported into a GitHub-ready Markdown format or a Bash script that automates all these checks for every service?







You said:
put above all together plus this #!/bin/bash
# Filename: system_audit.sh
# Description: Enterprise-grade diagnostic script for Linux server audit (Grafana, Docker, Loki, Fail2Ban, CPU, Mem, IO, Network)

echo "============================================"
echo "üìÖ Hostname: $(hostname)"
echo "üìç IP Address: $(hostname -I | awk '{print $1}')"
echo "üïí Date: $(date)"
echo "üñ•Ô∏è Uptime: $(uptime -p)"
echo "============================================"

echo -e "\nüîß Kernel & OS Info"
uname -a
lsb_release -a 2>/dev/null || cat /etc/os-release

echo -e "\nüß† Memory Usage:"
free -h

echo -e "\nüî• Top 10 CPU-consuming Processes:"
ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head -n 11

echo -e "\nüì¶ Disk Usage (Human Readable):"
df -hT

echo -e "\nüìÇ Largest Directories (top 10 in /):"
du -h --max-depth=1 / 2>/dev/null | sort -hr | head -n 10

echo -e "\nüß† Virtual Memory + Swap Activity:"
vmstat 1 3

echo -e "\nüîÑ I/O Stats (iostat):"
iostat -xz 1 3

echo -e "\nüåê Listening Ports:"
ss -tulpn | grep LISTEN

echo -e "\nüåê Outbound Connections (top talkers):"
netstat -ant | grep ESTABLISHED | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head -n 10

echo -e "\nüìã Recent Login Activity:"
last -a | head -n 10

echo -e "\nüìã Active Users:"
w

echo -e "\nüì¶ Docker Status:"
systemctl status docker --no-pager
echo -e "\nüì¶ Running Containers:"
docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"

echo -e "\nüìä Grafana Status:"
systemctl status grafana-server --no-pager

echo -e "\nüìÑ Grafana Logs (last 20 lines):"
journalctl -u grafana-server -n 20 --no-pager

echo -e "\nüìÅ Loki Service Status (if present):"
ps aux | grep -i loki | grep -v grep

echo -e "\nüõ°Ô∏è Fail2Ban Status:"
fail2ban-client status

echo -e "\nüö´ Fail2Ban Banned IPs for sshd:"
fail2ban-client status sshd 2>/dev/null | grep 'Banned IP list'

echo -e "\nüóÑÔ∏è Top 5 Log Files by Size (/var/log):"
find /var/log -type f -exec du -Sh {} + | sort -rh | head -n 5

echo -e "\nüìã Top 10 Running Services by Memory Usage:"
ps -eo pid,cmd,%mem,%cpu --sort=-%mem | head -n 11

echo -e "\n‚úÖ Audit Complete. Suggested follow-up: htop, journalctl, docker logs <container>, fail2ban-client, and grafana dashboards."  in one script


ChatGPT said:

Analyzed
python
Always show details

Copy
from ace_tools import display_dataframe_to_user
import os

# Define the full audit script with diagnostic playbook integration
script_content = """#!/bin/bash
# Filename: system_audit.sh
# Description: Enterprise-grade diagnostic script for Linux server audit (Grafana, Docker, Loki, Fail2Ban, CPU, Mem, IO, Network)

echo "============================================"
echo "üìÖ Hostname: $(hostname)"
echo "üìç IP Address: $(hostname -I | awk '{print $1}')"
echo "üïí Date: $(date)"
echo "üñ•Ô∏è Uptime: $(uptime -p)"
echo "============================================"

echo -e "\\nüîß Kernel & OS Info"
uname -a
lsb_release -a 2>/dev/null || cat /etc/os-release

echo -e "\\nüß† Memory Usage:"
free -h

echo -e "\\nüî• Top 10 CPU-consuming Processes:"
ps -eo pid,ppid,cmd,%mem,%cpu --sort=-%cpu | head -n 11

echo -e "\\nüì¶ Disk Usage (Human Readable):"
df -hT

echo -e "\\nüìÇ Largest Directories (top 10 in /):"
du -h --max-depth=1 / 2>/dev/null | sort -hr | head -n 10

echo -e "\\nüß† Virtual Memory + Swap Activity:"
vmstat 1 3

echo -e "\\nüîÑ I/O Stats (iostat):"
iostat -xz 1 3

echo -e "\\nüåê Listening Ports:"
ss -tulpn | grep LISTEN

echo -e "\\nüåê Outbound Connections (top talkers):"
netstat -ant | grep ESTABLISHED | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr | head -n 10

echo -e "\\nüìã Recent Login Activity:"
last -a | head -n 10

echo -e "\\nüìã Active Users:"
w

echo -e "\\nüì¶ Docker Status:"
systemctl status docker --no-pager
echo -e "\\nüì¶ Running Containers:"
docker ps --format "table {{.Names}}\\t{{.Image}}\\t{{.Status}}"

echo -e "\\nüìä Grafana Status:"
systemctl status grafana-server --no-pager

echo -e "\\nüìÑ Grafana Logs (last 20 lines):"
journalctl -u grafana-server -n 20 --no-pager

echo -e "\\nüìÅ Loki Service Status (if present):"
ps aux | grep -i loki | grep -v grep

echo -e "\\nüõ°Ô∏è Fail2Ban Status:"
fail2ban-client status

echo -e "\\nüö´ Fail2Ban Banned IPs for sshd:"
fail2ban-client status sshd 2>/dev/null | grep 'Banned IP list'

echo -e "\\nüóÑÔ∏è Top 5 Log Files by Size (/var/log):"
find /var/log -type f -exec du -Sh {} + | sort -rh | head -n 5

echo -e "\\nüìã Top 10 Running Services by Memory Usage:"
ps -eo pid,cmd,%mem,%cpu --sort=-%mem | head -n 11

echo -e "\\nüîé Additional Services Running:"
systemctl list-units --type=service --state=running | head -n 20

echo -e "\\nüö® Failed Services (if any):"
systemctl --failed

echo -e "\\n‚öôÔ∏è Services Enabled at Boot:"
systemctl list-unit-files --state=enabled | head -n 20

echo -e "\\nüìà Top CPU and Memory Processes (Live):"
ps aux --sort=-%mem | head -n 10
ps aux --sort=-%cpu | head -n 10

echo -e "\\n‚úÖ Audit Complete. Suggested follow-up: htop, journalctl, docker logs <container>, fail2ban-client, systemctl --failed."
"""

# Save the script to a file
script_path = "/mnt/data/system_audit_enterprise.sh"
with open(script_path, "w") as f:
    f.write(script_content)

script_path
Result
'/mnt/data/system_audit_enterprise.sh'
Your enhanced enterprise-grade Linux audit script is ready. You can download and execute it using the link below:

üìÑ Download system_audit_enterprise.sh

This version includes:

Full diagnostics for memory, disk, CPU, I/O, and network.

Deep checks on Docker, Grafana, Loki, and Fail2Ban.

Additional sections:

üß© All running services

üö® Failed services

‚öôÔ∏è Boot-enabled services

üìà Live CPU and memory hogs




















=====================================

GRAFANA , LOKI, FAIL2BAN LAB 

=====================================










Install and configure fail2ban
Your team is testing fail2ban to protect the sshd process in your server. You have decide to build a proof of concept (POC) of the system and tie it into your Grafana monitoring solution.


Solution
Solution
Install fail2ban

apt install -y fail2ban
Verify the version number of fail2ban client

fail2ban-client --version
Configure fail2ban for sshd jail.

vi /etc/fail2ban/jail.conf
#Uncomment [sshd] and enter the following lines under [sshd] section

     [sshd]
     enabled = true
     maxretry =  5
     findtime = 10
     bantime = 4h
#Check the rest of the file and ensure that there is no [sshd] config later in the file, delete or comment it out.

Review the configurations for apache and nginx to see what other types of jails are available in fail2ban.

Restart the service and verify that it is running properly.

systemctl restart fail2ban
systemctl status fail2ban --no-pager
Test the fail2ban is properly working by trying to connect back to the controlplane server from node01 as a fake account.

ssh node01
Run a for loop and keep trying to connect back to controlplane. You will have to hit enter on each password line until lockout occurs.

for i in {1..6}; do ssh invaliduser@controlplane; done
You will have to hit 'ctrl + c' to exit when it stops trying to connect to the far end.

Exit back to controlplane and check the logs and fail status.

Check the log of fail2ban

tail -20 /var/log/fail2ban.log
Verify that you see the banned IP.

fail2ban-client get sshd banned
Do you see the IP address that you expect? Why do you think that is?

Unban the ip address from the logs. You must manually enter the correct IP address below from the upper output

fail2ban-client set sshd unbanip <the IP from the logs>
Test that the unban has happened correctly.

ssh node01
Try to connect back to controlplane with a correct user, the root user.

ssh controlplane
Did you connect back correctly? If so, move on to the next part of the lab.










=========================









Install and configure Loki and Grafana
Install Grafana and Loki on the system.


Solution
Solution
Install the required packages and Grafana GPG key.

apt install -y apt-transport-https
apt install -y software-properties-common wget
sudo wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key
Add the Grafana repository.

echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
Finally, we're ready to install Grafana:

apt update
# Install the latest Enterprise release:
apt install -y grafana-enterprise
Now that you've installed Grafana, let's make sure it's started.

systemctl daemon-reload
systemctl start grafana-server
systemctl status grafana-server --no-pager
Verify that the server is serving on port 3000 (the default port). This may take up to 10 seconds to come back with the correct listening port.

systemctl status grafana-server --no-pager
ss -ntulp | grep grafana
ss -ntulp | grep 3000
We can also check that the external Web UI is available and change the default password.

https://1cbd62ba9005-10-244-21-178-3000.saci.r.killercoda.com

Change the password. Default User: admin and Password: admin

Feel free to look around in the Web UI and then continue on to the next part of the lab.

Next install Loki.

Create the directory where we will install Loki

mkdir /opt/loki
cd into that directory to set up the server

cd /opt/loki
Download and unpackage a current version of Loki

curl -O -L "https://github.com/grafana/loki/releases/download/v2.9.7/loki-linux-amd64.zip"
unzip "loki-linux-amd64.zip"
chmod a+x "loki-linux-amd64"

Copy over the loki config file from the /answers directory

cp /answers/loki-local-config.yaml /opt/loki
Copy over the loki.service file and restart the systemctl daemon so that Loki can run on your system.

cp /answers/loki.service /etc/systemd/system/loki.service
systemctl daemon-reload
Review the config file for Loki before starting the server.

cat /opt/loki/loki-local-config.yaml
Review the service file so that you are confident it is going to properly start Loki.

cat /etc/systemd/system/loki.service
Now that you've checked everything, start Loki daemon.

systemctl enable loki.service --now
Verify that Loki is running and exposing the proper port.

systemctl status loki.service --no-pager
ss -ntulp | grep 3100




===========================



Install and configure Promtail
In your reseach you find that the Promtail tool can push logs over to Loki in real time. Your tasks will be to deploy and configure Promtail to push logs into loki server.

Install Promtail.

Configure Promtail to push /var/log/auth.log and /var/log/syslog off the server to the Loki aggregator.

Ensure that Promtail is running correctly.


Solution
Solution
Create the directory where we will install Promtail.

mkdir /opt/promtail
Change to that directory and get ready to install promtail

cd /opt/promtail
Download and extract the executable

curl -O -L "https://github.com/grafana/loki/releases/download/v2.7.1/promtail-linux-amd64.zip"
unzip promtail-linux-amd64.zip 
Copy over the provided configuration and verify that it is pointing to the correct log files that you want to review.

cp /answers/promtail-local-config.yaml /opt/promtail
cat /opt/promtail/promtail-local-config.yaml
What do you notice about the configuration file? What are the scrape configs? What is the format that the file is in?

Setup the Promtail service configuration file for systemd to use to start the service

cp /answers/promtail.service /etc/systemd/system/promtail.service
cat /etc/systemd/system/promtail.service
Reload the systemd daemon and start the Promtail service

systemctl daemon-reload
systemctl enable promtail.service --now
Verify that the Promtail service is running on your system.

systemctl status promtail.service --no-pager
ps -ef | grep [p]romtail



============================================




Configure Dashboard and view logs
You've setup all the pieces, now you have to create a dashboard in Grafana and verify that everything is working end to end.

Log into Grafana (and change the password if you didn't do it earlier)

Create the datasource for Loki in the the Datasource page. URL = http://127.0.0.1:3100

Create a dashboard (import 13639) that shows the log files for your server.


Solution
Solution
Connect to Grafana and log in https://1cbd62ba9005-10-244-21-178-3000.saci.r.killercoda.com

Create the datasource for Loki in the the Datasource page. URL = http://127.0.0.1:3100

Import the dashboard 13639 to view logs.

Verify the dashboard is working properly.

Change the app field to fail2ban and re-test your failure condition from node01, from earlier. Do you see the logs passing through to Loki? Filter in loki on NOTICE. Do you see the ban and unban occurring?




=================================


















=============================

grafana dashboard, prometus end to end set up 
===========================







Install and configure Grafana
Your team has determined they need to monitor telemetry in your environment. You know that Grafana can do that as a visualization tool, so you plan to deploy it on a server as a daemon.

Deploy Grafana and ensure that it is running on your server.


Solution
Solution
Refer to the Grafana Docs for latest installation instructions.

Install the required packages and Grafana GPG key.

apt install -y apt-transport-https
apt install -y software-properties-common wget
wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key
Add the Grafana repository.

echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
Finally, we're ready to install Grafana:

apt update
# Install the latest Enterprise release:
apt install -y grafana-enterprise
Now that you've installed Grafana, let's make sure it's started.

systemctl daemon-reload
systemctl start grafana-server
systemctl status grafana-server --no-pager
Verify that the server is serving on port 3000 (the default port)

systemctl status grafana-server --no-pager
ss -ntulp | grep grafana
ss -ntulp | grep 3000
We can also check that the external Web UI is available and change the default password.

https://bcecf61935ad-10-244-20-197-3000.saci.r.killercoda.com

Change the password. Default User: admin and Password: admin

Feel free to look around in the Web UI and then continue on to the next part of the lab.





======================





Install and configure node exporter
Your team has decided that the data for Prometheus will be exposed via the tool Node Exporter. Your jobs is to get Node Exporter up and running on your server.

Install Node Exporter.

Verify Node Exporter is running and exposing port 9100.


Solution
Solution
Create the directory where we will install Node Exporter.
mkdir /opt/node_exporter
cd into that directory to set up the server.

cd /opt/node_exporter
Download and unpackage a current version of Node Exporter and move to the extracted folder.

wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
tar xvfz node_exporter-*.*-amd64.tar.gz
cd node_exporter-*.*-amd64
cp /answers/node_exporter.service /etc/systemd/system/node_exporter.service
Review the service file so that you are confident it is going to properly start Node Exporter.

cat /etc/systemd/system/node_exporter.service
Now that you've checked everything reload the systemd configuration manager and start Node Exporter daemon.

systemctl daemon-reload
systemctl enable node_exporter.service --now
Verify that Node Exporter is running and exposing the proper port.

systemctl status node_exporter --no-pager
sleep 2
curl http://localhost:9100/metrics
What data can you see exposed? Don't worry if it's not well formatted for you to process, it's in the correct configuration for Prometheus to scrape.


=============================




Install and configure Prometheus
In your reseach you find that the Prometheus can read telemetry data from Node Exporter. Your tasks will be to deploy and configure Prometheus to poll telemetry data from Node Exporter.

Install Prometheus.

Configure Prometheus to gather telemetry data.

Ensure that Prometheus is running correctly.


Solution
Solution
Setup your server for Prometheus install

useradd prometheus
mkdir /var/lib/prometheus
Download and extract Prometheus and required tools.

wget https://github.com/prometheus/prometheus/releases/download/v2.42.0-rc.0/prometheus-2.42.0-rc.0.linux-amd64.tar.gz  -P /tmp
tar xvfz /tmp/prometheus-2.42.0-rc.0.linux-amd64.tar.gz -C /var/lib/prometheus/ --strip-components=1
cp /var/lib/prometheus/prometheus /usr/bin/prometheus
Change ownership of /var/lib/prometheus so that prometheus user can start the service

chown -R prometheus:prometheus /var/lib/prometheus/
Create a directory and copy over the configuration for prometheus

mkdir /etc/prometheus
cp /answers/prometheus.yml /etc/prometheus/prometheus.yml
View the file and look at the configuration

cat /etc/prometheus/prometheus.yml
Copy over the prometheus.service file so that systemd can control and start prometheus

cp /answers/prometheus.service /etc/systemd/system/prometheus.service
View the file and look at the configuration

cat /etc/systemd/system/prometheus.service
Start the Prometheus Service

systemctl daemon-reload
systemctl start prometheus
Verify that Prometheus is working

systemctl status prometheus.service --no-pager
ps -ef | grep [p]rometheus
You can also access prometheus via this link:

https://bcecf61935ad-10-244-20-197-9090.saci.r.killercoda.com



















==============================










Configure Dashboard and view telemetry data
You've setup all the pieces, now you have to create a dashboard in Grafana and verify that everything is working end to end.

Log into Grafana (and change the password if you didn't do it earlier)

Create the datasource for Prometheus in the the Datasource page. URL = http://127.0.0.1:9090

Create a dashboard (import 159) that shows the telemetry information for your server.


Solution
Solution
Connect to Grafana and log in https://bcecf61935ad-10-244-20-197-3000.saci.r.killercoda.com

Create the datasource for Prometheus in the the Datasource page. URL = http://127.0.0.1:9090

Import the dashboard 159 to view the metric data.

Verify the dashboard is working properly.






apt install -y apt-transport-https
    7  apt install -y software-properties-common wget
    8  wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key
    9  echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
   10  apt update
   11  # Install the latest Enterprise release:
   12  apt install -y grafana-enterprise
   13  systemctl daemon-reload
   14  systemctl start grafana-server
   15  systemctl status grafana-server --no-pager
   16  ss -ntulp | grep grafana
   17  ss -ntulp | grep 3000
   18  mkdir /opt/node_exporter
   19  cd /opt/node_exporter
   20  wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
   21  tar xvfz node_exporter-*.*-amd64.tar.gz
   22  cd node_exporter-*.*-amd64
   23  cp /answers/node_exporter.service /etc/systemd/system/node_exporter.service
   24  cat /etc/systemd/system/node_exporter.service
   25  systemctl daemon-reload
   26  systemctl enable node_exporter.service --now
   27  systemctl status node_exporter --no-pager
   28  sleep 2
   29  curl http://localhost:9100/metrics
   30  useradd prometheus
   31  mkdir /var/lib/prometheus
   32  wget https://github.com/prometheus/prometheus/releases/download/v2.42.0-rc.0/prometheus-2.42.0-rc.0.linux-amd64.tar.gz  -P /tmp
   33  tar xvfz /tmp/prometheus-2.42.0-rc.0.linux-amd64.tar.gz -C /var/lib/prometheus/ --strip-components=1
   34  cp /var/lib/prometheus/prometheus /usr/bin/prometheus
   35  chown -R prometheus:prometheus /var/lib/prometheus/
   36  mkdir /etc/prometheus
   37  cp /answers/prometheus.yml /etc/prometheus/prometheus.yml
   38  cat /etc/prometheus/prometheus.yml
   39  cp /answers/prometheus.service /etc/systemd/system/prometheus.service
   40  cat /etc/systemd/system/prometheus.service
   41  systemctl daemon-reload
   42  systemctl start prometheus
   43  systemctl status prometheus.service --no-pager
   44  ps -ef | grep [p]rometheus
   45  history
controlplane:/opt/node_exporter/node_exporter-1.5.0.linux-amd64$ 





















==================













full blog post 



































### Building a Comprehensive Monitoring Stack: From Installation to Advanced Visualization

## Introduction

In today's complex IT environments, robust monitoring is not just a luxury‚Äîit's a necessity. Whether you're managing a small cluster of servers or a large-scale distributed system, having visibility into your infrastructure's performance, health, and behavior is critical for maintaining reliability and quickly resolving issues.

This comprehensive guide will walk you through building a complete monitoring stack using powerful open-source tools: Grafana for visualization, Prometheus for metrics collection, Node Exporter for system metrics, Alertmanager for notifications, and Loki for log aggregation. We'll also explore advanced visualization techniques to help you get the most out of your monitoring data.

By the end of this guide, you'll have a fully functional monitoring system capable of:

- Collecting and storing system metrics
- Visualizing performance data through customizable dashboards
- Alerting on potential issues before they become critical
- Aggregating and searching logs across your infrastructure
- Creating advanced visualizations for deeper insights


Let's dive in and build a monitoring system that gives you complete visibility into your infrastructure.

## Table of Contents

1. [Understanding the Monitoring Stack](#understanding-the-monitoring-stack)
2. [Installing and Configuring Grafana](#installing-and-configuring-grafana)
3. [Setting Up Node Exporter](#setting-up-node-exporter)
4. [Deploying Prometheus](#deploying-prometheus)
5. [Implementing Alertmanager](#implementing-alertmanager)
6. [Adding Loki for Log Aggregation](#adding-loki-for-log-aggregation)
7. [Configuring Basic Grafana Dashboards](#configuring-basic-grafana-dashboards)
8. [Advanced Visualization Techniques](#advanced-visualization-techniques)
9. [Creating Custom Queries and Panels](#creating-custom-queries-and-panels)
10. [Setting Up Alerting Rules](#setting-up-alerting-rules)
11. [Optimizing Your Monitoring Stack](#optimizing-your-monitoring-stack)
12. [Troubleshooting Common Issues](#troubleshooting-common-issues)
13. [Command Reference](#command-reference)
14. [Conclusion](#conclusion)


## Understanding the Monitoring Stack

Before we start installing components, let's understand how each piece fits into our monitoring architecture:

- **Grafana**: The visualization layer that creates dashboards from various data sources
- **Prometheus**: A time-series database that collects and stores metrics
- **Node Exporter**: An agent that exposes hardware and OS metrics for Prometheus to scrape
- **Alertmanager**: Handles alerts sent by Prometheus and routes them to receivers like email or Slack
- **Loki**: A log aggregation system designed to work seamlessly with Grafana and Prometheus


This architecture follows the modern monitoring paradigm of separating concerns: collection, storage, visualization, and alerting are handled by specialized components that excel at their specific tasks.

## Installing and Configuring Grafana

Grafana is our visualization layer, providing beautiful dashboards for our metrics and logs. Let's start by installing it.

### Step 1: Install Required Packages

First, we need to install some prerequisites:

```shellscript
apt update
apt install -y apt-transport-https software-properties-common wget curl gnupg2
```

### Step 2: Add Grafana Repository

Download the Grafana GPG key and add the repository:

```shellscript
wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key
echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
```

### Step 3: Install Grafana Enterprise

Update your package lists and install Grafana Enterprise:

```shellscript
apt update
apt install -y grafana-enterprise
```

### Step 4: Configure Grafana

Let's make some basic configuration changes to enhance security and performance. Edit the Grafana configuration file:

```shellscript
nano /etc/grafana/grafana.ini
```

Here are some recommended settings to adjust:

```ini
[server]
# Protocol (http, https, h2, socket)
protocol = https
# The ip address to bind to, empty will bind to all interfaces
http_addr = 
# The http port to use
http_port = 3000
# The public facing domain name used to access grafana from a browser
domain = your-domain.com
# Redirect to correct domain if host header does not match domain
enforce_domain = true

[security]
# disable creation of admin user on first start of grafana
disable_initial_admin_creation = false
# default admin user, created on startup
admin_user = admin
# default admin password, can be changed before first start of grafana, or in profile settings
admin_password = StrongPasswordHere
```

Save the file and exit.

### Step 5: Start and Enable Grafana Service

Start the Grafana server and enable it to start at boot:

```shellscript
systemctl daemon-reload
systemctl start grafana-server
systemctl enable grafana-server
systemctl status grafana-server --no-pager
```

### Step 6: Verify Connectivity

Check that Grafana is listening on port 3000:

```shellscript
ss -ntulp | grep grafana
ss -ntulp | grep 3000
```

You should now be able to access the Grafana web interface at `http://your-server-ip:3000`. The default login credentials are:

- Username: `admin`
- Password: `admin` (or the password you set in the configuration file)


You'll be prompted to change the password on first login if you didn't change it in the configuration.

## Setting Up Node Exporter

Node Exporter exposes system metrics like CPU usage, memory, disk I/O, and network statistics in a format Prometheus can scrape.

### Step 1: Create a System User for Node Exporter

For security reasons, let's create a dedicated user for running Node Exporter:

```shellscript
useradd --no-create-home --shell /bin/false node_exporter
```

### Step 2: Download and Extract Node Exporter

```shellscript
mkdir -p /opt/node_exporter
cd /opt/node_exporter
wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
tar xvfz node_exporter-*.*-amd64.tar.gz --strip-components=1
```

### Step 3: Set Proper Permissions

```shellscript
chown -R node_exporter:node_exporter /opt/node_exporter
```

### Step 4: Create a Systemd Service File

Create a service file for Node Exporter:

```shellscript
cat > /etc/systemd/system/node_exporter.service << 'EOF'
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/opt/node_exporter/node_exporter \
    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \
    --collector.systemd \
    --collector.processes \
    --web.listen-address=:9100

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
```

This configuration includes some useful flags:

- `--collector.filesystem.ignored-mount-points`: Ignores virtual filesystems
- `--collector.systemd`: Enables collection of systemd metrics
- `--collector.processes`: Enables collection of process metrics


### Step 5: Start and Enable Node Exporter Service

```shellscript
systemctl daemon-reload
systemctl start node_exporter
systemctl enable node_exporter
systemctl status node_exporter --no-pager
```

### Step 6: Verify Node Exporter is Running

Check the service status and verify metrics are being exposed:

```shellscript
curl http://localhost:9100/metrics | head
```

You should see metrics output beginning with comments explaining the format, followed by actual metrics.

## Deploying Prometheus

Prometheus is our time-series database that will collect and store metrics from Node Exporter and other sources.

### Step 1: Create a System User for Prometheus

```shellscript
useradd --no-create-home --shell /bin/false prometheus
```

### Step 2: Create Directories for Prometheus

```shellscript
mkdir -p /etc/prometheus /var/lib/prometheus
```

### Step 3: Download and Extract Prometheus

```shellscript
cd /tmp
wget https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
cd prometheus-*
```

### Step 4: Copy Prometheus Binaries and Configuration Files

```shellscript
cp prometheus promtool /usr/local/bin/
cp -r consoles/ console_libraries/ /etc/prometheus/
```

### Step 5: Create Prometheus Configuration File

Create a comprehensive configuration file for Prometheus:

```shellscript
cat > /etc/prometheus/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  scrape_timeout: 10s

  # Add labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'my-monitoring-system'

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - localhost:9093

# Load rules once and periodically evaluate them
rule_files:
  - "rules/*.yml"

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    static_configs:
      - targets: ['localhost:9100']
EOF
```

### Step 6: Create Rules Directory and Sample Alert Rule

```shellscript
mkdir -p /etc/prometheus/rules

cat > /etc/prometheus/rules/node_alerts.yml << 'EOF'
groups:
- name: node_alerts
  rules:
  - alert: HighCPULoad
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU load (instance {{ $labels.instance }})"
      description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

  - alert: HighMemoryLoad
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory load (instance {{ $labels.instance }})"
      description: "Memory load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

  - alert: HighDiskUsage
    expr: (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"} * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High disk usage (instance {{ $labels.instance }})"
      description: "Disk usage is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
EOF
```

### Step 7: Set Proper Permissions

```shellscript
chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus
chmod -R 775 /etc/prometheus /var/lib/prometheus
```

### Step 8: Create a Systemd Service File for Prometheus

```shellscript
cat > /etc/systemd/system/prometheus.service << 'EOF'
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file=/etc/prometheus/prometheus.yml \
    --storage.tsdb.path=/var/lib/prometheus/ \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries \
    --web.listen-address=0.0.0.0:9090 \
    --web.enable-lifecycle \
    --storage.tsdb.retention.time=15d

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
```

### Step 9: Start and Enable Prometheus Service

```shellscript
systemctl daemon-reload
systemctl start prometheus
systemctl enable prometheus
systemctl status prometheus --no-pager
```

### Step 10: Verify Prometheus is Running

Check the service status and access the web interface:

```shellscript
curl http://localhost:9090/-/healthy
```

You should receive a "Prometheus is Healthy." response. You can also access the Prometheus web interface at `http://your-server-ip:9090`.

## Implementing Alertmanager

Alertmanager handles alerts sent by Prometheus and routes them to various notification channels like email, Slack, or PagerDuty.

### Step 1: Create a System User for Alertmanager

```shellscript
useradd --no-create-home --shell /bin/false alertmanager
```

### Step 2: Create Directories for Alertmanager

```shellscript
mkdir -p /etc/alertmanager /var/lib/alertmanager
```

### Step 3: Download and Extract Alertmanager

```shellscript
cd /tmp
wget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz
tar xvfz alertmanager-*.tar.gz
cd alertmanager-*
```

### Step 4: Copy Alertmanager Binary

```shellscript
cp alertmanager amtool /usr/local/bin/
```

### Step 5: Create Alertmanager Configuration File

```shellscript
cat > /etc/alertmanager/alertmanager.yml << 'EOF'
global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtp.example.org:587'
  smtp_from: 'alertmanager@example.org'
  smtp_auth_username: 'alertmanager'
  smtp_auth_password: 'password'
  smtp_require_tls: true

route:
  group_by: ['alertname', 'job']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'email-notifications'

receivers:
- name: 'email-notifications'
  email_configs:
  - to: 'admin@example.org'
    send_resolved: true

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
EOF
```

Replace the SMTP and email settings with your actual email configuration.

### Step 6: Set Proper Permissions

```shellscript
chown -R alertmanager:alertmanager /etc/alertmanager /var/lib/alertmanager
chmod -R 775 /etc/alertmanager /var/lib/alertmanager
```

### Step 7: Create a Systemd Service File for Alertmanager

```shellscript
cat > /etc/systemd/system/alertmanager.service << 'EOF'
[Unit]
Description=Alertmanager
Wants=network-online.target
After=network-online.target

[Service]
User=alertmanager
Group=alertmanager
Type=simple
ExecStart=/usr/local/bin/alertmanager \
    --config.file=/etc/alertmanager/alertmanager.yml \
    --storage.path=/var/lib/alertmanager/ \
    --web.listen-address=0.0.0.0:9093

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
```

### Step 8: Start and Enable Alertmanager Service

```shellscript
systemctl daemon-reload
systemctl start alertmanager
systemctl enable alertmanager
systemctl status alertmanager --no-pager
```

### Step 9: Verify Alertmanager is Running

```shellscript
curl http://localhost:9093/-/healthy
```

You should receive an "OK" response. You can also access the Alertmanager web interface at `http://your-server-ip:9093`.

## Adding Loki for Log Aggregation

Loki is Grafana's log aggregation system, designed to be cost-effective and easy to operate.

### Step 1: Create a System User for Loki

```shellscript
useradd --no-create-home --shell /bin/false loki
```

### Step 2: Create Directories for Loki

```shellscript
mkdir -p /etc/loki /var/lib/loki
```

### Step 3: Download and Extract Loki

```shellscript
cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.8.0/loki-linux-amd64.zip
apt install -y unzip
unzip loki-linux-amd64.zip
```

### Step 4: Copy Loki Binary

```shellscript
cp loki-linux-amd64 /usr/local/bin/loki
chmod +x /usr/local/bin/loki
```

### Step 5: Create Loki Configuration File

```shellscript
cat > /etc/loki/loki-local-config.yaml << 'EOF'
auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096

common:
  path_prefix: /var/lib/loki
  storage:
    filesystem:
      chunks_directory: /var/lib/loki/chunks
      rules_directory: /var/lib/loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

ruler:
  alertmanager_url: http://localhost:9093

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
EOF
```

### Step 6: Set Proper Permissions

```shellscript
chown -R loki:loki /etc/loki /var/lib/loki
chmod -R 775 /etc/loki /var/lib/loki
```

### Step 7: Create a Systemd Service File for Loki

```shellscript
cat > /etc/systemd/system/loki.service << 'EOF'
[Unit]
Description=Loki
Wants=network-online.target
After=network-online.target

[Service]
User=loki
Group=loki
Type=simple
ExecStart=/usr/local/bin/loki -config.file=/etc/loki/loki-local-config.yaml

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
```

### Step 8: Start and Enable Loki Service

```shellscript
systemctl daemon-reload
systemctl start loki
systemctl enable loki
systemctl status loki --no-pager
```

### Step 9: Install Promtail to Ship Logs to Loki

Promtail is an agent that ships logs from the local system to Loki.

```shellscript
cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip
unzip promtail-linux-amd64.zip
cp promtail-linux-amd64 /usr/local/bin/promtail
chmod +x /usr/local/bin/promtail
```

### Step 10: Create Promtail Configuration File

```shellscript
mkdir -p /etc/promtail

cat > /etc/promtail/promtail-local-config.yaml << 'EOF'
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /var/lib/promtail/positions.yaml

clients:
  - url: http://localhost:3100/loki/api/v1/push

scrape_configs:
  - job_name: system
    static_configs:
    - targets:
        - localhost
      labels:
        job: varlogs
        __path__: /var/log/*log

  - job_name: syslog
    syslog:
      listen_address: 0.0.0.0:1514
      labels:
        job: syslog
    relabel_configs:
      - source_labels: ['__syslog_message_hostname']
        target_label: 'host'
EOF
```

### Step 11: Create Directories for Promtail

```shellscript
mkdir -p /var/lib/promtail
```

### Step 12: Create a Systemd Service File for Promtail

```shellscript
cat > /etc/systemd/system/promtail.service << 'EOF'
[Unit]
Description=Promtail
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
ExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-local-config.yaml

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
```

### Step 13: Start and Enable Promtail Service

```shellscript
systemctl daemon-reload
systemctl start promtail
systemctl enable promtail
systemctl status promtail --no-pager
```

## Configuring Basic Grafana Dashboards

Now that all components are installed, let's set up Grafana to visualize our metrics and logs.

### Step 1: Add Prometheus as a Data Source

1. Log into Grafana at `http://your-server-ip:3000`
2. Navigate to Configuration > Data Sources
3. Click "Add data source"
4. Select "Prometheus"
5. Set the URL to `http://localhost:9090`
6. Click "Save & Test"


### Step 2: Add Loki as a Data Source

1. Navigate to Configuration > Data Sources
2. Click "Add data source"
3. Select "Loki"
4. Set the URL to `http://localhost:3100`
5. Click "Save & Test"


### Step 3: Import Node Exporter Dashboard

1. Navigate to Dashboards > Import
2. Enter dashboard ID `1860` (Node Exporter Full dashboard)
3. Select your Prometheus data source
4. Click "Import"


### Step 4: Import Loki Dashboard

1. Navigate to Dashboards > Import
2. Enter dashboard ID `12019` (Loki Dashboard)
3. Select your Loki data source
4. Click "Import"


### Step 5: Create a System Overview Dashboard

1. Navigate to Dashboards > New Dashboard
2. Click "Add new panel"
3. In the query editor, select Prometheus as the data source
4. Add the following queries to create a system overview:


For CPU Usage:

```plaintext
100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

For Memory Usage:

```plaintext
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100
```

For Disk Usage:

```plaintext
(node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"} * 100
```

For Network Traffic:

```plaintext
rate(node_network_receive_bytes_total[5m])
rate(node_network_transmit_bytes_total[5m])
```

5. Customize each panel with appropriate titles, units, and thresholds
6. Save the dashboard


## Advanced Visualization Techniques

Now let's explore some advanced visualization techniques in Grafana to get more insights from our data.

### Creating Multi-Series Graphs

Multi-series graphs allow you to compare related metrics on the same panel:

1. Create a new panel
2. Add multiple queries, for example:

1. `rate(node_disk_read_bytes_total[5m])`
2. `rate(node_disk_written_bytes_total[5m])`



3. Use the "Transform" tab to rename and organize your series
4. In the "Field" tab, set appropriate units (bytes/sec) and customize colors


### Using Heatmaps for Distribution Analysis

Heatmaps are excellent for visualizing the distribution of values over time:

1. Create a new panel and select the "Heatmap" visualization
2. Use a histogram query, for example:

```plaintext
sum by (le) (rate(node_cpu_seconds_total{mode!="idle"}[5m]))
```


3. In the "Field" tab, adjust the color scheme to highlight important patterns


### Creating Composite Panels with Stat and Gauge

Combine different visualization types to create rich, informative panels:

1. Create a new row in your dashboard
2. Add multiple "Stat" panels showing current values:

1. CPU: `100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)`
2. Memory: `(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100`
3. Disk: `(1 - (sum(node_filesystem_free_bytes) / sum(node_filesystem_size_bytes))) * 100`



3. Add "Gauge" panels with thresholds (green < 70%, yellow 70-85%, red > 85%)
4. Add "Time Series" panels showing historical trends


### Using Variables for Dynamic Dashboards

Variables make your dashboards interactive and reusable:

1. Navigate to Dashboard Settings > Variables
2. Add a new "Query" variable named "instance":

```plaintext
label_values(node_uname_info, instance)
```


3. Add a "Multi-value" option to allow selecting multiple instances
4. Use this variable in your queries:

```plaintext
100 - (avg by (instance) (irate(node_cpu_seconds_total{instance=~"$instance",mode="idle"}[5m])) * 100)
```


5. Add a dashboard dropdown to select different instances


### Creating Log Panels with Loki

Integrate log data with your metrics for better troubleshooting:

1. Create a new panel and select "Logs" visualization
2. Select Loki as the data source
3. Add a query like:

```plaintext
{job="varlogs"} |= "error"
```


4. Use the "Split By" option to organize logs by source
5. Add a "Log Volume" panel to show log frequency over time


## Creating Custom Queries and Panels

Let's create some advanced custom queries and specialized panels.

### Service Health Overview

Create a panel that shows the health of key services:

1. Create a new "Stat" panel
2. Add queries for each service:

```plaintext
sum(up{job="node_exporter"})
sum(up{job="prometheus"})
sum(up{job="loki"})
```


3. Use the "Transform" tab to join the results
4. Set thresholds (0 = red, 1 = green)
5. Use value mappings (0 = "Down", 1 = "Up")


### Resource Saturation Dashboard

Create a dashboard focused on resource saturation:

1. Create panels for CPU, Memory, Disk, and Network saturation
2. For CPU saturation, use:

```plaintext
sum by (mode) (rate(node_cpu_seconds_total[5m]))
```


3. For Memory pressure, use:

```plaintext
node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes
node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes
```


4. For Disk I/O pressure:

```plaintext
rate(node_disk_io_time_seconds_total[5m]) * 100
```


5. For Network saturation:

```plaintext
rate(node_network_receive_bytes_total[5m]) / node_network_speed_bytes
```




### Custom PromQL for Advanced Metrics

Create advanced metrics using PromQL:

1. CPU steal time (important for cloud VMs):

```plaintext
avg by (instance) (irate(node_cpu_seconds_total{mode="steal"}[5m]) * 100)
```


2. Disk space prediction (when will disks fill up):

```plaintext
predict_linear(node_filesystem_free_bytes{fstype!~"tmpfs|fuse.lxcfs|squashfs"}[1h], 24 * 3600 * 7)
```


3. Memory fragmentation:

```plaintext
node_memory_Active_bytes / node_memory_MemTotal_bytes
```




## Setting Up Alerting Rules

Let's set up comprehensive alerting to be notified of potential issues.

### Step 1: Configure Alerting in Grafana

1. Navigate to Alerting > Notification channels
2. Add channels for email, Slack, or other notification methods
3. Configure the notification template


### Step 2: Create Alert Rules in Grafana

1. Edit a panel where you want to add an alert
2. Click the "Alert" tab
3. Configure conditions, for example:

1. "Avg() of query(A, 5m, now) is above 80"



4. Set evaluation interval and for duration
5. Add notifications and message


### Step 3: Create Advanced Prometheus Alert Rules

Edit the `/etc/prometheus/rules/node_alerts.yml` file to add more sophisticated alerts:

```yaml
groups:
- name: node_alerts
  rules:
  # Existing alerts...

  - alert: ContextSwitchingHigh
    expr: rate(node_context_switches_total[5m]) > 10000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High context switching (instance {{ $labels.instance }})"
      description: "Context switching is high, which might indicate CPU contention\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

  - alert: SystemdServiceFailed
    expr: node_systemd_unit_state{state="failed"} == 1
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Systemd service failed (instance {{ $labels.instance }})"
      description: "Service {{ $labels.name }} has entered failed state\n  LABELS: {{ $labels }}"

  - alert: DiskWillFillIn24Hours
    expr: predict_linear(node_filesystem_free_bytes{fstype!~"tmpfs|fuse.lxcfs|squashfs"}[1h], 24 * 3600) < 0
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Disk will fill in 24 hours (instance {{ $labels.instance }})"
      description: "Disk {{ $labels.device }} will fill in 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
```

Reload Prometheus configuration:

```shellscript
curl -X POST http://localhost:9090/-/reload
```

## Optimizing Your Monitoring Stack

Let's optimize our monitoring stack for better performance and resource usage.

### Prometheus Optimization

Edit `/etc/prometheus/prometheus.yml` to add scrape configurations:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  scrape_timeout: 10s
  # Add this line to limit resource usage
  query_log_file: /var/lib/prometheus/query.log

# Add storage settings
storage:
  tsdb:
    # Increase retention period
    retention.time: 30d
    # Enable WAL compression
    wal_compression: true
    # Set min block duration
    min_block_duration: 2h
    # Set max block duration
    max_block_duration: 4h
```

### Loki Optimization

Edit `/etc/loki/loki-local-config.yaml` to optimize for resource usage:

```yaml
limits_config:
  # Increase ingestion rate
  ingestion_rate_mb: 10
  # Increase ingestion burst size
  ingestion_burst_size_mb: 20
  # Set max query length
  max_query_length: 721h
  # Set max entries limit per query
  max_entries_limit_per_query: 10000
  # Set max query parallelism
  max_query_parallelism: 32
```

### Grafana Optimization

Edit `/etc/grafana/grafana.ini` to optimize Grafana:

```ini
[dashboards]
# Reduce dashboard versions
versions_to_keep = 10

[users]
# Disable user signup
allow_sign_up = false

[auth.anonymous]
# Enable anonymous access if needed
enabled = false

[metrics]
# Enable metrics endpoint
enabled = true

[unified_alerting]
# Enable unified alerting
enabled = true
```

## Troubleshooting Common Issues

Here are solutions to common issues you might encounter:

### Prometheus Not Scraping Metrics

If Prometheus isn't scraping metrics:

1. Check if the target is up in Prometheus UI (Status > Targets)
2. Verify firewall settings: `ufw status` and ensure port 9100 is open
3. Check Node Exporter logs: `journalctl -u node_exporter`
4. Verify Prometheus configuration: `promtool check config /etc/prometheus/prometheus.yml`


### Grafana Can't Connect to Data Sources

If Grafana can't connect to data sources:

1. Check if Prometheus is running: `systemctl status prometheus`
2. Verify network connectivity: `curl http://localhost:9090/-/healthy`
3. Check Grafana logs: `journalctl -u grafana-server`
4. Verify data source configuration in Grafana UI


### Alertmanager Not Sending Notifications

If alerts aren't being sent:

1. Check Alertmanager status: `systemctl status alertmanager`
2. Verify Prometheus is configured to use Alertmanager: Check `alerting` section in `prometheus.yml`
3. Check Alertmanager logs: `journalctl -u alertmanager`
4. Test email configuration: `amtool --alertmanager.url=http://localhost:9093 alert add alertname=TestAlert severity=warning`


### Loki Not Receiving Logs

If Loki isn't receiving logs:

1. Check Promtail status: `systemctl status promtail`
2. Verify Loki is running: `systemctl status loki`
3. Check Promtail logs: `journalctl -u promtail`
4. Verify Promtail configuration: `cat /etc/promtail/promtail-local-config.yaml`


## Command Reference

Here's a comprehensive reference of all commands used in this guide:

```shellscript
# Grafana Installation
apt update
apt install -y apt-transport-https software-properties-common wget curl gnupg2
wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key
echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
apt update
apt install -y grafana-enterprise
systemctl daemon-reload
systemctl start grafana-server
systemctl enable grafana-server
systemctl status grafana-server --no-pager
ss -ntulp | grep grafana

# Node Exporter Installation
useradd --no-create-home --shell /bin/false node_exporter
mkdir -p /opt/node_exporter
cd /opt/node_exporter
wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
tar xvfz node_exporter-*.*-amd64.tar.gz --strip-components=1
chown -R node_exporter:node_exporter /opt/node_exporter
systemctl daemon-reload
systemctl start node_exporter
systemctl enable node_exporter
systemctl status node_exporter --no-pager
curl http://localhost:9100/metrics | head

# Prometheus Installation
useradd --no-create-home --shell /bin/false prometheus
mkdir -p /etc/prometheus /var/lib/prometheus
cd /tmp
wget https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
cd prometheus-*
cp prometheus promtool /usr/local/bin/
cp -r consoles/ console_libraries/ /etc/prometheus/
mkdir -p /etc/prometheus/rules
chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus
chmod -R 775 /etc/prometheus /var/lib/prometheus
systemctl daemon-reload
systemctl start prometheus
systemctl enable prometheus
systemctl status prometheus --no-pager
curl http://localhost:9090/-/healthy

# Alertmanager Installation
useradd --no-create-home --shell /bin/false alertmanager
mkdir -p /etc/alertmanager /var/lib/alertmanager
cd /tmp
wget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz
tar xvfz alertmanager-*.tar.gz
cd alertmanager-*
cp alertmanager amtool /usr/local/bin/
chown -R alertmanager:alertmanager /etc/alertmanager /var/lib/alertmanager
chmod -R 775 /etc/alertmanager /var/lib/alertmanager
systemctl daemon-reload
systemctl start alertmanager
systemctl enable alertmanager
systemctl status alertmanager --no-pager
curl http://localhost:9093/-/healthy

# Loki Installation
useradd --no-create-home --shell /bin/false loki
mkdir -p /etc/loki /var/lib/loki
cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.8.0/loki-linux-amd64.zip
apt install -y unzip
unzip loki-linux-amd64.zip
cp loki-linux-amd64 /usr/local/bin/loki
chmod +x /usr/local/bin/loki
chown -R loki:loki /etc/loki /var/lib/loki
chmod -R 775 /etc/loki /var/lib/loki
systemctl daemon-reload
systemctl start loki
systemctl enable loki
systemctl status loki --no-pager

# Promtail Installation
cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip
unzip promtail-linux-amd64.zip
cp promtail-linux-amd64 /usr/local/bin/promtail
chmod +x /usr/local/bin/promtail
mkdir -p /etc/promtail /var/lib/promtail
systemctl daemon-reload
systemctl start promtail
systemctl enable promtail
systemctl status promtail --no-pager

# Reloading Prometheus Configuration
curl -X POST http://localhost:9090/-/reload

# Testing Alertmanager
amtool --alertmanager.url=http://localhost:9093 alert add alertname=TestAlert severity=warning
```

## Conclusion

Congratulations! You've built a comprehensive monitoring stack that provides deep visibility into your infrastructure. This system gives you:

- Real-time metrics collection and visualization
- Log aggregation and analysis
- Alerting for potential issues
- Advanced visualization capabilities for deeper insights


This monitoring stack is not just a tool‚Äîit's a critical part of your infrastructure that helps ensure reliability, performance, and security. By following this guide, you've created a system that can grow with your needs and adapt to your changing infrastructure.

Remember that monitoring is an ongoing process. Regularly review your dashboards, refine your metrics collection, adjust your alerting thresholds, and update your visualization techniques as you learn more about your systems' behavior.

With this foundation in place, you're well-equipped to maintain a healthy, performant infrastructure and quickly respond to issues before they impact your users.









ON THE JOB REFEREENCE OF ALL THE COMMANDS USE FOR THE ABOVE PROJECT VERY SUCCESSFUL 












grep 3000
tcp   LISTEN 0      4096                                 *:3000             *:*          
~ > systemctl status node_exporter --no-pager                                                  05:45:48 PM
Unit node_exporter.service could not be found.
~ > useradd --no-create-home --shell /bin/false node_exporter                                  05:46:34 PM
useradd: Permission denied.
useradd: cannot lock /etc/passwd; try again later.
~ > sudo useradd --no-create-home --shell /bin/false node_exporter                             05:47:07 PM
~ > mkdir -p /opt/node_exporter                                                                05:47:18 PM
cd /opt/node_exporter
wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
tar xvfz node_exporter-*.*-amd64.tar.gz --strip-components=1
mkdir: cannot create directory ‚Äò/opt/node_exporter‚Äô: Permission denied
cd: no such file or directory: /opt/node_exporter
--2025-05-17 17:47:39--  https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
Resolving github.com (github.com)... 140.82.114.3
Connecting to github.com (github.com)|140.82.114.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9524057/fc1630e0-8913-427f-94ba-4131d3ed96c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T174743Z&X-Amz-Expires=300&X-Amz-Signature=206fb9632b304dc3e0a9e814988c184d81400512a4ee167f5958542cee730bc6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dnode_exporter-1.5.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream [following]
--2025-05-17 17:47:39--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/9524057/fc1630e0-8913-427f-94ba-4131d3ed96c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T174743Z&X-Amz-Expires=300&X-Amz-Signature=206fb9632b304dc3e0a9e814988c184d81400512a4ee167f5958542cee730bc6&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dnode_exporter-1.5.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 10181045 (9.7M) [application/octet-stream]
Saving to: ‚Äònode_exporter-1.5.0.linux-amd64.tar.gz‚Äô

node_exporter-1.5.0.linux- 100%[=======================================>]   9.71M  7.48MB/s    in 1.3s    

2025-05-17 17:47:41 (7.48 MB/s) - ‚Äònode_exporter-1.5.0.linux-amd64.tar.gz‚Äô saved [10181045/10181045]

node_exporter-1.5.0.linux-amd64/LICENSE
node_exporter-1.5.0.linux-amd64/NOTICE
node_exporter-1.5.0.linux-amd64/node_exporter
~ > sudo mkdir -p /opt/node_exporter                                                           05:47:41 PM
sudo cd /opt/node_exporter
sudo wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
sudo tar xvfz node_exporter-*.*-amd64.tar.gz --strip-components=1
sudo: cd: command not found
sudo: "cd" is a shell built-in command, it cannot be run directly.
sudo: the -s option may be used to run a privileged shell.
sudo: the -D option may be used to run a command in a specific directory.
--2025-05-17 17:48:52--  https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/9524057/fc1630e0-8913-427f-94ba-4131d3ed96c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T174856Z&X-Amz-Expires=300&X-Amz-Signature=c065556b3a1b7ab60d836b7475351fcd56e5ee058ca23c2fa275f1f2d30dbfb1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dnode_exporter-1.5.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream [following]
--2025-05-17 17:48:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/9524057/fc1630e0-8913-427f-94ba-4131d3ed96c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T174856Z&X-Amz-Expires=300&X-Amz-Signature=c065556b3a1b7ab60d836b7475351fcd56e5ee058ca23c2fa275f1f2d30dbfb1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dnode_exporter-1.5.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 10181045 (9.7M) [application/octet-stream]
Saving to: ‚Äònode_exporter-1.5.0.linux-amd64.tar.gz‚Äô

node_exporter-1.5.0.linux- 100%[=======================================>]   9.71M  10.3MB/s    in 0.9s    

2025-05-17 17:48:54 (10.3 MB/s) - ‚Äònode_exporter-1.5.0.linux-amd64.tar.gz‚Äô saved [10181045/10181045]

node_exporter-1.5.0.linux-amd64/LICENSE
node_exporter-1.5.0.linux-amd64/NOTICE
node_exporter-1.5.0.linux-amd64/node_exporter
~ > chown -R node_exporter:node_exporter /opt/node_exporter                                    05:48:54 PM
chown: cannot read directory '/opt/node_exporter': Permission denied
~ > sudo chown -R node_exporter:node_exporter /opt/node_exporter                               05:49:07 PM
~ > cat > /etc/systemd/system/node_exporter.service << 'EOF'                                        05:49:15 PM
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/opt/node_exporter/node_exporter \
    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \
    --collector.systemd \
    --collector.processes \
    --web.listen-address=:9100

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
zsh: permission denied: /etc/systemd/system/node_exporter.service
~ > sudo cat > /etc/systemd/system/node_exporter.service << 'EOF'                                   05:50:36 PM
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/opt/node_exporter/node_exporter \
    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \
    --collector.systemd \
    --collector.processes \
    --web.listen-address=:9100

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
zsh: permission denied: /etc/systemd/system/node_exporter.service
~ > sudo su -                                                                                       05:50:45 PM
‚îè‚îÅ(Message from Kali developers)
‚îÉ
‚îÉ This is a minimal installation of Kali Linux, you likely
‚îÉ want to install supplementary tools. Learn how:
‚îÉ ‚áí https://www.kali.org/docs/troubleshooting/common-minimum-setup/
‚îÉ
‚îó‚îÅ(Run: ‚Äútouch ~/.hushlogin‚Äù to hide this message)
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# cat > /etc/systemd/system/node_exporter.service << 'EOF'
[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/opt/node_exporter/node_exporter \
    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \
    --collector.systemd \
    --collector.processes \
    --web.listen-address=:9100

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# systemctl daemon-reload
systemctl start node_exporter
systemctl enable node_exporter
systemctl status node_exporter --no-pager
Created symlink '/etc/systemd/system/multi-user.target.wants/node_exporter.service' ‚Üí '/etc/systemd/system/node_exporter.service'.
‚óè node_exporter.service - Node Exporter
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; preset: disabled)
     Active: activating (auto-restart) (Result: exit-code) since Sat 2025-05-17 17:51:21 UTC; 628ms ago
 Invocation: 9a66b778776245429fd09e60e19acba4
   Main PID: 12349 (code=exited, status=203/EXEC)
   Mem peak: 1.9M
        CPU: 34ms

May 17 17:51:21 kaligbrs systemd[1]: node_exporter.service: Main process exited, code=exited, status=203/EXEC
May 17 17:51:21 kaligbrs systemd[1]: node_exporter.service: Failed with result 'exit-code'.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# curl http://localhost:9100/metrics | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (7) Failed to connect to localhost port 9100 after 0 ms: Could not connect to server
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# systemctl status prometheus --no-pager
Unit prometheus.service could not be found.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# curl http://localhost:9100/metrics | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (7) Failed to connect to localhost port 9100 after 1 ms: Could not connect to server
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# ls -l /opt/node_exporter/node_exporter

ls: cannot access '/opt/node_exporter/node_exporter': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[~]
‚îî‚îÄ# cd /opt
curl -LO https://github.com/prometheus/node_exporter/releases/download/v1.8.0/node_exporter-1.8.0.linux-amd64.tar.gz

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100 10.1M  100 10.1M    0     0  7696k      0  0:00:01  0:00:01 --:--:-- 17.0M
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# tar -xzf node_exporter-1.8.0.linux-amd64.tar.gz
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# mv node_exporter-1.8.0.linux-amd64 node_exporter
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# chmod +x /opt/node_exporter/node_exporter/node_exporter
chmod: cannot access '/opt/node_exporter/node_exporter/node_exporter': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# systemctl daemon-reload
systemctl restart node_exporter
systemctl status node_exporter --no-pager
‚óè node_exporter.service - Node Exporter
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; preset: disabled)
     Active: active (running) since Sat 2025-05-17 17:56:20 UTC; 46ms ago
 Invocation: ddd0c49c6465411daa2297a37338c4b0
   Main PID: 15119 ((exporter))
      Tasks: 1 (limit: 9152)
     Memory: 1.6M (peak: 1.8M)
        CPU: 14ms
     CGroup: /system.slice/node_exporter.service
             ‚îî‚îÄ15119 "(exporter)"

May 17 17:56:20 kaligbrs systemd[1]: Started node_exporter.service - Node Exporter.
May 17 17:56:20 kaligbrs (exporter)[15119]: node_exporter.service: Unable to locate executable '/opt/nod‚Ä¶rectory
May 17 17:56:20 kaligbrs (exporter)[15119]: node_exporter.service: Failed at step EXEC spawning /opt/nod‚Ä¶rectory
May 17 17:56:20 kaligbrs systemd[1]: node_exporter.service: Main process exited, code=exited, status=203/EXEC
May 17 17:56:20 kaligbrs systemd[1]: node_exporter.service: Failed with result 'exit-code'.
Hint: Some lines were ellipsized, use -l to show in full.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# curl http://localhost:9100/metrics | head

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (7) Failed to connect to localhost port 9100 after 0 ms: Could not connect to server
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# mv node_exporter-1.8.0.linux-amd64 node_exporter

mv: cannot stat 'node_exporter-1.8.0.linux-amd64': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# ls -l /opt/node_exporter/node_exporter

ls: cannot access '/opt/node_exporter/node_exporter': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# chmod +x /opt/node_exporter/node_exporter  ‚úÖ

chmod: cannot access '/opt/node_exporter/node_exporter': No such file or directory
chmod: cannot access '‚úÖ': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# ls                                    
containerd  loki  microsoft  node_exporter  node_exporter-1.8.0.linux-amd64.tar.gz  promtail
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt]
‚îî‚îÄ# cd node_exporter                             
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# ls
node_exporter-1.8.0.linux-amd64
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# chmod +x /opt/node_exporter/node_exporter                

chmod: cannot access '/opt/node_exporter/node_exporter': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# nano /etc/systemd/system/node_exporter.service

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# systemctl daemon-reload
systemctl restart node_exporter
systemctl status node_exporter --no-pager

‚óè node_exporter.service - Node Exporter
     Loaded: loaded (/etc/systemd/system/node_exporter.service; enabled; preset: disabled)
     Active: active (running) since Sat 2025-05-17 18:00:27 UTC; 39ms ago
 Invocation: c98225a1a7fb4a2c8e3d984b1e8d2324
   Main PID: 17425 ((exporter))
      Tasks: 1 (limit: 9152)
     Memory: 1.6M (peak: 1.8M)
        CPU: 15ms
     CGroup: /system.slice/node_exporter.service
             ‚îî‚îÄ17425 "(exporter)"

May 17 18:00:27 kaligbrs systemd[1]: Started node_exporter.service - Node Exporter.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# cat /etc/systemd/system/node_exporter.service

[Unit]
Description=Node Exporter
Wants=network-online.target
After=network-online.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/opt/node_exporter/node_exporter-1.8.0.linux-amd64/node_exporter \
    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \
    --collector.systemd \
    --collector.processes \
    --web.listen-address=:9100

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# curl http://localhost:9100/metrics | head

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 0
go_gc_duration_seconds{quantile="0.25"} 0
go_gc_duration_seconds{quantile="0.5"} 0
go_gc_duration_seconds{quantile="0.75"} 0
go_gc_duration_seconds{quantile="1"} 0
go_gc_duration_seconds_sum 0
go_gc_duration_seconds_count 0
# HELP go_goroutines Number of goroutines that currently exist.
100 56993    0 56993    0     0   179k      0 --:--:-- --:--:-- --:--:--  179k
curl: (23) Failure writing output to destination, passed 810 returned 351
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# history 
    1  pwd
    2  ls
    3  usr
    4  users
    5  user
    6  exit
    7  docker network ls
    8  exit
    9  apt install -y apt-transport-https software-properties-common wget
   10  \napt install -y grafana-enterprise
   11  sudo wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key\necho "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list\n
   12  apt update
   13  chmod 644 /usr/share/keyrings/grafana.key
   14  echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee /etc/apt/sources.list.d/grafana.list\n
   15  apt update
   16  apt update\napt install -y grafana-enterprise
   17  systemctl daemon-reload
   18  systemctl enable grafana-server
   19  systemctl start grafana-server
   20  systemctl status grafana-server --no-pager
   21  ss -ntulp | grep grafana\nss -ntulp | grep 3000
   22  mkdir /opt/loki && cd /opt/loki
   23  curl -O -L "https://github.com/grafana/loki/releases/download/v2.9.7/loki-linux-amd64.zip"\nunzip loki-linux-amd64.zip\nchmod +x loki-linux-amd64
   24  cp /answers/loki-local-config.yaml /opt/loki\ncp /answers/loki.service /etc/systemd/system/loki.service
   25  systemctl daemon-reload
   26  systemctl enable loki.service --now
   27  systemctl status loki.service --no-pager
   28  ss -ntulp | grep 3100
   29  cat > /opt/loki/loki-local-config.yaml << 'EOF'\nauth_enabled: false\n\nserver:\n  http_listen_port: 3100\n  grpc_listen_port: 9096\n\ncommon:\n  path_prefix: /opt/loki\n  storage:\n    filesystem:\n      chunks_directory: /opt/loki/chunks\n      rules_directory: /opt/loki/rules\n  replication_factor: 1\n  ring:\n    instance_addr: 127.0.0.1\n    kvstore:\n      store: inmemory\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: index_\n        period: 24h\n\nruler:\n  alertmanager_url: http://localhost:9093\n\n# By default, Loki will send anonymous, but uniquely-identifiable usage and configuration\n# analytics to Grafana Labs. These statistics are sent to https://stats.grafana.org/\n# Statistics help us better understand how Loki is used, and they show us performance\n# levels for most users. This helps us prioritize features and documentation.\n# For more information on what's sent, look at\n# https://github.com/grafana/loki/blob/main/pkg/usagestats/stats.go\n# Refer to the buildReport method to see what goes into a report.\n#\n# If you would like to disable reporting, uncomment the following lines:\nanalytics:\n  reporting_enabled: false\nEOF
   30  cat > /etc/systemd/system/loki.service << 'EOF'\n[Unit]\nDescription=Loki service\nAfter=network.target\n\n[Service]\nType=simple\nUser=root\nExecStart=/opt/loki/loki-linux-amd64 -config.file=/opt/loki/loki-local-config.yaml\nRestart=on-failure\nWorkingDirectory=/opt/loki\n\n[Install]\nWantedBy=multi-user.target\nEOF
   31  mkdir -p /opt/loki/chunks\nmkdir -p /opt/loki/rules
   32  systemctl daemon-reload
   33  systemctl enable loki.service --now
   34  systemctl status loki.service --no-pager
   35  ss -ntulp | grep 3100
   36  mkdir /opt/promtail && cd /opt/promtail
   37  curl -O -L "https://github.com/grafana/loki/releases/download/v2.7.1/promtail-linux-amd64.zip"\nunzip promtail-linux-amd64.zip\nchmod +x promtail-linux-amd64
   38  cp /answers/promtail-local-config.yaml /opt/promtail\ncp /answers/promtail.service /etc/systemd/system/promtail.service
   39  systemctl daemon-reload\nsystemctl enable promtail.service --now\nsystemctl status promtail.service --no-pager\nps -ef | grep [p]romtail
   40  cat > /opt/promtail/promtail-local-config.yaml << 'EOF'\nserver:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /opt/promtail/positions.yaml\n\nclients:\n  - url: http://localhost:3100/loki/api/v1/push\n\nscrape_configs:\n  - job_name: system\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: varlogs\n          __path__: /var/log/*log\n\n  - job_name: syslog\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: syslog\n          __path__: /var/log/syslog*\n\n  - job_name: auth\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: auth\n          __path__: /var/log/auth.log*\n\n  - job_name: apache\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: apache\n          __path__: /var/log/apache2/*log\n\n  - job_name: nginx\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: nginx\n          __path__: /var/log/nginx/*log\nEOF
   41  cat > /etc/systemd/system/promtail.service << 'EOF'\n[Unit]\nDescription=Promtail service\nAfter=network.target\n\n[Service]\nType=simple\nUser=root\nExecStart=/opt/promtail/promtail-linux-amd64 -config.file=/opt/promtail/promtail-local-config.yaml\nRestart=on-failure\nWorkingDirectory=/opt/promtail\n\n[Install]\nWantedBy=multi-user.target\nEOF
   42  systemctl daemon-reload\n\n# Enable and start Promtail\nsystemctl enable promtail.service --now\n\n# Check the status\nsystemctl status promtail.service --no-pager\n\n# Verify Promtail is running\nps -ef | grep [p]romtail
   43  systemctl start loki.service\n\n# Check Loki status\nsystemctl status loki.service --no-pager\n\n# Verify Loki is listening on port 3100\nss -ntulp | grep 3100
   44  btop
   45  cd
   46  ls
   47  apt install -y git curl\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\nsource ~/.bashrc\nnvm install 20\nnvm use 20
   48  clear
   49  exit
   50  cat > /etc/systemd/system/node_exporter.service << 'EOF'\n[Unit]\nDescription=Node Exporter\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=node_exporter\nGroup=node_exporter\nType=simple\nExecStart=/opt/node_exporter/node_exporter \\n    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \\n    --collector.systemd \\n    --collector.processes \\n    --web.listen-address=:9100\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\nEOF
   51  systemctl daemon-reload\nsystemctl start node_exporter\nsystemctl enable node_exporter\nsystemctl status node_exporter --no-pager
   52  curl http://localhost:9100/metrics | head
   53  systemctl status prometheus --no-pager
   54  curl http://localhost:9100/metrics | head
   55  ls -l /opt/node_exporter/node_exporter\n
   56  cd /opt\ncurl -LO https://github.com/prometheus/node_exporter/releases/download/v1.8.0/node_exporter-1.8.0.linux-amd64.tar.gz\n
   57  tar -xzf node_exporter-1.8.0.linux-amd64.tar.gz
   58  mv node_exporter-1.8.0.linux-amd64 node_exporter
   59  chmod +x /opt/node_exporter/node_exporter/node_exporter
   60  systemctl daemon-reload\nsystemctl restart node_exporter\nsystemctl status node_exporter --no-pager
   61  curl http://localhost:9100/metrics | head\n
   62  mv node_exporter-1.8.0.linux-amd64 node_exporter\n
   63  ls -l /opt/node_exporter/node_exporter\n
   64  chmod +x /opt/node_exporter/node_exporter  ‚úÖ\n
   65  ls
   66  cd node_exporter
   67  ls
   68  chmod +x /opt/node_exporter/node_exporter\n
   69  nano /etc/systemd/system/node_exporter.service\n
   70  systemctl daemon-reload\nsystemctl restart node_exporter\nsystemctl status node_exporter --no-pager\n
   71  cat /etc/systemd/system/node_exporter.service\n
   72  curl http://localhost:9100/metrics | head\n
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# useradd --no-create-home --shell /bin/false prometheus
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# mkdir -p /etc/prometheus /var/lib/prometheus
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/opt/node_exporter]
‚îî‚îÄ# cd /tmp
wget https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
cd prometheus-*
--2025-05-17 18:02:51--  https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.linux-amd64.tar.gz
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/6838921/67c76e0b-84d6-4839-9b5a-0bffc648fab9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T180254Z&X-Amz-Expires=300&X-Amz-Signature=18abf81558a663a75c64240168cd99879d31b421d9a175637fa18e46c6e48321&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dprometheus-2.42.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream [following]
--2025-05-17 18:02:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/6838921/67c76e0b-84d6-4839-9b5a-0bffc648fab9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T180254Z&X-Amz-Expires=300&X-Amz-Signature=18abf81558a663a75c64240168cd99879d31b421d9a175637fa18e46c6e48321&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dprometheus-2.42.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 90588428 (86M) [application/octet-stream]
Saving to: ‚Äòprometheus-2.42.0.linux-amd64.tar.gz‚Äô

prometheus-2.42.0.linux-amd 100%[===========================================>]  86.39M  19.7MB/s    in 4.8s    

2025-05-17 18:02:56 (18.0 MB/s) - ‚Äòprometheus-2.42.0.linux-amd64.tar.gz‚Äô saved [90588428/90588428]

prometheus-2.42.0.linux-amd64/
prometheus-2.42.0.linux-amd64/NOTICE
prometheus-2.42.0.linux-amd64/consoles/
prometheus-2.42.0.linux-amd64/consoles/index.html.example
prometheus-2.42.0.linux-amd64/consoles/node.html
prometheus-2.42.0.linux-amd64/consoles/prometheus-overview.html
prometheus-2.42.0.linux-amd64/consoles/node-disk.html
prometheus-2.42.0.linux-amd64/consoles/prometheus.html
prometheus-2.42.0.linux-amd64/consoles/node-overview.html
prometheus-2.42.0.linux-amd64/consoles/node-cpu.html
prometheus-2.42.0.linux-amd64/console_libraries/
prometheus-2.42.0.linux-amd64/console_libraries/menu.lib
prometheus-2.42.0.linux-amd64/console_libraries/prom.lib
prometheus-2.42.0.linux-amd64/prometheus.yml
prometheus-2.42.0.linux-amd64/LICENSE
prometheus-2.42.0.linux-amd64/promtool
prometheus-2.42.0.linux-amd64/prometheus
cd: string not in pwd: prometheus-2.42.0.linux-amd64
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cp prometheus promtool /usr/local/bin/
cp -r consoles/ console_libraries/ /etc/prometheus/
cp: cannot stat 'prometheus': No such file or directory
cp: cannot stat 'promtool': No such file or directory
cp: cannot stat 'consoles/': No such file or directory
cp: cannot stat 'console_libraries/': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# ls -l /tmp

total 88468
-rw------- 1 gbrs          gbrs          0 May 17 17:33 config-err-Syl0cv
drwxr-xr-x 4 node_exporter docker      180 Feb  1  2023 prometheus-2.42.0.linux-amd64
-rw-r----- 1 root          root   90588428 Feb  1  2023 prometheus-2.42.0.linux-amd64.tar.gz
drwx------ 2 gbrs          gbrs         60 May 17 17:34 ssh-eIxzWGwdF1jN
drwx------ 3 root          root         60 May 17 17:34 systemd-private-f27952923fb5451187a669d17c4a02cb-colord.service-DEjd7h                                                                                                  
drwx------ 3 root          root         60 May 17 17:33 systemd-private-f27952923fb5451187a669d17c4a02cb-grafana-server.service-8n9Q8C                                                                                          
drwx------ 3 root          root         60 May 17 17:33 systemd-private-f27952923fb5451187a669d17c4a02cb-haveged.service-OLTxy7                                                                                                 
drwx------ 3 root          root         60 May 17 17:33 systemd-private-f27952923fb5451187a669d17c4a02cb-ModemManager.service-xX1CQn                                                                                            
drwx------ 3 root          root         60 May 17 17:33 systemd-private-f27952923fb5451187a669d17c4a02cb-polkit.service-gW9o5q                                                                                                  
drwx------ 3 root          root         60 May 17 17:33 systemd-private-f27952923fb5451187a669d17c4a02cb-rsyslog.service-4vXMWZ                                                                                                 
drwx------ 3 root          root         60 May 17 17:33 systemd-private-f27952923fb5451187a669d17c4a02cb-systemd-logind.service-LnQfHp                                                                                          
drwx------ 3 root          root         60 May 17 17:34 systemd-private-f27952923fb5451187a669d17c4a02cb-upower.service-4syhyM                                                                                                  
drwx------ 2 gbrs          gbrs         40 May 17 17:34 Temp-12ac9e08-ce15-45f2-9878-1cd4a0f9afe7
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cd /tmp/prometheus-2.42.0.linux-amd64

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# cp prometheus promtool /usr/local/bin/

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# ls -l /usr/local/bin/prometheus /usr/local/bin/promtool

-rwxr-x--- 1 root root 118789213 May 17 18:05 /usr/local/bin/prometheus
-rwxr-x--- 1 root root 110468077 May 17 18:05 /usr/local/bin/promtool
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# cp -r consoles/ console_libraries/ /etc/prometheus/

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# ls /etc/prometheus/consoles
ls /etc/prometheus/console_libraries

index.html.example  node-disk.html  node-overview.html  prometheus-overview.html
node-cpu.html       node.html       prometheus.html
menu.lib  prom.lib
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# cat > /etc/prometheus/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  scrape_timeout: 10s

  # Add labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'my-monitoring-system'

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - localhost:9093

# Load rules once and periodically evaluate them
rule_files:
  - "rules/*.yml"

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    static_configs:
      - targets: ['localhost:9100']
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# mkdir -p /etc/prometheus/rules               
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# cat > /etc/prometheus/rules/node_alerts.yml << 'EOF'
groups:
- name: node_alerts
  rules:
  - alert: HighCPULoad
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU load (instance {{ $labels.instance }})"
      description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

  - alert: HighMemoryLoad
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory load (instance {{ $labels.instance }})"
      description: "Memory load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

  - alert: HighDiskUsage
    expr: (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"} * 100 > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High disk usage (instance {{ $labels.instance }})"
      description: "Disk usage is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus
chmod -R 775 /etc/prometheus /var/lib/prometheus
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# cat > /etc/systemd/system/prometheus.service << 'EOF'
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file=/etc/prometheus/prometheus.yml \
    --storage.tsdb.path=/var/lib/prometheus/ \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries \
    --web.listen-address=0.0.0.0:9090 \
    --web.enable-lifecycle \
    --storage.tsdb.retention.time=15d

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# systemctl daemon-reload
systemctl start prometheus
systemctl enable prometheus
systemctl status prometheus --no-pager
Created symlink '/etc/systemd/system/multi-user.target.wants/prometheus.service' ‚Üí '/etc/systemd/system/prometheus.service'.
‚óè prometheus.service - Prometheus
     Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; preset: disabled)
     Active: activating (auto-restart) (Result: exit-code) since Sat 2025-05-17 18:08:15 UTC; 31ms ago
 Invocation: f20edd1c8bef4f75b904d255031f5468
    Process: 21528 ExecStart=/usr/local/bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/var/lib/prometheus/ --web.console.templates=/etc/prometheus/consoles --web.console.libraries=/etc/prometheus/console_libraries --web.listen-address=0.0.0.0:9090 --web.enable-lifecycle --storage.tsdb.retention.time=15d (code=exited, status=203/EXEC)
   Main PID: 21528 (code=exited, status=203/EXEC)
   Mem peak: 1.9M
        CPU: 16ms

May 17 18:08:15 kaligbrs systemd[1]: prometheus.service: Failed with result 'exit-code'.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# ls -l /usr/local/bin/prometheus

-rwxr-x--- 1 root root 118789213 May 17 18:05 /usr/local/bin/prometheus
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# chmod 755 /usr/local/bin/prometheus

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# ls -l /usr/local/bin/prometheus

-rwxr-xr-x 1 root root 118789213 May 17 18:05 /usr/local/bin/prometheus
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# systemctl daemon-reload
systemctl restart prometheus
systemctl status prometheus --no-pager

‚óè prometheus.service - Prometheus
     Loaded: loaded (/etc/systemd/system/prometheus.service; enabled; preset: disabled)
     Active: active (running) since Sat 2025-05-17 18:10:11 UTC; 40ms ago
 Invocation: 791991ebb0a34acfa91bdeff4ed6a0b4
   Main PID: 22758 ((ometheus))
      Tasks: 1 (limit: 9152)
     Memory: 1.5M (peak: 1.6M)
        CPU: 14ms
     CGroup: /system.slice/prometheus.service
             ‚îî‚îÄ22758 "(ometheus)"

May 17 18:10:11 kaligbrs systemd[1]: Started prometheus.service - Prometheus.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# curl http://localhost:9090/metrics | head

  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 0.000337162
go_gc_duration_seconds{quantile="0.25"} 0.000485039
go_gc_duration_seconds{quantile="0.5"} 0.000644075
go_gc_duration_seconds{quantile="0.75"} 0.000905515
go_gc_duration_seconds{quantile="1"} 0.005280419
go_gc_duration_seconds_sum 0.00765221
go_gc_duration_seconds_count 5
# HELP go_goroutines Number of goroutines that currently exist.
100 32768    0 32768    0     0  5288k      0 --:--:-- --:--:-- --:--:-- 5333k
curl: (23) Failure writing output to destination, passed 2048 returned 0
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# curl http://localhost:9090/-/healthy
Prometheus Server is Healthy.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# useradd --no-create-home --shell /bin/false alertmanager
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# mkdir -p /etc/alertmanager /var/lib/alertmanager
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/prometheus-2.42.0.linux-amd64]
‚îî‚îÄ# cd /tmp
wget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz 
tar xvfz alertmanager-*.tar.gz
cd alertmanager-*
--2025-05-17 18:11:35--  https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/11452538/bc7618fc-1d75-4ed8-9c68-b4b0ab032f29?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T181138Z&X-Amz-Expires=300&X-Amz-Signature=b2845e6159b638b5d5bdea579ba97b72020ba41f9afda3b09a0bc922761bfb37&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dalertmanager-0.25.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream [following]
--2025-05-17 18:11:35--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/11452538/bc7618fc-1d75-4ed8-9c68-b4b0ab032f29?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T181138Z&X-Amz-Expires=300&X-Amz-Signature=b2845e6159b638b5d5bdea579ba97b72020ba41f9afda3b09a0bc922761bfb37&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dalertmanager-0.25.0.linux-amd64.tar.gz&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 29254678 (28M) [application/octet-stream]
Saving to: ‚Äòalertmanager-0.25.0.linux-amd64.tar.gz‚Äô

alertmanager-0.25.0.linux-a 100%[===========================================>]  27.90M  14.6MB/s    in 1.9s    

2025-05-17 18:11:37 (14.6 MB/s) - ‚Äòalertmanager-0.25.0.linux-amd64.tar.gz‚Äô saved [29254678/29254678]

alertmanager-0.25.0.linux-amd64/
alertmanager-0.25.0.linux-amd64/alertmanager.yml
alertmanager-0.25.0.linux-amd64/NOTICE
alertmanager-0.25.0.linux-amd64/amtool
alertmanager-0.25.0.linux-amd64/alertmanager
alertmanager-0.25.0.linux-amd64/LICENSE
cd: string not in pwd: alertmanager-0.25.0.linux-amd64
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cp alertmanager amtool /usr/local/bin/
cp: cannot stat 'alertmanager': No such file or directory
cp: cannot stat 'amtool': No such file or directory
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cd /tmp/alertmanager-0.25.0.linux-amd64

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# cp alertmanager amtool /usr/local/bin/

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# chmod +x /usr/local/bin/alertmanager /usr/local/bin/amtool

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# ls -l /usr/local/bin/alertmanager /usr/local/bin/amtool

-rwxr-x--- 1 root root 34546840 May 17 18:14 /usr/local/bin/alertmanager
-rwxr-x--- 1 root root 27906085 May 17 18:14 /usr/local/bin/amtool
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# cat > /etc/alertmanager/alertmanager.yml << 'EOF'
global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtp.example.org:587'
  smtp_from: 'alertmanager@example.org'
  smtp_auth_username: 'alertmanager'
  smtp_auth_password: 'password'
  smtp_require_tls: true

route:
  group_by: ['alertname', 'job']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'email-notifications'

receivers:
- name: 'email-notifications'
  email_configs:
  - to: 'admin@example.org'
    send_resolved: true

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# chown -R alertmanager:alertmanager /etc/alertmanager /var/lib/alertmanager
chmod -R 775 /etc/alertmanager /var/lib/alertmanager
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# cat > /etc/systemd/system/alertmanager.service << 'EOF'
[Unit]
Description=Alertmanager
Wants=network-online.target
After=network-online.target

[Service]
User=alertmanager
Group=alertmanager
Type=simple
ExecStart=/usr/local/bin/alertmanager \
    --config.file=/etc/alertmanager/alertmanager.yml \
    --storage.path=/var/lib/alertmanager/ \
    --web.listen-address=0.0.0.0:9093

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# systemctl daemon-reload
systemctl start alertmanager
systemctl enable alertmanager
systemctl status alertmanager --no-pager
Created symlink '/etc/systemd/system/multi-user.target.wants/alertmanager.service' ‚Üí '/etc/systemd/system/alertmanager.service'.
‚óè alertmanager.service - Alertmanager
     Loaded: loaded (/etc/systemd/system/alertmanager.service; enabled; preset: disabled)
     Active: activating (auto-restart) (Result: exit-code) since Sat 2025-05-17 18:16:25 UTC; 31ms ago
 Invocation: 0612936cff444059b046ef4f76774ad9
    Process: 26094 ExecStart=/usr/local/bin/alertmanager --config.file=/etc/alertmanager/alertmanager.yml --storage.path=/var/lib/alertmanager/ --web.listen-address=0.0.0.0:9093 (code=exited, status=203/EXEC)
   Main PID: 26094 (code=exited, status=203/EXEC)
   Mem peak: 1.9M
        CPU: 22ms
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# curl http://localhost:9093/-/healthy
curl: (7) Failed to connect to localhost port 9093 after 0 ms: Could not connect to server
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# chmod 755 /usr/local/bin/alertmanager /usr/local/bin/amtool

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# systemctl daemon-reload
systemctl restart alertmanager
systemctl status alertmanager --no-pager

‚óè alertmanager.service - Alertmanager
     Loaded: loaded (/etc/systemd/system/alertmanager.service; enabled; preset: disabled)
     Active: active (running) since Sat 2025-05-17 18:18:38 UTC; 40ms ago
 Invocation: 90233b8e47a148a3aead9f74c9dc68ec
   Main PID: 27393 ((tmanager))
      Tasks: 1 (limit: 9152)
     Memory: 1.6M (peak: 1.7M)
        CPU: 13ms
     CGroup: /system.slice/alertmanager.service
             ‚îî‚îÄ27393 "(tmanager)"

May 17 18:18:38 kaligbrs systemd[1]: Started alertmanager.service - Alertmanager.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# curl http://localhost:9093/-/healthy

OK                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# cat /etc/prometheus/prometheus.yml 
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  scrape_timeout: 10s

  # Add labels to any time series or alerts when communicating with
  # external systems (federation, remote storage, Alertmanager).
  external_labels:
    monitor: 'my-monitoring-system'

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - localhost:9093

# Load rules once and periodically evaluate them
rule_files:
  - "rules/*.yml"

# A scrape configuration containing exactly one endpoint to scrape:
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node_exporter'
    static_configs:
      - targets: ['localhost:9100']
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# curl -X POST http://localhost:9090/-/reload

                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp/alertmanager-0.25.0.linux-amd64]
‚îî‚îÄ# cd /etc/   
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/etc]
‚îî‚îÄ# ls                                                     
adduser.conf              fail2ban             libnl-3          pam.conf           skel
aide                      firebird             libpaper.d       pam.d              smartd.conf
alertmanager              firefox-esr          libvirt          paperspecs         smartmontools
aliases                   fonts                lightdm          passwd             smi.conf
alternatives              freetds              lighttpd         passwd-            snmp
apache2                   fstab                locale.alias     pcp                snort
apparmor                  fuse.conf            locale.conf      pcp.conf           speech-dispatcher
apparmor.d                gai.conf             locale.gen       pcp.env            sqlmap
apt                       geoclue              localtime        perl               ssh
arp-scan                  ghostscript          logcheck         php                ssl
audit                     glvnd                login.defs       phpldapadmin       sslsplit
avahi                     gnome-system-tools   logrotate.conf   plymouth           strongswan.conf
bash.bashrc               gophish              logrotate.d      polkit-1           strongswan.d
bash_completion           gprofng.rc           lvm              postgresql         stunnel
bash_completion.d         grafana              lynis            postgresql-common  subgid
bindresvport.blacklist    groff                macchanger       powershell-empire  subgid-
binfmt.d                  group                machine-id       ppp                subuid
bluetooth                 group-               magic            profile            subuid-
ca-certificates           grub.d               magic.mime       profile.d          subversion
ca-certificates.conf      gshadow              mailname         prometheus         sudo.conf
cczerc                    gshadow-             mail.rc          protocols          sudoers
chatscripts               gss                  manpath.config   proxychains4.conf  sudoers.d
chkrootkit                gtk-2.0              matplotlibrc     pulse              sudo_logsrvd.conf
chromium                  gtk-3.0              mdevctl.d        python2.7          supercat
chromium.d                guymager             menu             python3            sv
cifs-utils                gvm                  menu-methods     python3.12         swtpm-localca.conf
cloud                     hdparm.conf          mime.types       python3.13         swtpm-localca.options
colord                    host.conf            minicom          qemu-ifdown        swtpm_setup.conf
console-setup             hostname             miredo           qemu-ifup          sysctl.d
containerd                hosts                miredo.conf      radcli             sysstat
cracklib                  hosts.allow          mke2fs.conf      rc0.d              systemd
credstore                 hosts.deny           ModemManager     rc1.d              terminfo
credstore.encrypted       idmapd.conf          modprobe.d       rc2.d              texmf
cron.d                    ifplugd              modules          rc3.d              theHarvester
cron.daily                ImageMagick-7        modules-load.d   rc4.d              tightvncserver.conf
cron.hourly               inetsim              monit            rc5.d              timidity
cron.monthly              init.d               mosquitto        rc6.d              tmpfiles.d
crontab                   initramfs-tools      motd             rcS.d              tor
cron.weekly               inputrc              mtab             reader.conf.d      ts.conf
cron.yearly               insserv.conf.d       mtools.conf      rearj.cfg          ucf.conf
cryptsetup-initramfs      ipp-usb              mysql            redis              udev
cryptsetup-nuke-password  ipsec.conf           nanorc           redsocks.conf      udisks2
crypttab                  ipsec.d              needrestart      request-key.conf   ufw
cupshelpers               ipsec.secrets        netconfig        request-key.d      unicornscan
dbus-1                    iptables             netsniff-ng      resolv.conf        updatedb.conf
dconf                     iscsi                network          responder          update-motd.d
debconf.conf              issue                NetworkManager   rkhunter.conf      UPower
debian_version            issue.net            networks         rmt                usb_modeswitch.conf
default                   java-21-openjdk      nfs.conf         rpc                usb_modeswitch.d
deluser.conf              john                 nfs.conf.d       rsyslog.conf       vconsole.conf
depmod.d                  kali-menu            nftables.conf    rsyslog.d          vdpau_wrapper.cfg
dhcp                      kernel               nginx            runit              vim
dhcpcd.conf               kernel-img.conf      nikto.conf       samba              vpnc
dictionaries-common       keyutils             nsisconf.nsh     sane.d             vulkan
dnf                       kismet               nsswitch.conf    sasl2              wgetrc
dns2tcpd.conf             ldap                 ODBCDataSources  scalpel            wireshark
doc-base                  ld-musl-x86_64.d     odbc.ini         screenrc           wpa_supplicant
docker                    ld-musl-x86_64.path  odbcinst.ini     sddm.conf.d        X11
dpkg                      ld.so.cache          oinkmaster.conf  searchsploit_rc    xattr.conf
e2scrub.conf              ld.so.conf           openal           security           xdg
eac                       ld.so.conf.d         OpenCL           selinux            xfce4
emacs                     legion.conf          openni2          sensors3.conf      xml
email-addresses           letsencrypt          opensc           sensors.d          xrdp
environment               libao.conf           openvas          services           zabbix
environment.d             libaudit.conf        openvpn          sgml               zsh
ethertypes                libblockdev          opt              shadow             zsh_command_not_found
ettercap                  libccid_Info.plist   os-release       shadow-
exim4                     libibverbs.d         PackageKit       shells
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/etc]
‚îî‚îÄ#         
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/etc]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/etc]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/etc]
‚îî‚îÄ# useradd --no-create-home --shell /bin/false loki
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/etc]
‚îî‚îÄ# cd /var/lib/   
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/var/lib]
‚îî‚îÄ# ls
AccountsService       doc-base        iscsi           notus              python         systemd
aide                  docker          ispell          openvas            reaver         tex-common
alertmanager          dpkg            ldap            openvpn            redis          texmf
apache2               emacsen-common  letsencrypt     os-prober          rkhunter       tor
apt                   exim4           libvirt         PackageKit         rpm            tpm
aspell                fail2ban        lightdm         pam                samba          ucf
autopsy               gems            logrotate       pcp                saned          udisks2
bluetooth             geoclue         machines        php                sgml-base      unicornscan
ca-certificates-java  ghostscript     man-db          plocate            shells.state   upower
colord                git             misc            plymouth           smartmontools  usb_modeswitch
command-not-found     gophish         mosquitto       polkit-1           snmp           vim
containerd            grafana         mysql           portables          snort          xfonts
dbus                  grub            NetworkManager  postgresql         strongswan     xkb
dhcpcd                gvm             nfs             powershell-empire  stunnel4       xml-core
dictionaries-common   ieee-data       nginx           private            sudo
dnf                   inetsim         nikto           prometheus         swtpm-localca
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/var/lib]
‚îî‚îÄ# mkdir -p /etc/loki /var/lib/loki
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/var/lib]
‚îî‚îÄ# cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.8.0/loki-linux-amd64.zip
apt install -y unzip
unzip loki-linux-amd64.zip
--2025-05-17 18:22:50--  https://github.com/grafana/loki/releases/download/v2.8.0/loki-linux-amd64.zip
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/129717717/5a83a124-473b-4e43-8f55-044b0d59f414?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T182253Z&X-Amz-Expires=300&X-Amz-Signature=9b98d5cda59476b4264e18e14c441a850b4d00ad5b367ac5aa8cb8195c204a82&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dloki-linux-amd64.zip&response-content-type=application%2Foctet-stream [following]
--2025-05-17 18:22:50--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/129717717/5a83a124-473b-4e43-8f55-044b0d59f414?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T182253Z&X-Amz-Expires=300&X-Amz-Signature=9b98d5cda59476b4264e18e14c441a850b4d00ad5b367ac5aa8cb8195c204a82&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dloki-linux-amd64.zip&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 18854582 (18M) [application/octet-stream]
Saving to: ‚Äòloki-linux-amd64.zip‚Äô

loki-linux-amd64.zip        100%[===========================================>]  17.98M  7.85MB/s    in 2.3s    

2025-05-17 18:22:53 (7.85 MB/s) - ‚Äòloki-linux-amd64.zip‚Äô saved [18854582/18854582]

unzip is already the newest version (6.0-29).
The following packages were automatically installed and are no longer required:
  libfuse3-3  liblbfgsb0  libpoppler145  python3.12-tk
Use 'apt autoremove' to remove them.

Summary:
  Upgrading: 0, Installing: 0, Removing: 0, Not Upgrading: 481
Archive:  loki-linux-amd64.zip
  inflating: loki-linux-amd64        
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cp loki-linux-amd64 /usr/local/bin/loki
chmod +x /usr/local/bin/loki
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cat > /etc/loki/loki-local-config.yaml << 'EOF'
auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096

common:
  path_prefix: /var/lib/loki
  storage:
    filesystem:
      chunks_directory: /var/lib/loki/chunks
      rules_directory: /var/lib/loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index: 
        prefix: index_
        period: 24h

ruler:
  alertmanager_url: http://localhost:9093

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# chown -R loki:loki /etc/loki /var/lib/loki
chmod -R 775 /etc/loki /var/lib/loki
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cat > /etc/systemd/system/loki.service << 'EOF'
[Unit]
Description=Loki
Wants=network-online.target
After=network-online.target

[Service]
User=loki
Group=loki
Type=simple
ExecStart=/usr/local/bin/loki -config.file=/etc/loki/loki-local-config.yaml

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# systemctl daemon-reload
systemctl start loki
systemctl enable loki
systemctl status loki --no-pager
‚óè loki.service - Loki
     Loaded: loaded (/etc/systemd/system/loki.service; enabled; preset: disabled)
     Active: active (running) since Sat 2025-05-17 17:33:15 UTC; 50min ago
 Invocation: 1582f4ef6cf543afaf6771241f98e672
   Main PID: 771 (loki-linux-amd6)
      Tasks: 10 (limit: 9152)
     Memory: 143.1M (peak: 148.6M)
        CPU: 1min 48.372s
     CGroup: /system.slice/loki.service
             ‚îî‚îÄ771 /opt/loki/loki-linux-amd64 -config.file=/opt/loki/loki-local-config.yaml

May 17 18:23:25 kaligbrs loki-linux-amd64[771]: level=info ts=2025-05-17T18:23:25.494373541Z caller=compa‚Ä¶_20221
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: ts=2025-05-17T18:23:25.494415586Z caller=spanlogger.go:86‚Ä¶cache"
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: ts=2025-05-17T18:23:25.49444978Z caller=spanlogger.go:86‚Ä¶8.808¬µs
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: level=info ts=2025-05-17T18:23:25.494456753Z caller=table‚Ä¶ount=1
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: level=info ts=2025-05-17T18:23:25.494487224Z caller=compa‚Ä¶_20221
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: level=info ts=2025-05-17T18:23:25.494580939Z caller=compa‚Ä¶_20220
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: ts=2025-05-17T18:23:25.494656175Z caller=spanlogger.go:86‚Ä¶cache"
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: ts=2025-05-17T18:23:25.494700425Z caller=spanlogger.go:8‚Ä¶7.004¬µs
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: level=info ts=2025-05-17T18:23:25.494708711Z caller=table‚Ä¶ount=1
May 17 18:23:25 kaligbrs loki-linux-amd64[771]: level=info ts=2025-05-17T18:23:25.49474866Z caller=compac‚Ä¶_20220
Hint: Some lines were ellipsized, use -l to show in full.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip
unzip promtail-linux-amd64.zip
cp promtail-linux-amd64 /usr/local/bin/promtail
chmod +x /usr/local/bin/promtail
--2025-05-17 18:24:15--  https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/129717717/f785f051-768f-485b-ad78-d7d83f26fb97?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T182417Z&X-Amz-Expires=300&X-Amz-Signature=f7f3fc066e11de78957d607d3c78eb617491a97a11696caa415d506e5c653fc5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dpromtail-linux-amd64.zip&response-content-type=application%2Foctet-stream [following]
--2025-05-17 18:24:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/129717717/f785f051-768f-485b-ad78-d7d83f26fb97?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250517%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250517T182417Z&X-Amz-Expires=300&X-Amz-Signature=f7f3fc066e11de78957d607d3c78eb617491a97a11696caa415d506e5c653fc5&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dpromtail-linux-amd64.zip&response-content-type=application%2Foctet-stream
Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...
Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 26044171 (25M) [application/octet-stream]
Saving to: ‚Äòpromtail-linux-amd64.zip‚Äô

promtail-linux-amd64.zip    100%[===========================================>]  24.84M  9.04MB/s    in 2.7s    

2025-05-17 18:24:18 (9.04 MB/s) - ‚Äòpromtail-linux-amd64.zip‚Äô saved [26044171/26044171]

Archive:  promtail-linux-amd64.zip
  inflating: promtail-linux-amd64    
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# mkdir -p /etc/promtail
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cat > /etc/promtail/promtail-local-config.yaml << 'EOF'
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /var/lib/promtail/positions.yaml

clients:
  - url: http://localhost:3100/loki/api/v1/push

scrape_configs:
  - job_name: system
    static_configs:
    - targets:
        - localhost
      labels:
        job: varlogs
        __path__: /var/log/*log

  - job_name: syslog
    syslog:
      listen_address: 0.0.0.0:1514
      labels:
        job: syslog
    relabel_configs:
      - source_labels: ['__syslog_message_hostname']
        target_label: 'host'
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# mkdir -p /var/lib/promtail
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# cat > /etc/systemd/system/promtail.service << 'EOF'
[Unit]
Description=Promtail
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
ExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-local-config.yaml

Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target
EOF
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# systemctl daemon-reload
systemctl start promtail
systemctl enable promtail
systemctl status promtail --no-pager
‚óè promtail.service - Promtail
     Loaded: loaded (/etc/systemd/system/promtail.service; enabled; preset: disabled)
     Active: active (running) since Sat 2025-05-17 17:33:15 UTC; 52min ago
 Invocation: 42166bae6eaf4bcd8d008bef1984f600
   Main PID: 773 (promtail-linux-)
      Tasks: 12 (limit: 9152)
     Memory: 94.4M (peak: 96.4M)
        CPU: 3min 55.506s
     CGroup: /system.slice/promtail.service
             ‚îî‚îÄ773 /opt/promtail/promtail-linux-amd64 -config.file=/opt/promtail/promtail-local-config.yaml

May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: ts=2025-05-17T17:33:24.876555227Z caller=log.go:168 l‚Ä¶ce:0}"
May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: level=info ts=2025-05-17T17:33:24.876641902Z caller=t‚Ä¶ss.log
May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: level=info ts=2025-05-17T17:33:24.876657929Z caller=t‚Ä¶or.log
May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: ts=2025-05-17T17:33:24.876688756Z caller=log.go:168 l‚Ä¶ce:0}"
May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: ts=2025-05-17T17:33:24.876720634Z caller=log.go:168 l‚Ä¶ce:0}"
May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: level=info ts=2025-05-17T17:33:24.87925136Z caller=ta‚Ä¶ss.log
May 17 17:33:24 kaligbrs promtail-linux-amd64[773]: ts=2025-05-17T17:33:24.873332392Z caller=log.go:168 l‚Ä¶ce:0}"
May 17 17:33:25 kaligbrs promtail-linux-amd64[773]: ts=2025-05-17T17:33:25.095138144Z caller=log.go:168 l‚Ä¶g ..."
May 17 17:33:25 kaligbrs promtail-linux-amd64[773]: ts=2025-05-17T17:33:25.095973095Z caller=log.go:168 l‚Ä¶0.log"
May 17 17:35:07 kaligbrs promtail-linux-amd64[773]: level=warn ts=2025-05-17T17:35:07.653949605Z caller=logging‚Ä¶
Hint: Some lines were ellipsized, use -l to show in full.
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# 
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# history
    1  pwd
    2  ls
    3  usr
    4  users
    5  user
    6  exit
    7  docker network ls
    8  exit
    9  apt install -y apt-transport-https software-properties-common wget
   10  \napt install -y grafana-enterprise
   11  sudo wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key\necho "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list\n
   12  apt update
   13  chmod 644 /usr/share/keyrings/grafana.key
   14  echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee /etc/apt/sources.list.d/grafana.list\n
   15  apt update
   16  apt update\napt install -y grafana-enterprise
   17  systemctl daemon-reload
   18  systemctl enable grafana-server
   19  systemctl start grafana-server
   20  systemctl status grafana-server --no-pager
   21  ss -ntulp | grep grafana\nss -ntulp | grep 3000
   22  mkdir /opt/loki && cd /opt/loki
   23  curl -O -L "https://github.com/grafana/loki/releases/download/v2.9.7/loki-linux-amd64.zip"\nunzip loki-linux-amd64.zip\nchmod +x loki-linux-amd64
   24  cp /answers/loki-local-config.yaml /opt/loki\ncp /answers/loki.service /etc/systemd/system/loki.service
   25  systemctl daemon-reload
   26  systemctl enable loki.service --now
   27  systemctl status loki.service --no-pager
   28  ss -ntulp | grep 3100
   29  cat > /opt/loki/loki-local-config.yaml << 'EOF'\nauth_enabled: false\n\nserver:\n  http_listen_port: 3100\n  grpc_listen_port: 9096\n\ncommon:\n  path_prefix: /opt/loki\n  storage:\n    filesystem:\n      chunks_directory: /opt/loki/chunks\n      rules_directory: /opt/loki/rules\n  replication_factor: 1\n  ring:\n    instance_addr: 127.0.0.1\n    kvstore:\n      store: inmemory\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: index_\n        period: 24h\n\nruler:\n  alertmanager_url: http://localhost:9093\n\n# By default, Loki will send anonymous, but uniquely-identifiable usage and configuration\n# analytics to Grafana Labs. These statistics are sent to https://stats.grafana.org/\n# Statistics help us better understand how Loki is used, and they show us performance\n# levels for most users. This helps us prioritize features and documentation.\n# For more information on what's sent, look at\n# https://github.com/grafana/loki/blob/main/pkg/usagestats/stats.go\n# Refer to the buildReport method to see what goes into a report.\n#\n# If you would like to disable reporting, uncomment the following lines:\nanalytics:\n  reporting_enabled: false\nEOF
   30  cat > /etc/systemd/system/loki.service << 'EOF'\n[Unit]\nDescription=Loki service\nAfter=network.target\n\n[Service]\nType=simple\nUser=root\nExecStart=/opt/loki/loki-linux-amd64 -config.file=/opt/loki/loki-local-config.yaml\nRestart=on-failure\nWorkingDirectory=/opt/loki\n\n[Install]\nWantedBy=multi-user.target\nEOF
   31  mkdir -p /opt/loki/chunks\nmkdir -p /opt/loki/rules
   32  systemctl daemon-reload
   33  systemctl enable loki.service --now
   34  systemctl status loki.service --no-pager
   35  ss -ntulp | grep 3100
   36  mkdir /opt/promtail && cd /opt/promtail
   37  curl -O -L "https://github.com/grafana/loki/releases/download/v2.7.1/promtail-linux-amd64.zip"\nunzip promtail-linux-amd64.zip\nchmod +x promtail-linux-amd64
   38  cp /answers/promtail-local-config.yaml /opt/promtail\ncp /answers/promtail.service /etc/systemd/system/promtail.service
   39  systemctl daemon-reload\nsystemctl enable promtail.service --now\nsystemctl status promtail.service --no-pager\nps -ef | grep [p]romtail
   40  cat > /opt/promtail/promtail-local-config.yaml << 'EOF'\nserver:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /opt/promtail/positions.yaml\n\nclients:\n  - url: http://localhost:3100/loki/api/v1/push\n\nscrape_configs:\n  - job_name: system\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: varlogs\n          __path__: /var/log/*log\n\n  - job_name: syslog\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: syslog\n          __path__: /var/log/syslog*\n\n  - job_name: auth\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: auth\n          __path__: /var/log/auth.log*\n\n  - job_name: apache\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: apache\n          __path__: /var/log/apache2/*log\n\n  - job_name: nginx\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: nginx\n          __path__: /var/log/nginx/*log\nEOF
   41  cat > /etc/systemd/system/promtail.service << 'EOF'\n[Unit]\nDescription=Promtail service\nAfter=network.target\n\n[Service]\nType=simple\nUser=root\nExecStart=/opt/promtail/promtail-linux-amd64 -config.file=/opt/promtail/promtail-local-config.yaml\nRestart=on-failure\nWorkingDirectory=/opt/promtail\n\n[Install]\nWantedBy=multi-user.target\nEOF
   42  systemctl daemon-reload\n\n# Enable and start Promtail\nsystemctl enable promtail.service --now\n\n# Check the status\nsystemctl status promtail.service --no-pager\n\n# Verify Promtail is running\nps -ef | grep [p]romtail
   43  systemctl start loki.service\n\n# Check Loki status\nsystemctl status loki.service --no-pager\n\n# Verify Loki is listening on port 3100\nss -ntulp | grep 3100
   44  btop
   45  cd
   46  ls
   47  apt install -y git curl\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\nsource ~/.bashrc\nnvm install 20\nnvm use 20
   48  clear
   49  exit
   50  cat > /etc/systemd/system/node_exporter.service << 'EOF'\n[Unit]\nDescription=Node Exporter\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=node_exporter\nGroup=node_exporter\nType=simple\nExecStart=/opt/node_exporter/node_exporter \\n    --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/) \\n    --collector.systemd \\n    --collector.processes \\n    --web.listen-address=:9100\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\nEOF
   51  systemctl daemon-reload\nsystemctl start node_exporter\nsystemctl enable node_exporter\nsystemctl status node_exporter --no-pager
   52  curl http://localhost:9100/metrics | head
   53  systemctl status prometheus --no-pager
   54  curl http://localhost:9100/metrics | head
   55  ls -l /opt/node_exporter/node_exporter\n
   56  cd /opt\ncurl -LO https://github.com/prometheus/node_exporter/releases/download/v1.8.0/node_exporter-1.8.0.linux-amd64.tar.gz\n
   57  tar -xzf node_exporter-1.8.0.linux-amd64.tar.gz
   58  mv node_exporter-1.8.0.linux-amd64 node_exporter
   59  chmod +x /opt/node_exporter/node_exporter/node_exporter
   60  systemctl daemon-reload\nsystemctl restart node_exporter\nsystemctl status node_exporter --no-pager
   61  curl http://localhost:9100/metrics | head\n
   62  mv node_exporter-1.8.0.linux-amd64 node_exporter\n
   63  ls -l /opt/node_exporter/node_exporter\n
   64  chmod +x /opt/node_exporter/node_exporter  ‚úÖ\n
   65  ls
   66  cd node_exporter
   67  ls
   68  chmod +x /opt/node_exporter/node_exporter\n
   69  nano /etc/systemd/system/node_exporter.service\n
   70  systemctl daemon-reload\nsystemctl restart node_exporter\nsystemctl status node_exporter --no-pager\n
   71  cat /etc/systemd/system/node_exporter.service\n
   72  curl http://localhost:9100/metrics | head\n
   73  history
   74  useradd --no-create-home --shell /bin/false prometheus
   75  mkdir -p /etc/prometheus /var/lib/prometheus
   76  cd /tmp\nwget https://github.com/prometheus/prometheus/releases/download/v2.42.0/prometheus-2.42.0.linux-amd64.tar.gz\ntar xvfz prometheus-*.tar.gz\ncd prometheus-*
   77  cp prometheus promtool /usr/local/bin/\ncp -r consoles/ console_libraries/ /etc/prometheus/
   78  ls -l /tmp\n
   79  cd /tmp/prometheus-2.42.0.linux-amd64\n
   80  cp prometheus promtool /usr/local/bin/\n
   81  ls -l /usr/local/bin/prometheus /usr/local/bin/promtool\n
   82  cp -r consoles/ console_libraries/ /etc/prometheus/\n
   83  ls /etc/prometheus/consoles\nls /etc/prometheus/console_libraries\n
   84  chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus\n
   85  cat > /etc/prometheus/prometheus.yml << 'EOF'\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n  scrape_timeout: 10s\n\n  # Add labels to any time series or alerts when communicating with\n  # external systems (federation, remote storage, Alertmanager).\n  external_labels:\n    monitor: 'my-monitoring-system'\n\n# Alertmanager configuration\nalerting:\n  alertmanagers:\n  - static_configs:\n    - targets:\n      - localhost:9093\n\n# Load rules once and periodically evaluate them\nrule_files:\n  - "rules/*.yml"\n\n# A scrape configuration containing exactly one endpoint to scrape:\nscrape_configs:\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n\n  - job_name: 'node_exporter'\n    static_configs:\n      - targets: ['localhost:9100']\nEOF
   86  mkdir -p /etc/prometheus/rules
   87  cat > /etc/prometheus/rules/node_alerts.yml << 'EOF'\ngroups:\n- name: node_alerts\n  rules:\n  - alert: HighCPULoad\n    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: "High CPU load (instance {{ $labels.instance }})"\n      description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"\n\n  - alert: HighMemoryLoad\n    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: "High memory load (instance {{ $labels.instance }})"\n      description: "Memory load is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"\n\n  - alert: HighDiskUsage\n    expr: (node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"} * 100 > 80\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: "High disk usage (instance {{ $labels.instance }})"\n      description: "Disk usage is > 80%\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"\nEOF
   88  chown -R prometheus:prometheus /etc/prometheus /var/lib/prometheus\nchmod -R 775 /etc/prometheus /var/lib/prometheus
   89  cat > /etc/systemd/system/prometheus.service << 'EOF'\n[Unit]\nDescription=Prometheus\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=prometheus\nGroup=prometheus\nType=simple\nExecStart=/usr/local/bin/prometheus \\n    --config.file=/etc/prometheus/prometheus.yml \\n    --storage.tsdb.path=/var/lib/prometheus/ \\n    --web.console.templates=/etc/prometheus/consoles \\n    --web.console.libraries=/etc/prometheus/console_libraries \\n    --web.listen-address=0.0.0.0:9090 \\n    --web.enable-lifecycle \\n    --storage.tsdb.retention.time=15d\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\nEOF
   90  systemctl daemon-reload\nsystemctl start prometheus\nsystemctl enable prometheus\nsystemctl status prometheus --no-pager
   91  ls -l /usr/local/bin/prometheus\n
   92  chmod 755 /usr/local/bin/prometheus\n
   93  ls -l /usr/local/bin/prometheus\n
   94  systemctl daemon-reload\nsystemctl restart prometheus\nsystemctl status prometheus --no-pager\n
   95  curl http://localhost:9090/metrics | head\n
   96  curl http://localhost:9090/-/healthy
   97  useradd --no-create-home --shell /bin/false alertmanager
   98  mkdir -p /etc/alertmanager /var/lib/alertmanager
   99  cd /tmp\nwget https://github.com/prometheus/alertmanager/releases/download/v0.25.0/alertmanager-0.25.0.linux-amd64.tar.gz\ntar xvfz alertmanager-*.tar.gz\ncd alertmanager-*
  100  cp alertmanager amtool /usr/local/bin/
  101  cd /tmp/alertmanager-0.25.0.linux-amd64\n
  102  cp alertmanager amtool /usr/local/bin/\n
  103  chmod +x /usr/local/bin/alertmanager /usr/local/bin/amtool\n
  104  ls -l /usr/local/bin/alertmanager /usr/local/bin/amtool\n
  105  cat > /etc/alertmanager/alertmanager.yml << 'EOF'\nglobal:\n  resolve_timeout: 5m\n  smtp_smarthost: 'smtp.example.org:587'\n  smtp_from: 'alertmanager@example.org'\n  smtp_auth_username: 'alertmanager'\n  smtp_auth_password: 'password'\n  smtp_require_tls: true\n\nroute:\n  group_by: ['alertname', 'job']\n  group_wait: 30s\n  group_interval: 5m\n  repeat_interval: 4h\n  receiver: 'email-notifications'\n\nreceivers:\n- name: 'email-notifications'\n  email_configs:\n  - to: 'admin@example.org'\n    send_resolved: true\n\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'instance']\nEOF
  106  chown -R alertmanager:alertmanager /etc/alertmanager /var/lib/alertmanager\nchmod -R 775 /etc/alertmanager /var/lib/alertmanager
  107  cat > /etc/systemd/system/alertmanager.service << 'EOF'\n[Unit]\nDescription=Alertmanager\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=alertmanager\nGroup=alertmanager\nType=simple\nExecStart=/usr/local/bin/alertmanager \\n    --config.file=/etc/alertmanager/alertmanager.yml \\n    --storage.path=/var/lib/alertmanager/ \\n    --web.listen-address=0.0.0.0:9093\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\nEOF
  108  systemctl daemon-reload\nsystemctl start alertmanager\nsystemctl enable alertmanager\nsystemctl status alertmanager --no-pager
  109  curl http://localhost:9093/-/healthy
  110  chmod 755 /usr/local/bin/alertmanager /usr/local/bin/amtool\n
  111  systemctl daemon-reload\nsystemctl restart alertmanager\nsystemctl status alertmanager --no-pager\n
  112  curl http://localhost:9093/-/healthy\n
  113  cat /etc/prometheus/prometheus.yml
  114  curl -X POST http://localhost:9090/-/reload\n
  115  cd /etc/
  116  ls
  117  useradd --no-create-home --shell /bin/false loki
  118  cd /var/lib/\
  
  119  ls
  120  mkdir -p /etc/loki /var/lib/loki
  121  cd /tmp\nwget https://github.com/grafana/loki/releases/download/v2.8.0/loki-linux-amd64.zip\napt install -y unzip\nunzip loki-linux-amd64.zip
  122  cp loki-linux-amd64 /usr/local/bin/loki\nchmod +x /usr/local/bin/loki
  123  cat > /etc/loki/loki-local-config.yaml << 'EOF'\nauth_enabled: false\n\nserver:\n  http_listen_port: 3100\n  grpc_listen_port: 9096\n\ncommon:\n  path_prefix: /var/lib/loki\n  storage:\n    filesystem:\n      chunks_directory: /var/lib/loki/chunks\n      rules_directory: /var/lib/loki/rules\n  replication_factor: 1\n  ring:\n    instance_addr: 127.0.0.1\n    kvstore:\n      store: inmemory\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: index_\n        period: 24h\n\nruler:\n  alertmanager_url: http://localhost:9093\n\nlimits_config:\n  enforce_metric_name: false\n  reject_old_samples: true\n  reject_old_samples_max_age: 168h\nEOF
  124  chown -R loki:loki /etc/loki /var/lib/loki\nchmod -R 775 /etc/loki /var/lib/loki
  125  cat > /etc/systemd/system/loki.service << 'EOF'\n[Unit]\nDescription=Loki\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nUser=loki\nGroup=loki\nType=simple\nExecStart=/usr/local/bin/loki -config.file=/etc/loki/loki-local-config.yaml\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\nEOF
  126  systemctl daemon-reload\nsystemctl start loki\nsystemctl enable loki\nsystemctl status loki --no-pager
  127  cd /tmp\nwget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip\nunzip promtail-linux-amd64.zip\ncp promtail-linux-amd64 /usr/local/bin/promtail\nchmod +x /usr/local/bin/promtail
  128  mkdir -p /etc/promtail
  129  cat > /etc/promtail/promtail-local-config.yaml << 'EOF'\nserver:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /var/lib/promtail/positions.yaml\n\nclients:\n  - url: http://localhost:3100/loki/api/v1/push\n\nscrape_configs:\n  - job_name: system\n    static_configs:\n    - targets:\n        - localhost\n      labels:\n        job: varlogs\n        __path__: /var/log/*log\n\n  - job_name: syslog\n    syslog:\n      listen_address: 0.0.0.0:1514\n      labels:\n        job: syslog\n    relabel_configs:\n      - source_labels: ['__syslog_message_hostname']\n        target_label: 'host'\nEOF
  130  mkdir -p /var/lib/promtail
  131  cat > /etc/systemd/system/promtail.service << 'EOF'\n[Unit]\nDescription=Promtail\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nType=simple\nExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-local-config.yaml\n\nRestart=always\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\nEOF
  132  systemctl daemon-reload\nsystemctl start promtail\nsystemctl enable promtail\nsystemctl status promtail --no-pager
                                                                                                                
‚îå‚îÄ‚îÄ(root„âøkaligbrs)-[/tmp]
‚îî‚îÄ# 
