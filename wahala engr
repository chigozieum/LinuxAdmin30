The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional
I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.


Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.4/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.4/fpm/php.ini"
    elif [ -f /etc/php/7.3/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.3/fpm/php.ini"
    elif [ -f /etc/php/7.2/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.2/fpm/php.ini"
    elif [ -f /etc/php.ini ]; then
        PHP_INI="/etc/php.ini"
    else
        log_message "${YELLOW}PHP configuration file not found${NC}"
        return
    fi
    
    # Backup original PHP configuration
    cp "$PHP_INI" "$PHP_INI.bak"
    
    # Update PHP configuration
    sed -i 's/^max_execution_time = .*/max_execution_time = 60/' "$PHP_INI"
    sed -i 's/^memory_limit = .*/memory_limit = 256M/' "$PHP_INI"
    sed -i 's/^upload_max_filesize = .*/upload_max_filesize = 20M/' "$PHP_INI"
    sed -i 's/^post_max_size = .*/post_max_size = 20M/' "$PHP_INI"
    sed -i 's/^;date.timezone.*/date.timezone = UTC/' "$PHP_INI"
    
    # Restart PHP-FPM
    if [ "$DISTRO" = "debian" ]; then
        systemctl restart php7.4-fpm 2>/dev/null || systemctl restart php7.3-fpm 2>/dev/null || systemctl restart php7.2-fpm
    elif [ "$DISTRO" = "rhel" ]; then
        systemctl restart php-fpm
    fi
    
    log_message "${GREEN}PHP configured successfully${NC}"
}

# Function to configure firewall
configure_firewall() {
    log_message "${BLUE}Configuring firewall...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Configure UFW
        ufw default deny incoming
        ufw default allow outgoing
        ufw allow ssh
        ufw allow http
        ufw allow https
        
        # Enable UFW
        echo "y" | ufw enable
        
        log_message "${GREEN}UFW firewall configured successfully${NC}"
    elif [ "$DISTRO" = "rhel" ]; then
        # Configure firewalld
        systemctl start firewalld
        systemctl enable firewalld
        
        firewall-cmd --permanent --add-service=ssh
        firewall-cmd --permanent --add-service=http
        firewall-cmd --permanent --add-service=https
        firewall-cmd --reload
        
        log_message "${GREEN}Firewalld configured successfully${NC}"
    fi
}

# Function to configure fail2ban
configure_fail2ban() {
    log_message "${BLUE}Configuring fail2ban...${NC}"
    
    # Create fail2ban configuration
    cat > /etc/fail2ban/jail.local << 'EOL'
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 5

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3

[nginx-http-auth]
enabled = true
filter = nginx-http-auth
port = http,https
logpath = /var/log/nginx/error.log
EOL
    
    # Restart fail2ban
    systemctl restart fail2ban
    systemctl enable fail2ban
    
    log_message "${GREEN}Fail2ban configured successfully${NC}"
}

# Function to set up log rotation
configure_logrotate() {
    log_message "${BLUE}Configuring log rotation...${NC}"
    
    # Create logrotate configuration for application logs
    cat > /etc/logrotate.d/webapp << 'EOL'
/var/www/html/logs/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 www-data www-data
    sharedscripts
    postrotate
        systemctl reload nginx
    endscript
}
EOL
    
    log_message "${GREEN}Log rotation configured successfully${NC}"
}

# Function to set up backup script
setup_backup() {
    log_message "${BLUE}Setting up backup system...${NC}"
    
    # Create backup script
    cat > "$PROJECT_DIR/scripts/backup.sh" << 'EOL'
#!/bin/bash
# backup.sh - Backup script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="/var/www/html"
DB_NAME="webapp"
DB_USER="webappuser"
DB_PASSWORD=$(grep "Database Password:" "$PROJECT_DIR/configs/db_credentials.txt" | cut -d' ' -f3)
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/backup_$DATE.tar.gz"
DB_BACKUP_FILE="$BACKUP_DIR/db_backup_$DATE.sql"

# Create backup directory if it doesn't exist
mkdir -p "$BACKUP_DIR"

# Backup database
mysqldump -u "$DB_USER" -p"$DB_PASSWORD" "$DB_NAME" > "$DB_BACKUP_FILE"

# Backup web files
tar -czf "$BACKUP_FILE" -C "$WWW_DIR" .

# Add database backup to archive
tar -rf "${BACKUP_FILE%.tar.gz}.tar" -C "$BACKUP_DIR" "$(basename "$DB_BACKUP_FILE")"
gzip -f "${BACKUP_FILE%.tar.gz}.tar"

# Remove temporary database backup file
rm "$DB_BACKUP_FILE"

# Keep only the last 7 backups
ls -t "$BACKUP_DIR"/backup_*.tar.gz | tail -n +8 | xargs -r rm

echo "Backup completed: $BACKUP_FILE"
EOL
    
    # Make backup script executable
    chmod +x "$PROJECT_DIR/scripts/backup.sh"
    
    # Set up cron job for daily backups
    (crontab -l 2>/dev/null; echo "0 2 * * * $PROJECT_DIR/scripts/backup.sh > $LOGS_DIR/backup.log 2>&1") | crontab -
    
    log_message "${GREEN}Backup system set up successfully${NC}"
}

# Function to set up monitoring script
setup_monitoring() {
    log_message "${BLUE}Setting up monitoring system...${NC}"
    
    # Create monitoring script
    cat > "$PROJECT_DIR/scripts/monitor.sh" << 'EOL'
#!/bin/bash
# monitor.sh - Monitoring script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
LOGS_DIR="$PROJECT_DIR/logs"
MONITOR_LOG="$LOGS_DIR/monitor.log"
EMAIL_RECIPIENT="admin@example.com"
HOSTNAME=$(hostname)
DATE=$(date +%Y-%m-%d)
TIME=$(date +%H:%M:%S)

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo "$timestamp - $message" >> "$MONITOR_LOG"
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Check if services are running
check_services() {
    log_message "Checking services..."
    
    # Check Nginx
    if ! systemctl is-active --quiet nginx; then
        log_message "ERROR: Nginx is not running"
        send_alert "[$HOSTNAME] Nginx is down" "Nginx service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart nginx
    else
        log_message "Nginx is running"
    fi
    
    # Check MariaDB
    if ! systemctl is-active --quiet mariadb; then
        log_message "ERROR: MariaDB is not running"
        send_alert "[$HOSTNAME] MariaDB is down" "MariaDB service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart mariadb
    else
        log_message "MariaDB is running"
    fi
    
    # Check PHP-FPM
    if ! systemctl is-active --quiet php7.4-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.3-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.2-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php-fpm 2>/dev/null; then
        log_message "ERROR: PHP-FPM is not running"
        send_alert "[$HOSTNAME] PHP-FPM is down" "PHP-FPM service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart php7.4-fpm 2>/dev/null || 
        systemctl restart php7.3-fpm 2>/dev/null || 
        systemctl restart php7.2-fpm 2>/dev/null || 
        systemctl restart php-fpm 2>/dev/null
    else
        log_message "PHP-FPM is running"
    fi
}

# Check disk space
check_disk_space() {
    log_message "Checking disk space..."
    
    # Get disk usage percentage
    DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ "$DISK_USAGE" -gt 90 ]; then
        log_message "WARNING: Disk space is critically low ($DISK_USAGE%)"
        send_alert "[$HOSTNAME] Disk space critical" "Disk space usage is at $DISK_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$DISK_USAGE" -gt 80 ]; then
        log_message "WARNING: Disk space is running low ($DISK_USAGE%)"
    else
        log_message "Disk space is OK ($DISK_USAGE%)"
    fi
}

# Check memory usage
check_memory() {
    log_message "Checking memory usage..."
    
    # Get memory usage percentage
    MEM_USAGE=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
    
    if [ "$MEM_USAGE" -gt 90 ]; then
        log_message "WARNING: Memory usage is critically high ($MEM_USAGE%)"
        send_alert "[$HOSTNAME] Memory usage critical" "Memory usage is at $MEM_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$MEM_USAGE" -gt 80 ]; then
        log_message "WARNING: Memory usage is high ($MEM_USAGE%)"
    else
        log_message "Memory usage is OK ($MEM_USAGE%)"
    fi
}

# Check load average
check_load() {
    log_message "Checking system load..."
    
    # Get number of CPU cores
    CPU_CORES=$(nproc)
    
    # Get load average for 1 minute
    LOAD_AVG=$(cat /proc/loadavg | awk '{print $1}')
    
    # Calculate load per core
    LOAD_PER_CORE=$(echo "$LOAD_AVG / $CPU_CORES" | bc -l)
    
    if (( $(echo "$LOAD_PER_CORE > 2.0" | bc -l) )); then
        log_message "WARNING: System load is critically high (${LOAD_AVG})"
        send_alert "[$HOSTNAME] System load critical" "System load is at ${LOAD_AVG} (${LOAD_PER_CORE} per core) on $HOSTNAME at $DATE $TIME"
    elif (( $(echo "$LOAD_PER_CORE > 1.0" | bc -l) )); then
        log_message "WARNING: System load is high (${LOAD_AVG})"
    else
        log_message "System load is OK (${LOAD_AVG})"
    fi
}

# Check for failed login attempts
check_failed_logins() {
    log_message "Checking for failed login attempts..."
    
    # Count failed SSH login attempts in the last hour
    FAILED_LOGINS=$(grep "Failed password" /var/log/auth.log | grep -c "$(date +%b' '%d' '%H)")
    
    if [ "$FAILED_LOGINS" -gt 10 ]; then
        log_message "WARNING: High number of failed login attempts ($FAILED_LOGINS in the last hour)"
        send_alert "[$HOSTNAME] Security alert" "High number of failed login attempts ($FAILED_LOGINS in the last hour) on $HOSTNAME at $DATE $TIME"
    elif [ "$FAILED_LOGINS" -gt 5 ]; then
        log_message "WARNING: Multiple failed login attempts ($FAILED_LOGINS in the last hour)"
    else
        log_message "Failed login attempts are OK ($FAILED_LOGINS in the last hour)"
    fi
}

# Check HTTP response
check_http_response() {
    log_message "Checking HTTP response..."
    
    # Get HTTP status code
    HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost)
    
    if [ "$HTTP_STATUS" != "200" ]; then
        log_message "ERROR: HTTP response is not OK (status code: $HTTP_STATUS)"
        send_alert "[$HOSTNAME] Website is down" "Website returned HTTP status code $HTTP_STATUS on $HOSTNAME at $DATE $TIME"
    else
        log_message "HTTP response is OK (status code: $HTTP_STATUS)"
    fi
}

# Main function
main() {
    log_message "Starting monitoring check..."
    
    check_services
    check_disk_space
    check_memory
    check_load
    check_failed_logins
    check_http_response
    
    log_message "Monitoring check completed"
}

# Create logs directory if it doesn't exist
mkdir -p "$LOGS_DIR"

# Run main function
main
EOL
    
    # Make monitoring script executable
    chmod +x "$PROJECT_DIR/scripts/monitor.sh"
    
    # Set up cron job for monitoring every 15 minutes
    (crontab -l 2>/dev/null; echo "*/15 * * * * $PROJECT_DIR/scripts/monitor.sh > /dev/null 2>&1") | crontab -
    
    log_message "${GREEN}Monitoring system set up successfully${NC}"
}

# Function to create Docker configuration
setup_docker() {
    log_message "${BLUE}Setting up Docker configuration...${NC}"
    
    # Check if Docker is installed
    if ! command -v docker &> /dev/null; then
        log_message "${YELLOW}Docker is not installed. Installing Docker...${NC}"
        
        if [ "$DISTRO" = "debian" ]; then
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release >> "$LOG_FILE" 2>&1
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
            echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        elif [ "$DISTRO" = "rhel" ]; then
            yum install -y yum-utils >> "$LOG_FILE" 2>&1
            yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo >> "$LOG_FILE" 2>&1
            yum install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        fi
        
        systemctl start docker
        systemctl enable docker
    fi
    
    # Check if Docker Compose is installed
    if ! command -v docker-compose &> /dev/null; then
        log_message "${YELLOW}Docker Compose is not installed. Installing Docker Compose...${NC}"
        
        curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        chmod +x /usr/local/bin/docker-compose
    fi
    
    # Create Docker Compose configuration
    cat > "$PROJECT_DIR/docker-compose.yml" << 'EOL'
version: '3'

services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    volumes:
      - ./www:/usr/share/nginx/html
      - ./configs/nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - php
    networks:
      - webapp

  php:
    image: php:7.4-fpm
    volumes:
      - ./www:/var/www/html
    networks:
      - webapp

  db:
    image: mariadb:latest
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MYSQL_DATABASE: ${DB_NAME}
      MYSQL_USER: ${DB_USER}
      MYSQL_PASSWORD: ${DB_PASSWORD}
    volumes:
      - db_data:/var/lib/mysql
    networks:
      - webapp

networks:
  webapp:

volumes:
  db_data:
EOL
    
    # Create Nginx configuration for Docker
    mkdir -p "$CONFIG_DIR"
    cat > "$CONFIG_DIR/nginx.conf" << 'EOL'
server {
    listen 80;
    server_name localhost;
    
    root /usr/share/nginx/html;
    index index.php index.html;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        fastcgi_pass php:9000;
        fastcgi_index index.php;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        include fastcgi_params;
    }
}
EOL
    
    # Create .env file for Docker Compose
    cat > "$PROJECT_DIR/.env" << EOF
DB_ROOT_PASSWORD=$(grep "Database Root Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f4)
DB_NAME=$(grep "Database Name:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_USER=$(grep "Database User:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_PASSWORD=$(grep "Database Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
EOF
    
    # Create sample index.php file for Docker
    mkdir -p "$WWW_DIR"
    cat > "$WWW_DIR/index.php" << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Docker Web Server</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Docker Web Server Deployment Successful!</h1>
        <p>This page confirms that your Docker web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>Database Connection Test</h2>
        <?php
        $host = 'db';
        $dbname = getenv('DB_NAME');
        $user = getenv('DB_USER');
        $pass = getenv('DB_PASSWORD');
        
        try {
            $conn = new PDO("mysql:host=$host;dbname=$dbname", $user, $pass);
            $conn->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
            echo '<p style="color: green;">Database connection successful!</p>';
        } catch(PDOException $e) {
            echo '<p style="color: red;">Database connection failed: ' . $e->getMessage() . '</p>';
        }
        ?>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Create Docker start script
    cat > "$PROJECT_DIR/scripts/start-docker.sh" << 'EOL'
#!/bin/bash
# start-docker.sh - Start Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose up -d

echo "Docker containers started. Access the web server at http://localhost:8080"
EOL
    
    # Create Docker stop script
    cat > "$PROJECT_DIR/scripts/stop-docker.sh" << 'EOL'
#!/bin/bash
# stop-docker.sh - Stop Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose down

echo "Docker containers stopped"
EOL
    
    # Make Docker scripts executable
    chmod +x "$PROJECT_DIR/scripts/start-docker.sh"
    chmod +x "$PROJECT_DIR/scripts/stop-docker.sh"
    
    log_message "${GREEN}Docker configuration set up successfully${NC}"
    log_message "${YELLOW}To start Docker containers, run: $PROJECT_DIR/scripts/start-docker.sh${NC}"
    log_message "${YELLOW}To stop Docker containers, run: $PROJECT_DIR/scripts/stop-docker.sh${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}Web Server Deployment Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Server IP:${NC} $ip_address"
    echo -e "${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}Docker Web Server:${NC} http://$ip_address:8080 (when Docker is running)"
    echo -e "\n${YELLOW}Database Credentials:${NC} $CONFIG_DIR/db_credentials.txt"
    echo -e "${YELLOW}SSH Key for webadmin:${NC} /home/webadmin/.ssh/id_ed25519"
    echo -e "\n${YELLOW}Scripts:${NC}"
    echo -e "  Backup: $PROJECT_DIR/scripts/backup.sh"
    echo -e "  Monitor: $PROJECT_DIR/scripts/monitor.sh"
    echo -e "  Docker Start: $PROJECT_DIR/scripts/start-docker.sh"
    echo -e "  Docker Stop: $PROJECT_DIR/scripts/stop-docker.sh"
    echo -e "\n${YELLOW}Logs:${NC} $LOGS_DIR"
    echo -e "${YELLOW}Backups:${NC} $BACKUP_DIR"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}Deployment log: $LOG_FILE${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Create directories
    mkdir -p "$CONFIG_DIR" "$LOGS_DIR" "$BACKUP_DIR" "$WWW_DIR"
    
    # Check if running as root
    check_root
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      WEB SERVER DEPLOYMENT SCRIPT     ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages
    install_packages
    
    # Create web server user
    create_web_user
    
    # Configure services
    configure_nginx
    configure_mariadb
    configure_php
    configure_firewall
    configure_fail2ban
    configure_logrotate
    
    # Set up scripts
    setup_backup
    setup_monitoring
    setup_docker
    
    # Display summary
    display_summary
    
    log_message "${GREEN}Web server deployment completed successfully${NC}"
}

# Run main function
main
Make the script executable:

```bash chmod +x ~/web-server-project/scripts/deploy.sh


#### Step 3: Run the Deployment Script

\`\`\`bash
sudo ~/web-server-project/scripts/deploy.sh
This script will:

Install and configure a web server (Nginx, MariaDB, PHP)
Set up a dedicated web server user with SSH key authentication
Configure firewall rules and fail2ban for security
Set up log rotation for proper log management
Create backup and monitoring scripts with cron jobs
Set up Docker and Docker Compose for containerized deployment
Generate a comprehensive deployment report
Step 4: Test the Deployment
After the script completes, you can test the deployment by:

Accessing the web server at http://your-server-ip
Starting the Docker containers with ~/web-server-project/scripts/start-docker.sh
Accessing the containerized web server at http://your-server-ip:8080
Testing the backup script with ~/web-server-project/scripts/backup.sh
Testing the monitoring script with ~/web-server-project/scripts/monitor.sh
Step 5: Document the Project
Create a README.md file for the project:

```markdown

Automated Web Server Deployment and Monitoring System
Overview
This project provides a comprehensive system for deploying, securing, and monitoring a web server environment. It includes automated scripts for installation, configuration, backup, and monitoring.

Features
Automated deployment of Nginx, MariaDB, and PHP
User management with secure SSH key authentication
Firewall configuration and intrusion prevention with fail2ban
Log rotation and management
Automated backup system
Comprehensive monitoring system
Containerized deployment with Docker and Docker Compose
Directory Structure
scripts/ - Contains all automation scripts

deploy.sh - Main deployment script
backup.sh - Automated backup script
monitor.sh - System monitoring script
start-docker.sh - Start Docker containers
stop-docker.sh - Stop Docker containers
configs/ - Configuration files
logs/ - Log files
backups/ - Backup files
www/ - Web files for Docker deployment
Usage
Initial Deployment
```bash sudo ./scripts/deploy.sh


### Managing Backups

\`\`\`bash
# Run a manual backup
./scripts/backup.sh

# Restore from backup
tar -xzf backups/backup_YYYYMMDD_HHMMSS.tar.gz -C /var/www/html
Monitoring
```bash

Run a manual monitoring check
./scripts/monitor.sh


### Docker Deployment

\`\`\`bash
# Start Docker containers
./scripts/start-docker.sh

# Stop Docker containers
./scripts/stop-docker.sh
Security Features
Dedicated web server user with restricted permissions
SSH key authentication
Firewall rules allowing only necessary services
Fail2ban for intrusion prevention
Secure database configuration
HTTPS support
Monitoring Features
Service status monitoring
Disk space monitoring
Memory usage monitoring
System load monitoring
Failed login attempts monitoring
HTTP response monitoring
Backup System
Daily automated backups
Database and file system backups
Rotation system to manage backup storage
Requirements
Ubuntu 20.04 LTS or CentOS 8
Sudo/root access
Internet connection for package installation
License
This project is licensed under the MIT License - see the LICENSE file for details.


#### Day 7 Learning Outcomes

By completing this capstone project, you should be able to:

1. Deploy and configure a complete web server environment
2. Implement proper security measures for a production server
3. Set up automated monitoring and alerting
4. Create a comprehensive backup and recovery system
5. Containerize an application for easy deployment
6. Document a complex system for future reference
7. Apply all the skills learned in Week 1 to a real-world project

#### Additional Resources for Day 7

- [Nginx Documentation](https://nginx.org/en/docs/)
- [MariaDB Documentation](https://mariadb.com/kb/en/documentation/)
- [PHP Documentation](https://www.php.net/docs.php)
- [Docker Documentation](https://docs.docker.com/)
- [Linux Server Security Guide](https://www.digitalocean.com/community/tutorials/7-security-measures-to-protect-your-servers)

## Week 2: Advanced System Administration

In Week 2, we'll build on the foundation established in Week 1 and dive into more advanced system administration topics. This week focuses on advanced shell scripting, system performance, security, networking, storage, and high availability.

### Day 8: Advanced Shell Scripting

Shell scripting is a powerful tool for automating complex tasks. In this section, we'll explore advanced shell scripting techniques that will make your scripts more robust, efficient, and maintainable.

#### Advanced Bash Features

**Bash Arrays:**

\`\`\`bash
# Indexed arrays
declare -a fruits=("Apple" "Banana" "Orange" "Mango")
echo "First fruit: ${fruits[0]}"
echo "All fruits: ${fruits[@]}"
echo "Number of fruits: ${#fruits[@]}"

# Iterating through array
for fruit in "${fruits[@]}"; do
    echo "Processing $fruit"
done

# Array operations
fruits+=(["Pineapple" "Grape"])  # Add elements
unset fruits[1]                  # Remove element
fruits=("${fruits[@]}")          # Reindex array

# Associative arrays (dictionaries)
declare -A user_info
user_info[name]="John"
user_info[age]=30
user_info[city]="New York"

echo "Name: ${user_info[name]}"
echo "Age: ${### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.4/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.4/fpm/php.ini"
    elif [ -f /etc/php/7.3/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.3/fpm/php.ini"
    elif [ -f /etc/php/7.2/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.2/fpm/php.ini"
    elif [ -f /etc/php.ini ]; then
        PHP_INI="/etc/php.ini"
    else
        log_message "${YELLOW}PHP configuration file not found${NC}"
        return
    fi
    
    # Backup original PHP configuration
    cp "$PHP_INI" "$PHP_INI.bak"
    
    # Update PHP configuration
    sed -i 's/^max_execution_time = .*/max_execution_time = 60/' "$PHP_INI"
    sed -i 's/^memory_limit = .*/memory_limit = 256M/' "$PHP_INI"
    sed -i 's/^upload_max_filesize = .*/upload_max_filesize = 20M/' "$PHP_INI"
    sed -i 's/^post_max_size = .*/post_max_size = 20M/' "$PHP_INI"
    sed -i 's/^;date.timezone.*/date.timezone = UTC/' "$PHP_INI"
    
    # Restart PHP-FPM
    if [ "$DISTRO" = "debian" ]; then
        systemctl restart php7.4-fpm 2>/dev/null || systemctl restart php7.3-fpm 2>/dev/null || systemctl restart php7.2-fpm
    elif [ "$DISTRO" = "rhel" ]; then
        systemctl restart php-fpm
    fi
    
    log_message "${GREEN}PHP configured successfully${NC}"
}

# Function to configure firewall
configure_firewall() {
    log_message "${BLUE}Configuring firewall...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Configure UFW
        ufw default deny incoming
        ufw default allow outgoing
        ufw allow ssh
        ufw allow http
        ufw allow https
        
        # Enable UFW
        echo "y" | ufw enable
        
        log_message "${GREEN}UFW firewall configured successfully${NC}"
    elif [ "$DISTRO" = "rhel" ]; then
        # Configure firewalld
        systemctl start firewalld
        systemctl enable firewalld
        
        firewall-cmd --permanent --add-service=ssh
        firewall-cmd --permanent --add-service=http
        firewall-cmd --permanent --add-service=https
        firewall-cmd --reload
        
        log_message "${GREEN}Firewalld configured successfully${NC}"
    fi
}

# Function to configure fail2ban
configure_fail2ban() {
    log_message "${BLUE}Configuring fail2ban...${NC}"
    
    # Create fail2ban configuration
    cat > /etc/fail2ban/jail.local << 'EOL'
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 5

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3

[nginx-http-auth]
enabled = true
filter = nginx-http-auth
port = http,https
logpath = /var/log/nginx/error.log
EOL
    
    # Restart fail2ban
    systemctl restart fail2ban
    systemctl enable fail2ban
    
    log_message "${GREEN}Fail2ban configured successfully${NC}"
}

# Function to set up log rotation
configure_logrotate() {
    log_message "${BLUE}Configuring log rotation...${NC}"
    
    # Create logrotate configuration for application logs
    cat > /etc/logrotate.d/webapp << 'EOL'
/var/www/html/logs/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 www-data www-data
    sharedscripts
    postrotate
        systemctl reload nginx
    endscript
}
EOL
    
    log_message "${GREEN}Log rotation configured successfully${NC}"
}

# Function to set up backup script
setup_backup() {
    log_message "${BLUE}Setting up backup system...${NC}"
    
    # Create backup script
    cat > "$PROJECT_DIR/scripts/backup.sh" << 'EOL'
#!/bin/bash
# backup.sh - Backup script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="/var/www/html"
DB_NAME="webapp"
DB_USER="webappuser"
DB_PASSWORD=$(grep "Database Password:" "$PROJECT_DIR/configs/db_credentials.txt" | cut -d' ' -f3)
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/backup_$DATE.tar.gz"
DB_BACKUP_FILE="$BACKUP_DIR/db_backup_$DATE.sql"

# Create backup directory if it doesn't exist
mkdir -p "$BACKUP_DIR"

# Backup database
mysqldump -u "$DB_USER" -p"$DB_PASSWORD" "$DB_NAME" > "$DB_BACKUP_FILE"

# Backup web files
tar -czf "$BACKUP_FILE" -C "$WWW_DIR" .

# Add database backup to archive
tar -rf "${BACKUP_FILE%.tar.gz}.tar" -C "$BACKUP_DIR" "$(basename "$DB_BACKUP_FILE")"
gzip -f "${BACKUP_FILE%.tar.gz}.tar"

# Remove temporary database backup file
rm "$DB_BACKUP_FILE"

# Keep only the last 7 backups
ls -t "$BACKUP_DIR"/backup_*.tar.gz | tail -n +8 | xargs -r rm

echo "Backup completed: $BACKUP_FILE"
EOL
    
    # Make backup script executable
    chmod +x "$PROJECT_DIR/scripts/backup.sh"
    
    # Set up cron job for daily backups
    (crontab -l 2>/dev/null; echo "0 2 * * * $PROJECT_DIR/scripts/backup.sh > $LOGS_DIR/backup.log 2>&1") | crontab -
    
    log_message "${GREEN}Backup system set up successfully${NC}"
}

# Function to set up monitoring script
setup_monitoring() {
    log_message "${BLUE}Setting up monitoring system...${NC}"
    
    # Create monitoring script
    cat > "$PROJECT_DIR/scripts/monitor.sh" << 'EOL'
#!/bin/bash
# monitor.sh - Monitoring script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
LOGS_DIR="$PROJECT_DIR/logs"
MONITOR_LOG="$LOGS_DIR/monitor.log"
EMAIL_RECIPIENT="admin@example.com"
HOSTNAME=$(hostname)
DATE=$(date +%Y-%m-%d)
TIME=$(date +%H:%M:%S)

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo "$timestamp - $message" >> "$MONITOR_LOG"
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Check if services are running
check_services() {
    log_message "Checking services..."
    
    # Check Nginx
    if ! systemctl is-active --quiet nginx; then
        log_message "ERROR: Nginx is not running"
        send_alert "[$HOSTNAME] Nginx is down" "Nginx service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart nginx
    else
        log_message "Nginx is running"
    fi
    
    # Check MariaDB
    if ! systemctl is-active --quiet mariadb; then
        log_message "ERROR: MariaDB is not running"
        send_alert "[$HOSTNAME] MariaDB is down" "MariaDB service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart mariadb
    else
        log_message "MariaDB is running"
    fi
    
    # Check PHP-FPM
    if ! systemctl is-active --quiet php7.4-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.3-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.2-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php-fpm 2>/dev/null; then
        log_message "ERROR: PHP-FPM is not running"
        send_alert "[$HOSTNAME] PHP-FPM is down" "PHP-FPM service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart php7.4-fpm 2>/dev/null || 
        systemctl restart php7.3-fpm 2>/dev/null || 
        systemctl restart php7.2-fpm 2>/dev/null || 
        systemctl restart php-fpm 2>/dev/null
    else
        log_message "PHP-FPM is running"
    fi
}

# Check disk space
check_disk_space() {
    log_message "Checking disk space..."
    
    # Get disk usage percentage
    DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ "$DISK_USAGE" -gt 90 ]; then
        log_message "WARNING: Disk space is critically low ($DISK_USAGE%)"
        send_alert "[$HOSTNAME] Disk space critical" "Disk space usage is at $DISK_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$DISK_USAGE" -gt 80 ]; then
        log_message "WARNING: Disk space is running low ($DISK_USAGE%)"
    else
        log_message "Disk space is OK ($DISK_USAGE%)"
    fi
}

# Check memory usage
check_memory() {
    log_message "Checking memory usage..."
    
    # Get memory usage percentage
    MEM_USAGE=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
    
    if [ "$MEM_USAGE" -gt 90 ]; then
        log_message "WARNING: Memory usage is critically high ($MEM_USAGE%)"
        send_alert "[$HOSTNAME] Memory usage critical" "Memory usage is at $MEM_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$MEM_USAGE" -gt 80 ]; then
        log_message "WARNING: Memory usage is high ($MEM_USAGE%)"
    else
        log_message "Memory usage is OK ($MEM_USAGE%)"
    fi
}

# Check load average
check_load() {
    log_message "Checking system load..."
    
    # Get number of CPU cores
    CPU_CORES=$(nproc)
    
    # Get load average for 1 minute
    LOAD_AVG=$(cat /proc/loadavg | awk '{print $1}')
    
    # Calculate load per core
    LOAD_PER_CORE=$(echo "$LOAD_AVG / $CPU_CORES" | bc -l)
    
    if (( $(echo "$LOAD_PER_CORE > 2.0" | bc -l) )); then
        log_message "WARNING: System load is critically high (${LOAD_AVG})"
        send_alert "[$HOSTNAME] System load critical" "System load is at ${LOAD_AVG} (${LOAD_PER_CORE} per core) on $HOSTNAME at $DATE $TIME"
    elif (( $(echo "$LOAD_PER_CORE > 1.0" | bc -l) )); then
        log_message "WARNING: System load is high (${LOAD_AVG})"
    else
        log_message "System load is OK (${LOAD_AVG})"
    fi
}

# Check for failed login attempts
check_failed_logins() {
    log_message "Checking for failed login attempts..."
    
    # Count failed SSH login attempts in the last hour
    FAILED_LOGINS=$(grep "Failed password" /var/log/auth.log | grep -c "$(date +%b' '%d' '%H)")
    
    if [ "$FAILED_LOGINS" -gt 10 ]; then
        log_message "WARNING: High number of failed login attempts ($FAILED_LOGINS in the last hour)"
        send_alert "[$HOSTNAME] Security alert" "High number of failed login attempts ($FAILED_LOGINS in the last hour) on $HOSTNAME at $DATE $TIME"
    elif [ "$FAILED_LOGINS" -gt 5 ]; then
        log_message "WARNING: Multiple failed login attempts ($FAILED_LOGINS in the last hour)"
    else
        log_message "Failed login attempts are OK ($FAILED_LOGINS in the last hour)"
    fi
}

# Check HTTP response
check_http_response() {
    log_message "Checking HTTP response..."
    
    # Get HTTP status code
    HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost)
    
    if [ "$HTTP_STATUS" != "200" ]; then
        log_message "ERROR: HTTP response is not OK (status code: $HTTP_STATUS)"
        send_alert "[$HOSTNAME] Website is down" "Website returned HTTP status code $HTTP_STATUS on $HOSTNAME at $DATE $TIME"
    else
        log_message "HTTP response is OK (status code: $HTTP_STATUS)"
    fi
}

# Main function
main() {
    log_message "Starting monitoring check..."
    
    check_services
    check_disk_space
    check_memory
    check_load
    check_failed_logins
    check_http_response
    
    log_message "Monitoring check completed"
}

# Create logs directory if it doesn't exist
mkdir -p "$LOGS_DIR"

# Run main function
main
EOL
    
    # Make monitoring script executable
    chmod +x "$PROJECT_DIR/scripts/monitor.sh"
    
    # Set up cron job for monitoring every 15 minutes
    (crontab -l 2>/dev/null; echo "*/15 * * * * $PROJECT_DIR/scripts/monitor.sh > /dev/null 2>&1") | crontab -
    
    log_message "${GREEN}Monitoring system set up successfully${NC}"
}

# Function to create Docker configuration
setup_docker() {
    log_message "${BLUE}Setting up Docker configuration...${NC}"
    
    # Check if Docker is installed
    if ! command -v docker &> /dev/null; then
        log_message "${YELLOW}Docker is not installed. Installing Docker...${NC}"
        
        if [ "$DISTRO" = "debian" ]; then
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release >> "$LOG_FILE" 2>&1
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
            echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        elif [ "$DISTRO" = "rhel" ]; then
            yum install -y yum-utils >> "$LOG_FILE" 2>&1
            yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo >> "$LOG_FILE" 2>&1
            yum install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        fi
        
        systemctl start docker
        systemctl enable docker
    fi
    
    # Check if Docker Compose is installed
    if ! command -v docker-compose &> /dev/null; then
        log_message "${YELLOW}Docker Compose is not installed. Installing Docker Compose...${NC}"
        
        curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        chmod +x /usr/local/bin/docker-compose
    fi
    
    # Create Docker Compose configuration
    cat > "$PROJECT_DIR/docker-compose.yml" << 'EOL'
version: '3'

services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    volumes:
      - ./www:/usr/share/nginx/html
      - ./configs/nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - php
    networks:
      - webapp

  php:
    image: php:7.4-fpm
    volumes:
      - ./www:/var/www/html
    networks:
      - webapp

  db:
    image: mariadb:latest
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MYSQL_DATABASE: ${DB_NAME}
      MYSQL_USER: ${DB_USER}
      MYSQL_PASSWORD: ${DB_PASSWORD}
    volumes:
      - db_data:/var/lib/mysql
    networks:
      - webapp

networks:
  webapp:

volumes:
  db_data:
EOL
    
    # Create Nginx configuration for Docker
    mkdir -p "$CONFIG_DIR"
    cat > "$CONFIG_DIR/nginx.conf" << 'EOL'
server {
    listen 80;
    server_name localhost;
    
    root /usr/share/nginx/html;
    index index.php index.html;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        fastcgi_pass php:9000;
        fastcgi_index index.php;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        include fastcgi_params;
    }
}
EOL
    
    # Create .env file for Docker Compose
    cat > "$PROJECT_DIR/.env" << EOF
DB_ROOT_PASSWORD=$(grep "Database Root Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f4)
DB_NAME=$(grep "Database Name:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_USER=$(grep "Database User:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_PASSWORD=$(grep "Database Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
EOF
    
    # Create sample index.php file for Docker
    mkdir -p "$WWW_DIR"
    cat > "$WWW_DIR/index.php" << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Docker Web Server</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Docker Web Server Deployment Successful!</h1>
        <p>This page confirms that your Docker web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>Database Connection Test</h2>
        <?php
        $host = 'db';
        $dbname = getenv('DB_NAME');
        $user = getenv('DB_USER');
        $pass = getenv('DB_PASSWORD');
        
        try {
            $conn = new PDO("mysql:host=$host;dbname=$dbname", $user, $pass);
            $conn->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
            echo '<p style="color: green;">Database connection successful!</p>';
        } catch(PDOException $e) {
            echo '<p style="color: red;">Database connection failed: ' . $e->getMessage() . '</p>';
        }
        ?>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Create Docker start script
    cat > "$PROJECT_DIR/scripts/start-docker.sh" << 'EOL'
#!/bin/bash
# start-docker.sh - Start Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose up -d

echo "Docker containers started. Access the web server at http://localhost:8080"
EOL
    
    # Create Docker stop script
    cat > "$PROJECT_DIR/scripts/stop-docker.sh" << 'EOL'
#!/bin/bash
# stop-docker.sh - Stop Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose down

echo "Docker containers stopped"
EOL
    
    # Make Docker scripts executable
    chmod +x "$PROJECT_DIR/scripts/start-docker.sh"
    chmod +x "$PROJECT_DIR/scripts/stop-docker.sh"
    
    log_message "${GREEN}Docker configuration set up successfully${NC}"
    log_message "${YELLOW}To start Docker containers, run: $PROJECT_DIR/scripts/start-docker.sh${NC}"
    log_message "${YELLOW}To stop Docker containers, run: $PROJECT_DIR/scripts/stop-docker.sh${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}Web Server Deployment Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Server IP:${NC} $ip_address"
    echo -e "${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}Docker Web Server:${NC} http://$ip_address:8080 (when Docker is running)"
    echo -e "\n${YELLOW}Database Credentials:${NC} $CONFIG_DIR/db_credentials.txt"
    echo -e "${YELLOW}SSH Key for webadmin:${NC} /home/webadmin/.ssh/id_ed25519"
    echo -e "\n${YELLOW}Scripts:${NC}"
    echo -e "  Backup: $PROJECT_DIR/scripts/backup.sh"
    echo -e "  Monitor: $PROJECT_DIR/scripts/monitor.sh"
    echo -e "  Docker Start: $PROJECT_DIR/scripts/start-docker.sh"
    echo -e "  Docker Stop: $PROJECT_DIR/scripts/stop-docker.sh"
    echo -e "\n${YELLOW}Logs:${NC} $LOGS_DIR"
    echo -e "${YELLOW}Backups:${NC} $BACKUP_DIR"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}Deployment log: $LOG_FILE${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Create directories
    mkdir -p "$CONFIG_DIR" "$LOGS_DIR" "$BACKUP_DIR" "$WWW_DIR"
    
    # Check if running as root
    check_root
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      WEB SERVER DEPLOYMENT SCRIPT     ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages
    install_packages
    
    # Create web server user
    create_web_user
    
    # Configure services
    configure_nginx
    configure_mariadb
    configure_php
    configure_firewall
    configure_fail2ban
    configure_logrotate
    
    # Set up scripts
    setup_backup
    setup_monitoring
    setup_docker
    
    # Display summary
    display_summary
    
    log_message "${GREEN}Web server deployment completed successfully${NC}"
}

# Run main function
main
Make the script executable:

```bash chmod +x ~/web-server-project/scripts/deploy.sh


#### Step 3: Run the Deployment Script

\`\`\`bash
sudo ~/web-server-project/scripts/deploy.sh
This script will:

Install and configure a web server (Nginx, MariaDB, PHP)
Set up a dedicated web server user with SSH key authentication
Configure firewall rules and fail2ban for security
Set up log rotation for proper log management
Create backup and monitoring scripts with cron jobs
Set up Docker and Docker Compose for containerized deployment
Generate a comprehensive deployment report
Step 4: Test the Deployment
After the script completes, you can test the deployment by:

Accessing the web server at http://your-server-ip
Starting the Docker containers with ~/web-server-project/scripts/start-docker.sh
Accessing the containerized web server at http://your-server-ip:8080
Testing the backup script with ~/web-server-project/scripts/backup.sh
Testing the monitoring script with ~/web-server-project/scripts/monitor.sh
Step 5: Document the Project
Create a README.md file for the project:

```markdown

Automated Web Server Deployment and Monitoring System
Overview
This project provides a comprehensive system for deploying, securing, and monitoring a web server environment. It includes automated scripts for installation, configuration, backup, and monitoring.

Features
Automated deployment of Nginx, MariaDB, and PHP
User management with secure SSH key authentication
Firewall configuration and intrusion prevention with fail2ban
Log rotation and management
Automated backup system
Comprehensive monitoring system
Containerized deployment with Docker and Docker Compose
Directory Structure
scripts/ - Contains all automation scripts

deploy.sh - Main deployment script
backup.sh - Automated backup script
monitor.sh - System monitoring script
start-docker.sh - Start Docker containers
stop-docker.sh - Stop Docker containers
configs/ - Configuration files
logs/ - Log files
backups/ - Backup files
www/ - Web files for Docker deployment
Usage
Initial Deployment
```bash sudo ./scripts/deploy.sh


### Managing Backups

\`\`\`bash
# Run a manual backup
./scripts/backup.sh

# Restore from backup
tar -xzf backups/backup_YYYYMMDD_HHMMSS.tar.gz -C /var/www/html
Monitoring
```bash

Run a manual monitoring check
./scripts/monitor.sh


### Docker Deployment

\`\`\`bash
# Start Docker containers
./scripts/start-docker.sh

# Stop Docker containers
./scripts/stop-docker.sh
Security Features
Dedicated web server user with restricted permissions
SSH key authentication
Firewall rules allowing only necessary services
Fail2ban for intrusion prevention
Secure database configuration
HTTPS support
Monitoring Features
Service status monitoring
Disk space monitoring
Memory usage monitoring
System load monitoring
Failed login attempts monitoring
HTTP response monitoring
Backup System
Daily automated backups
Database and file system backups
Rotation system to manage backup storage
Requirements
Ubuntu 20.04 LTS or CentOS 8
Sudo/root access
Internet connection for package installation
License
This project is licensed under the MIT License - see the LICENSE file for details.


#### Day 7 Learning Outcomes

By completing this capstone project, you should be able to:

1. Deploy and configure a complete web server environment
2. Implement proper security measures for a production server
3. Set up automated monitoring and alerting
4. Create a comprehensive backup and recovery system
5. Containerize an application for easy deployment
6. Document a complex system for future reference
7. Apply all the skills learned in Week 1 to a real-world project

#### Additional Resources for Day 7

- [Nginx Documentation](https://nginx.org/en/docs/)
- [MariaDB Documentation](https://mariadb.com/kb/en/documentation/)
- [PHP Documentation](https://www.php.net/docs.php)
- [Docker Documentation](https://docs.docker.com/)
- [Linux Server Security Guide](https://www.digitalocean.com/community/tutorials/7-security-measures-to-protect-your-servers)

## Week 2: Advanced System Administration

In Week 2, we'll build on the foundation established in Week 1 and dive into more advanced system administration topics. This week focuses on advanced shell scripting, system performance, security, networking, storage, and high availability.

### Day 8: Advanced Shell Scripting

Shell scripting is a powerful tool for automating complex tasks. In this section, we'll explore advanced shell scripting techniques that will make your scripts more robust, efficient, and maintainable.

#### Advanced Bash Features

**Bash Arrays:**

\`\`\`bash
# Indexed arrays
declare -a fruits=("Apple" "Banana" "Orange" "Mango")
echo "First fruit: ${fruits[0]}"
echo "All fruits: ${fruits[@]}"
echo "Number of fruits: ${#fruits[@]}"

# Iterating through array
for fruit in "${fruits[@]}"; do
    echo "Processing $fruit"
done

# Array operations
fruits+=(["Pineapple" "Grape"])  # Add elements
unset fruits[1]                  # Remove element
fruits=("${fruits[@]}")          # Reindex array

# Associative arrays (dictionaries)
declare -A user_info
user_info[name]="John"
user_info[age]=30
user_info[city]="New York"

echo "Name: ${user_info[name]}"
echo "Age: ${user_info[age]}"

# Iterating through associative array
for key in "${!user_info[@]}"; do
    echo "$key: ${user_info[$key]}"
done
String Manipulation:

```bash

String length
string="Hello, World!" echo "Length: ${#string}"

Substring extraction
echo "Substring: ${string:7:5}" # Start at position 7, length 5

String replacement
echo "Replace first: ${string/o/O}" # Replace first occurrence echo "Replace all: ${string//o/O}" # Replace all occurrences echo "Replace prefix: ${string/#Hello/Hi}" # Replace at beginning echo "Replace suffix: ${string/%World/Earth}" # Replace at end

Case conversion
echo "Uppercase: ${string^^}" echo "Lowercase: ${string,,}" echo "First char uppercase: ${string^}" echo "First char lowercase: ${string,}"

String trimming
string=" Hello, World! " echo "Trim leading spaces: ${string#"${string%%[![:space:]]}"}" echo "Trim trailing spaces: ${string%"${string##[![:space:]]}"}"


**Parameter Expansion and Default Values:**

\`\`\`bash
# Default values
name=${1:-"Anonymous"}  # Use $1 if set, otherwise "Anonymous"
echo "Hello, $name"

# Default assignment
count=${count:=0}  # Assign 0 to count if it's unset or null

# Error if unset
required=${required:?"Required parameter is missing"}

# Use alternate value
optional=${optional:+"Optional parameter is set to: $optional"}

# Substring removal
filename="script.test.sh"
echo "Remove prefix: ${filename#*.}"      # Remove shortest match from beginning
echo "Remove prefix: ${filename##*.}"     # Remove longest match from beginning
echo "Remove suffix: ${filename%.*}"      # Remove shortest match from end
echo "Remove suffix: ${filename%%.*}"     # Remove longest match from end
Brace Expansion:

```bash

Range expansion
echo {1..10} # 1 2 3 4 5 6 7 8 9 10 echo {a..z} # a b c d ... z echo {01..10..2} # 01 03 05 07 09

String combinations
echo {apple,banana,cherry} echo file.{txt,md,pdf} echo {2023..2025}-{01..12}

Nested brace expansion
echo {a,b{1,2,3},c} # a b1 b2 b3 c


**Process Substitution:**

\`\`\`bash
# Use command output as file
diff <(ls -l /etc) <(ls -l /tmp)
grep "pattern" <(cat file1.txt file2.txt)

# Feed command output to another command
cat <(echo "Header") file.txt <(echo "Footer")

# Multiple process substitutions
paste <(cut -f1 data.txt) <(cut -f3 data.txt)
Advanced Error Handling
Trap Command for Signal Handling:

```bash #!/bin/bash

Temporary files
TEMP_FILE1=$(mktemp) TEMP_FILE2=$(mktemp)

Cleanup function
cleanup() { echo "Cleaning up temporary files..." rm -f "$TEMP_FILE1" "$TEMP_FILE2" exit }

Trap signals
trap cleanup EXIT INT TERM

Trap specific signals with different handlers
trap 'echo "Received SIGINT"; cleanup' INT trap 'echo "Received SIGTERM"; cleanup' TERM

Rest of the script
echo "Script is running..." echo "Temporary files: $TEMP_FILE1 $TEMP_FILE2" echo "Sleeping for 30 seconds. Try pressing Ctrl+C..." sleep 30 echo "Script completed normally."


**Advanced Error Handling:**

\`\`\`bash
#!/bin/bash

# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Enable debug mode
# set -x

# Error handling function
error_exit() {
    local line=$1
    local command=$2
    local code=${3:-1}
    echo "Error on line $line running command '$command', exit code $code" >&2
    exit $code
}

# Trap errors
trap 'error_exit $LINENO "$BASH_COMMAND" $?' ERR

# Function with error checking
run_command() {
    local cmd=$1
    local error_msg=${2:-"Command failed"}
    
    echo "Running: $cmd"
    if ! eval "$cmd"; then
        echo "$error_msg" >&2
        return 1
    fi
    return 0
}

# Example usage
run_command "ls -la /etc" "Failed to list /etc directory"
run_command "ls -la /nonexistent" "Failed to list nonexistent directory" || echo "Continuing despite error"

# This will trigger the error trap
cat /nonexistent/file.txt

echo "This line will not be executed due to the error above"
Advanced Input/Output
Here Documents and Here Strings:

```bash

Here document (heredoc)
cat << EOF > output.txt This is a multi-line text block that will be written to output.txt. Current date: $(date) EOF

Here document with variable substitution disabled
cat << 'EOF' > script.sh #!/bin/bash echo "The current date is $(date)" echo "My home directory is $HOME" EOF

Here document with custom delimiter
cat << 'CUSTOM_DELIMITER' > config.ini [database] host=localhost user=dbuser password=secret123 CUSTOM_DELIMITER

Here document with indentation preserved
cat <<- EOF > indented.txt This text will have leading tabs removed. This line has two tabs, which will be removed. But the relative indentation is preserved. EOF

Here string
grep "pattern" <<< "This is a string to search for pattern" while read -r line; do echo "Line: $line" done <<< "Line 1 Line 2 Line 3"


**Advanced File Descriptors:**

\`\`\`bash
#!/bin/bash

# Redirect stdout to a file
exec 1>output.log

# Redirect stderr to a file
exec 2>error.log

# Create a new file descriptor for a file
exec 3>custom.log

# Write to custom file descriptor
echo "This goes to custom.log" >&3

# Create a file descriptor for reading
exec 4<input.txt

# Read from custom file descriptor
read -r line <&4
echo "Read from input.txt: $line"

# Duplicate file descriptors
exec 5>&1  # Save stdout to fd 5
exec 1>combined.log  # Redirect stdout to file
echo "This goes to combined.log"
exec 1>&5  # Restore stdout
echo "This goes to the terminal"

# Close file descriptors
exec 3>&-
exec 4<&-
exec 5>&-
Capturing Command Output:

```bash

Basic command substitution
current_date=$(date +%Y-%m-%d) echo "Today is $current_date"

Capturing exit status
if output=$(some_command 2>&1); then echo "Command succeeded: $output" else echo "Command failed with status $?: $output" fi

Capturing both stdout and stderr separately
{ stdout=$(eval "$cmd" 2>/tmp/stderr.) status=$? stderr=$(cat /tmp/stderr.) rm /tmp/stderr.$$ }

Using a function to capture output
capture_output() { local cmd=$1 local stdout_var=$2 local stderr_var=$3 local status_var=$4

local stdout_file=$(mktemp)
local stderr_file=$(mktemp)

eval "$cmd" > "$stdout_file" 2> "$stderr_file"
local status=$?

eval "$stdout_var='$(cat "$stdout_file")'"
eval "$stderr_var='$(cat "$stderr_file")'"
eval "$status_var=$status"

rm -f "$stdout_file" "$stderr_file"
return $status
}

Example usage
capture_output "ls -la" STDOUT STDERR STATUS echo "Exit status: $STATUS" echo "Standard output: $STDOUT" echo "Standard error: $STDERR"


#### Advanced Control Structures

**Select Loop for Menus:**

\`\`\`bash
#!/bin/bash

echo "Select a fruit:"
select fruit in "Apple" "Banana" "Orange" "Quit"; do
    case $fruit in
        "Apple")
            echo "You selected Apple"
            ;;
        "Banana")
            echo "You selected Banana"
            ;;
        "Orange")
            echo "You selected Orange"
            ;;
        "Quit")
            echo "Exiting..."
            break
            ;;
        *)
            echo "Invalid selection"
            ;;
    esac
done
Advanced Case Statements:

```bash #!/bin/bash

read -p "Enter a value: " input

case $input in [0-9]) echo "You entered a single digit" ;; [0-9][0-9]) echo "You entered a two-digit number" ;; [0-9][0-9][0-9]) echo "You entered a three-digit number" ;; [a-zA-Z]) echo "You entered a string starting with a letter" ;; [0-9]) echo "You entered a string ending with a digit" ;; @.) echo "You entered what looks like an email address" ;; .txt|.md|.doc) echo "You entered a document filename" ;; *) echo "I don't recognize the pattern of your input" ;; esac


**Advanced Loops:**

\`\`\`bash
#!/bin/bash

# Loop with step value
for ((i=0; i&lt;=20; i+=5)); do
    echo "i = $i"
done

# Loop with multiple variables
for ((i=1, j=10; i&lt;=5; i++, j--)); do
    echo "i = $i, j = $j"
done

# Loop with early termination and continuation
for file in /etc/*.conf; do
    # Skip if not a regular file
    [ -f "$file" ] || continue
    
    # Skip files larger than 10KB
    size=$(du -k "$file" | cut -f1)
    [ "$size" -gt 10 ] && continue
    
    # Process file
    echo "Processing $file (size: ${size}KB)"
    
    # Break if we've processed 5 files
    ((count++))
    [ "$count" -ge 5 ] && break
done

# Loop with named iteration
while IFS=: read -r username password uid gid info home shell; do
    # Skip system users
    [ "$uid" -lt 1000 ] && continue
    
    echo "User: $username"
    echo "  UID: $uid"
    echo "  Home: $home"
    echo "  Shell: $shell"
done &lt; /etc/passwd
Advanced Functions
Functions with Return Values:

```bash #!/bin/bash

Function with return code
is_number() { local input=$1 [[ $input =~ ^[0-9]+$ ]] return $? }

Function that returns a value via echo
get_user_home() { local username=$1 local home=$(grep "^$username:" /etc/passwd | cut -d: -f6) echo "$home" }

Function with multiple return values
get_file_info() { local file=$1 if [ ! -f "$file" ]; then echo "" echo "" return 1 fi

local size=$(du -h "$file" | cut -f1)
local type=$(file -b "$file")

echo "$size"
echo "$type"
return 0
}

Example usage
if is_number "123"; then echo "123 is a number" else echo "123 is not a number" fi

home_dir=$(get_user_home "root") echo "Root's home directory: $home_dir"

Capturing multiple return values
read -r file_size file_type < <(get_file_info "/etc/passwd") if [ -n "$file_size" ]; then echo "File size: $file_size" echo "File type: $file_type" else echo "File not found" fi


**Function Libraries:**

\`\`\`bash
#!/bin/bash
# file: lib_string.sh

# String utility functions

# Convert string to lowercase
to_lowercase() {
    local input=$1
    echo "${input,,}"
}

# Convert string to uppercase
to_uppercase() {
    local input=$1
    echo "${input^^}"
}

# Trim whitespace from string
trim() {
    local input=$1
    # Remove leading whitespace
    input="${input#"${input%%[![:space:]]*}"}"
    # Remove trailing whitespace
    input="${input%"${input##*[![:space:]]}"}"
    echo "$input"
}

# Check if string contains substring
contains() {
    local string=$1
    local substring=$2
    [[ "$string" == *"$substring"* ]]
    return $?
}

# Count occurrences of substring in string
count_occurrences() {
    local string=$1
    local substring=$2
    local count=$(grep -o "$substring" <<< "$string" | wc -l)
    echo "$count"
}

# Replace substring in string
replace_string() {
    local string=$1
    local search=$2
    local replace=$3
    echo "${string//$search/$replace}"
}
```bash #!/bin/bash

file: lib_file.sh
File utility functions
Check if file exists and is readable
is_readable_file() { local file=$1 [ -f "$file" ] && [ -r "$file" ] return $? }

Get file size in human-readable format
get_file_size() { local file=$1 if is_readable_file "$file"; then du -h "$file" | cut -f1 else echo "0" fi }

Count lines in file
count_lines() { local file=$1 if is_readable_file "$file"; then wc -l < "$file" else echo "0" fi }

Get file modification time
get_file_mtime() { local file=$1 if is_readable_file "$file"; then stat -c %y "$file" else echo "" fi }

Create backup of file
backup_file() { local file=$1 local backup="${file}.bak" if is_readable_file "$file"; then cp -f "$file" "$backup" return $? else return 1 fi }


\`\`\`bash
#!/bin/bash
# file: main.sh

# Source function libraries
source ./lib_string.sh
source ./lib_file.sh

# Example usage
filename="/etc/passwd"

# String functions
echo "Lowercase: $(to_lowercase "HELLO World")"
echo "Uppercase: $(to_uppercase "hello World")"
echo "Trimmed: '$(trim "  hello world  ")'"

if contains "hello world" "world"; then
    echo "String contains 'world'"
fi

echo "Occurrences of 'o': $(count_occurrences "hello world" "o")"
echo "Replaced: $(replace_string "hello world" "world" "universe")"

# File functions
if is_readable_file "$filename"; then
    echo "File size: $(get_file_size "$filename")"
    echo "Line count: $(count_lines "$filename")"
    echo "Modified: $(get_file_mtime "$filename")"
    
    if backup_file "$filename"; then
        echo "Backup created: ${filename}.bak"
    fi
else
    echo "File $filename is not readable"
fi
Advanced Script Organization
Modular Script Design:

```bash #!/bin/bash

file: config.sh
Configuration variables
APP_NAME="MyApp" APP_VERSION="1.0.0" LOG_DIR="/var/log/$APP_NAME" CONFIG_DIR="/etc/$APP_NAME" DATA_DIR="/var/lib/$APP_NAME" TEMP_DIR="/tmp/$APP_NAME"

Default settings
DEBUG_MODE=false VERBOSE_MODE=false MAX_RETRIES=3 TIMEOUT=30


\`\`\`bash
#!/bin/bash
# file: utils.sh

# Source configuration
source ./config.sh

# Utility functions

# Logging function
log() {
    local level=$1
    local message=$2
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    
    # Create log directory if it doesn't exist
    mkdir -p "$LOG_DIR"
    
    # Log to file
    echo "[$timestamp] [$level] $message" >> "$LOG_DIR/app.log"
    
    # Log to console if verbose mode is enabled
    if [ "$VERBOSE_MODE" = true ] || [ "$level" = "ERROR" ]; then
        echo "[$timestamp] [$level] $message"
    fi
}

# Debug logging
debug() {
    if [ "$DEBUG_MODE" = true ]; then
        log "DEBUG" "$1"
    fi
}

# Info logging
info() {
    log "INFO" "$1"
}

# Warning logging
warn() {
    log "WARNING" "$1"
}

# Error logging
error() {
    log "ERROR" "$1"
}

# Create required directories
create_dirs() {
    mkdir -p "$LOG_DIR" "$CONFIG_DIR" "$DATA_DIR" "$TEMP_DIR"
    
    # Check if directories were created successfully
    if [ ! -d "$LOG_DIR" ] || [ ! -d "$CONFIG_DIR" ] || [ ! -d "$DATA_DIR" ] || [ ! -d "$TEMP_DIR" ]; then
        error "Failed to create required directories"
        return 1
    fi
    
    debug "Created required directories"
    return 0
}

# Clean up temporary files
cleanup() {
    debug "Cleaning up temporary files"
    rm -rf "$TEMP_DIR"/*
    debug "Cleanup completed"
}
```bash #!/bin/bash

file: app.sh
Source configuration and utilities
source ./config.sh source ./utils.sh

Parse command line arguments
parse_args() { while [[ $# -gt 0 ]]; do case $1 in --debug) DEBUG_MODE=true shift ;; --verbose) VERBOSE_MODE=true shift ;; --config=) CONFIG_FILE="${1#=}" shift ;; --help) show_help exit 0 ;; *) error "Unknown option: $1" show_help exit 1 ;; esac done }

Show help message
show_help() { echo "Usage: $0 [options]" echo echo "Options:" echo " --debug Enable debug mode" echo " --verbose Enable verbose output" echo " --config=FILE Use specified config file" echo " --help Show this help message" }

Main application function
main() { info "Starting $APP_NAME v$APP_VERSION"

# Parse command line arguments
parse_args "$@"

# Create required directories
if ! create_dirs; then
    error "Failed to initialize application"
    exit 1
fi

# Set up cleanup on exit
trap cleanup EXIT

# Application logic here
info "Application initialized successfully"
debug "Debug mode is enabled"

# Simulate some work
info "Performing task 1"
sleep 1

info "Performing task 2"
sleep 1

info "Application completed successfully"
return 0
}

Run main function with all arguments
main "$@"


#### Mini-Project: Advanced System Information Dashboard

Create a comprehensive system information dashboard script that uses advanced shell scripting techniques:

\`\`\`bash
#!/bin/bash
# system_dashboard.sh - Advanced System Information Dashboard

# Colors and formatting
RESET="\033[0m"
BOLD="\033[1m"
RED="\033[31m"
GREEN="\033[32m"
YELLOW="\033[33m"
BLUE="\033[34m"
MAGENTA="\033[35m"
CYAN="\033[36m"
WHITE="\033[37m"
BG_RED="\033[41m"
BG_GREEN="\033[42m"
BG_YELLOW="\033[43m"
BG_BLUE="\033[44m"

# Configuration
TEMP_DIR="/tmp/system_dashboard"
HISTORY_FILE="$TEMP_DIR/history.dat"
REFRESH_INTERVAL=5  # seconds
MAX_HISTORY=60      # data points to keep

# Create temporary directory
mkdir -p "$TEMP_DIR"

# Trap for cleanup
trap 'rm -rf "$TEMP_DIR"; echo -e "\n${GREEN}Dashboard terminated.${RESET}"; exit 0' EXIT INT TERM

# Function to print section header
print_header() {
    local title="$1"
    local width=$(tput cols)
    local padding=$(( (width - ${#title} - 4) / 2 ))
    
    echo -e "\n${BOLD}${BLUE}"
    printf "%${width}s" | tr ' ' '='
    printf "\n%${padding}s %s %${padding}s\n" "=" "$title" "="
    printf "%${width}s" | tr ' ' '='
    echo -e "${RESET}"
}

# Function to print formatted key-value pair
print_info() {
    local key="$1"
    local value="$2"
    local color="${3:-$WHITE}"
    
    printf "${BOLD}%-25s${RESET} : ${color}%s${RESET}\n" "$key" "$value"
}

# Function to print progress bar
print_progress_bar() {
    local value=$1
    local max=$2
    local width=50
    local title=$3
    local percentage=$((value * 100 / max))
    local filled=$((value * width / max))
    local empty=$((width - filled))
    
    # Choose color based on percentage
    local color=$GREEN
    if [ $percentage -gt 80 ]; then
        color=$RED
    elif [ $percentage -gt 60 ]; then
        color=$YELLOW
    fi
    
    printf "%-20s [${color}" "$title"
    printf "%${filled}s" | tr ' ' '#'
    printf "${RESET}"
    printf "%${empty}s" | tr ' ' ' '
    printf "] %3d%%\n" $percentage
}

# Function to get system information
get_system_info() {
    print_header "SYSTEM INFORMATION"
    
    # Hostname and kernel
    print_info "Hostname" "$(hostname)" $CYAN
    print_info "Kernel" "$(uname -r)" $CYAN
    print_info "Operating System" "$(grep PRETTY_NAME /etc/os-release 2>/dev/null | cut -d= -f2 | tr -d '"')" $CYAN
    print_info "Architecture" "$(uname -m)" $CYAN
    
    # Uptime
    local uptime_seconds=$(cat /proc/uptime | awk '{print $1}' | cut -d. -f1)
    local uptime_days=$((uptime_seconds / 86400))
    local uptime_hours=$(((uptime_seconds % 86400) / 3600))
    local uptime_minutes=$(((uptime_seconds % 3600) / 60))
    print_info "Uptime" "${uptime_days}d ${uptime_hours}h ${uptime_minutes}m" $CYAN
    
    # Last boot
    print_info "Last Boot" "$(who -b | awk '{print $3, $4}')" $CYAN
    
    # Load average
    local load=$(cat /proc/loadavg)
    local load_1m=$(echo $load | awk '{print $1}')
    local load_5m=$(echo $load | awk '{print $2}')
    local load_15m=$(echo $load | awk '{print $3}')
    
    local cpu_cores=$(nproc)
    local load_color=$GREEN
    
    if (( $(echo "$load_1m > $cpu_cores" | bc -l) )); then
        load_color=$RED
    elif (( $(echo "$load_1m > $cpu_cores * 0.7" | bc -l) )); then
        load_color=$YELLOW
    fi
    
    print_info "Load Average" "${load_1m} (1m), ${load_5m} (5m), ${load_15m} (15m)" $load_color
    print_info "CPU Cores" "$cpu_cores" $CYAN
}

# Function to get CPU information
get_cpu_info() {
    print_header "CPU INFORMATION"
    
    # CPU model
    local cpu_model=$(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')
    print_info "CPU Model" "$cpu_model" $CYAN
    
    # CPU usage
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2 + $4}')
    print_info "CPU Usage" "${cpu_usage}%" $([ $(echo "$cpu_usage > 80" | bc -l) -eq 1 ] && echo $RED || [ $(echo "$cpu_usage > 50" | bc -l) -eq 1 ] && echo $YELLOW || echo $GREEN)
    
    # CPU frequency
    if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq ]; then
        local cpu_freq=$(cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq)
        cpu_freq=$(echo "scale=2; $cpu_freq / 1000000" | bc)
        print_info "CPU Frequency" "${cpu_freq} GHz" $CYAN
    fi
    
    # CPU temperature
    if [ -f /sys/class/thermal/thermal_zone0/temp ]; then
        local cpu_temp=$(cat /sys/class/thermal/thermal_zone0/temp)
        cpu_temp=$(echo "scale=1; $cpu_temp / 1000" | bc)
        local temp_color=$GREEN
        if [ $(echo "$cpu_temp > 80" | bc -l) -eq 1 ]; then
            temp_color=$RED
        elif [ $(echo "$cpu_temp > 60" | bc -l) -eq 1 ]; then
            temp_color=$YELLOW
        fi
        print_info "CPU Temperature" "${cpu_temp}°C" $temp_color
    fi
    
    # CPU governor
    if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor ]; then
        local cpu_governor=$(cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor)
        print_info "CPU Governor" "$cpu_governor" $CYAN
    fi
    
    # Show CPU usage bar
    print_progress_bar ${cpu_usage%.*} 100 "CPU Usage"
    
    # Store CPU usage history
    echo "$(date +%s) $cpu_usage" >> "$TEMP_DIR/cpu_history.dat"
}

# Function to get memory information
get_memory_info() {
    print_header "MEMORY INFORMATION"
    
    # Get memory info
    local mem_total=$(grep MemTotal /proc/meminfo | awk '{print $2}')
    local mem_free=$(grep MemFree /proc/meminfo | awk '{print $2}')
    local mem_available=$(grep MemAvailable /proc/meminfo | awk '{print $2}')
    local mem_cached=$(grep "^Cached" /proc/meminfo | awk '{print $2}')
    local mem_buffers=$(grep "^Buffers" /proc/meminfo | awk '{print $2}')
    
    # Calculate used memory
    local mem_used=$((mem_total - mem_free - mem_cached - mem_buffers))
    local mem_used_percent=$((mem_used * 100 / mem_total))
    
    # Convert to human-readable format
    mem_total_hr=$(echo "scale=2; $mem_total / 1024 / 1024" | bc)
    mem_used_hr=$(echo "scale=2; $mem_used / 1024 / 1024" | bc)
    mem_free_hr=$(echo "scale=2; $mem_free / 1024 / 1024" | bc)
    mem_cached_hr=$(echo "scale=2; $mem_cached / 1024 / 1024" | bc)
    
    # Print memory information
    print_info "Total Memory" "${mem_total_hr} GB" $CYAN
    
    local mem_color=$GREEN
    if [ $mem_used_percent -gt 80 ]; then
        mem_color=$RED
    elif [ $mem_used_percent -gt 60 ]; then
        mem_color=$YELLOW
    fi
    
    print_info "Used Memory" "${mem_used_hr} GB (${mem_used_percent}%)" $mem_color
    print_info "Free Memory" "${mem_free_hr} GB" $CYAN
    print_info "Cached Memory" "${mem_cached_hr} GB" $CYAN
    
    # Get swap info
    local swap_total=$(grep SwapTotal /proc/meminfo | awk '{print $2}')
    local swap_free=$(grep SwapFree /proc/meminfo | awk '{print $2}')
    
    if [ $swap_total -gt 0 ]; then
        local swap_used=$((swap_total - swap_free))
        local swap_used_percent=$((swap_used * 100 / swap_total))
        
        # Convert to human-readable format
        swap_total_hr=$(echo "scale=2; $swap_total / 1024 / 1024" | bc)
        swap_used_hr=$(echo "scale=2; $swap_used / 1024 / 1024" | bc)
        
        local swap_color=$GREEN
        if [ $swap_used_percent -gt 50 ]; then
            swap_color=$RED
        elif [ $swap_used_percent -gt 25 ]; then
            swap_color=$YELLOW
        fi
        
        print_info "Total Swap" "${swap_total_hr} GB" $CYAN
        print_info "Used Swap" "${swap_used_hr} GB (${swap_used_percent}%)" $swap_color
        
        # Show swap usage bar
        print_progress_bar $swap_used_percent 100 "Swap Usage"
    else
        print_info "Swap" "Not configured" $YELLOW
    fi
    
    # Show memory usage bar
    print_progress_bar $mem_used_percent 100 "Memory Usage"
    
    # Store memory usage history
    echo "$(date +%s) $mem_used_percent" >> "$TEMP_DIR/mem_history.dat"
}

# Function to get disk information
get_disk_info() {
    print_header "DISK INFORMATION"
    
    # Get filesystem information
    echo -e "${BOLD}Filesystem Usage:${RESET}\n"
    
    # Print header
    printf "${BOLD}### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.4/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.4/fpm/php.ini"
    elif [ -f /etc/php/7.3/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.3/fpm/php.ini"
    elif [ -f /etc/php/7.2/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.2/fpm/php.ini"
    elif [ -f /etc/php.ini ]; then
        PHP_INI="/etc/php.ini"
    else
        log_message "${YELLOW}PHP configuration file not found${NC}"
        return
    fi
    
    # Backup original PHP configuration
    cp "$PHP_INI" "$PHP_INI.bak"
    
    # Update PHP configuration
    sed -i 's/^max_execution_time = .*/max_execution_time = 60/' "$PHP_INI"
    sed -i 's/^memory_limit = .*/memory_limit = 256M/' "$PHP_INI"
    sed -i 's/^upload_max_filesize = .*/upload_max_filesize = 20M/' "$PHP_INI"
    sed -i 's/^post_max_size = .*/post_max_size = 20M/' "$PHP_INI"
    sed -i 's/^;date.timezone.*/date.timezone = UTC/' "$PHP_INI"
    
    # Restart PHP-FPM
    if [ "$DISTRO" = "debian" ]; then
        systemctl restart php7.4-fpm 2>/dev/null || systemctl restart php7.3-fpm 2>/dev/null || systemctl restart php7.2-fpm
    elif [ "$DISTRO" = "rhel" ]; then
        systemctl restart php-fpm
    fi
    
    log_message "${GREEN}PHP configured successfully${NC}"
}

# Function to configure firewall
configure_firewall() {
    log_message "${BLUE}Configuring firewall...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Configure UFW
        ufw default deny incoming
        ufw default allow outgoing
        ufw allow ssh
        ufw allow http
        ufw allow https
        
        # Enable UFW
        echo "y" | ufw enable
        
        log_message "${GREEN}UFW firewall configured successfully${NC}"
    elif [ "$DISTRO" = "rhel" ]; then
        # Configure firewalld
        systemctl start firewalld
        systemctl enable firewalld
        
        firewall-cmd --permanent --add-service=ssh
        firewall-cmd --permanent --add-service=http
        firewall-cmd --permanent --add-service=https
        firewall-cmd --reload
        
        log_message "${GREEN}Firewalld configured successfully${NC}"
    fi
}

# Function to configure fail2ban
configure_fail2ban() {
    log_message "${BLUE}Configuring fail2ban...${NC}"
    
    # Create fail2ban configuration
    cat > /etc/fail2ban/jail.local << 'EOL'
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 5

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3

[nginx-http-auth]
enabled = true
filter = nginx-http-auth
port = http,https
logpath = /var/log/nginx/error.log
EOL
    
    # Restart fail2ban
    systemctl restart fail2ban
    systemctl enable fail2ban
    
    log_message "${GREEN}Fail2ban configured successfully${NC}"
}

# Function to set up log rotation
configure_logrotate() {
    log_message "${BLUE}Configuring log rotation...${NC}"
    
    # Create logrotate configuration for application logs
    cat > /etc/logrotate.d/webapp << 'EOL'
/var/www/html/logs/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 www-data www-data
    sharedscripts
    postrotate
        systemctl reload nginx
    endscript
}
EOL
    
    log_message "${GREEN}Log rotation configured successfully${NC}"
}

# Function to set up backup script
setup_backup() {
    log_message "${BLUE}Setting up backup system...${NC}"
    
    # Create backup script
    cat > "$PROJECT_DIR/scripts/backup.sh" << 'EOL'
#!/bin/bash
# backup.sh - Backup script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="/var/www/html"
DB_NAME="webapp"
DB_USER="webappuser"
DB_PASSWORD=$(grep "Database Password:" "$PROJECT_DIR/configs/db_credentials.txt" | cut -d' ' -f3)
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/backup_$DATE.tar.gz"
DB_BACKUP_FILE="$BACKUP_DIR/db_backup_$DATE.sql"

# Create backup directory if it doesn't exist
mkdir -p "$BACKUP_DIR"

# Backup database
mysqldump -u "$DB_USER" -p"$DB_PASSWORD" "$DB_NAME" > "$DB_BACKUP_FILE"

# Backup web files
tar -czf "$BACKUP_FILE" -C "$WWW_DIR" .

# Add database backup to archive
tar -rf "${BACKUP_FILE%.tar.gz}.tar" -C "$BACKUP_DIR" "$(basename "$DB_BACKUP_FILE")"
gzip -f "${BACKUP_FILE%.tar.gz}.tar"

# Remove temporary database backup file
rm "$DB_BACKUP_FILE"

# Keep only the last 7 backups
ls -t "$BACKUP_DIR"/backup_*.tar.gz | tail -n +8 | xargs -r rm

echo "Backup completed: $BACKUP_FILE"
EOL
    
    # Make backup script executable
    chmod +x "$PROJECT_DIR/scripts/backup.sh"
    
    # Set up cron job for daily backups
    (crontab -l 2>/dev/null; echo "0 2 * * * $PROJECT_DIR/scripts/backup.sh > $LOGS_DIR/backup.log 2>&1") | crontab -
    
    log_message "${GREEN}Backup system set up successfully${NC}"
}

# Function to set up monitoring script
setup_monitoring() {
    log_message "${BLUE}Setting up monitoring system...${NC}"
    
    # Create monitoring script
    cat > "$PROJECT_DIR/scripts/monitor.sh" << 'EOL'
#!/bin/bash
# monitor.sh - Monitoring script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
LOGS_DIR="$PROJECT_DIR/logs"
MONITOR_LOG="$LOGS_DIR/monitor.log"
EMAIL_RECIPIENT="admin@example.com"
HOSTNAME=$(hostname)
DATE=$(date +%Y-%m-%d)
TIME=$(date +%H:%M:%S)

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo "$timestamp - $message" >> "$MONITOR_LOG"
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Check if services are running
check_services() {
    log_message "Checking services..."
    
    # Check Nginx
    if ! systemctl is-active --quiet nginx; then
        log_message "ERROR: Nginx is not running"
        send_alert "[$HOSTNAME] Nginx is down" "Nginx service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart nginx
    else
        log_message "Nginx is running"
    fi
    
    # Check MariaDB
    if ! systemctl is-active --quiet mariadb; then
        log_message "ERROR: MariaDB is not running"
        send_alert "[$HOSTNAME] MariaDB is down" "MariaDB service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart mariadb
    else
        log_message "MariaDB is running"
    fi
    
    # Check PHP-FPM
    if ! systemctl is-active --quiet php7.4-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.3-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.2-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php-fpm 2>/dev/null; then
        log_message "ERROR: PHP-FPM is not running"
        send_alert "[$HOSTNAME] PHP-FPM is down" "PHP-FPM service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart php7.4-fpm 2>/dev/null || 
        systemctl restart php7.3-fpm 2>/dev/null || 
        systemctl restart php7.2-fpm 2>/dev/null || 
        systemctl restart php-fpm 2>/dev/null
    else
        log_message "PHP-FPM is running"
    fi
}

# Check disk space
check_disk_space() {
    log_message "Checking disk space..."
    
    # Get disk usage percentage
    DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ "$DISK_USAGE" -gt 90 ]; then
        log_message "WARNING: Disk space is critically low ($DISK_USAGE%)"
        send_alert "[$HOSTNAME] Disk space critical" "Disk space usage is at $DISK_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$DISK_USAGE" -gt 80 ]; then
        log_message "WARNING: Disk space is running low ($DISK_USAGE%)"
    else
        log_message "Disk space is OK ($DISK_USAGE%)"
    fi
}

# Check memory usage
check_memory() {
    log_message "Checking memory usage..."
    
    # Get memory usage percentage
    MEM_USAGE=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
    
    if [ "$MEM_USAGE" -gt 90 ]; then
        log_message "WARNING: Memory usage is critically high ($MEM_USAGE%)"
        send_alert "[$HOSTNAME] Memory usage critical" "Memory usage is at $MEM_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$MEM_USAGE" -gt 80 ]; then
        log_message "WARNING: Memory usage is high ($MEM_USAGE%)"
    else
        log_message "Memory usage is OK ($MEM_USAGE%)"
    fi
}

# Check load average
check_load() {
    log_message "Checking system load..."
    
    # Get number of CPU cores
    CPU_CORES=$(nproc)
    
    # Get load average for 1 minute
    LOAD_AVG=$(cat /proc/loadavg | awk '{print $1}')
    
    # Calculate load per core
    LOAD_PER_CORE=$(echo "$LOAD_AVG / $CPU_CORES" | bc -l)
    
    if (( $(echo "$LOAD_PER_CORE > 2.0" | bc -l) )); then
        log_message "WARNING: System load is critically high (${LOAD_AVG})"
        send_alert "[$HOSTNAME] System load critical" "System load is at ${LOAD_AVG} (${LOAD_PER_CORE} per core) on $HOSTNAME at $DATE $TIME"
    elif (( $(echo "$LOAD_PER_CORE > 1.0" | bc -l) )); then
        log_message "WARNING: System load is high (${LOAD_AVG})"
    else
        log_message "System load is OK (${LOAD_AVG})"
    fi
}

# Check for failed login attempts
check_failed_logins() {
    log_message "Checking for failed login attempts..."
    
    # Count failed SSH login attempts in the last hour
    FAILED_LOGINS=$(grep "Failed password" /var/log/auth.log | grep -c "$(date +%b' '%d' '%H)")
    
    if [ "$FAILED_LOGINS" -gt 10 ]; then
        log_message "WARNING: High number of failed login attempts ($FAILED_LOGINS in the last hour)"
        send_alert "[$HOSTNAME] Security alert" "High number of failed login attempts ($FAILED_LOGINS in the last hour) on $HOSTNAME at $DATE $TIME"
    elif [ "$FAILED_LOGINS" -gt 5 ]; then
        log_message "WARNING: Multiple failed login attempts ($FAILED_LOGINS in the last hour)"
    else
        log_message "Failed login attempts are OK ($FAILED_LOGINS in the last hour)"
    fi
}

# Check HTTP response
check_http_response() {
    log_message "Checking HTTP response..."
    
    # Get HTTP status code
    HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost)
    
    if [ "$HTTP_STATUS" != "200" ]; then
        log_message "ERROR: HTTP response is not OK (status code: $HTTP_STATUS)"
        send_alert "[$HOSTNAME] Website is down" "Website returned HTTP status code $HTTP_STATUS on $HOSTNAME at $DATE $TIME"
    else
        log_message "HTTP response is OK (status code: $HTTP_STATUS)"
    fi
}

# Main function
main() {
    log_message "Starting monitoring check..."
    
    check_services
    check_disk_space
    check_memory
    check_load
    check_failed_logins
    check_http_response
    
    log_message "Monitoring check completed"
}

# Create logs directory if it doesn't exist
mkdir -p "$LOGS_DIR"

# Run main function
main
EOL
    
    # Make monitoring script executable
    chmod +x "$PROJECT_DIR/scripts/monitor.sh"
    
    # Set up cron job for monitoring every 15 minutes
    (crontab -l 2>/dev/null; echo "*/15 * * * * $PROJECT_DIR/scripts/monitor.sh > /dev/null 2>&1") | crontab -
    
    log_message "${GREEN}Monitoring system set up successfully${NC}"
}

# Function to create Docker configuration
setup_docker() {
    log_message "${BLUE}Setting up Docker configuration...${NC}"
    
    # Check if Docker is installed
    if ! command -v docker &> /dev/null; then
        log_message "${YELLOW}Docker is not installed. Installing Docker...${NC}"
        
        if [ "$DISTRO" = "debian" ]; then
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release >> "$LOG_FILE" 2>&1
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
            echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        elif [ "$DISTRO" = "rhel" ]; then
            yum install -y yum-utils >> "$LOG_FILE" 2>&1
            yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo >> "$LOG_FILE" 2>&1
            yum install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        fi
        
        systemctl start docker
        systemctl enable docker
    fi
    
    # Check if Docker Compose is installed
    if ! command -v docker-compose &> /dev/null; then
        log_message "${YELLOW}Docker Compose is not installed. Installing Docker Compose...${NC}"
        
        curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        chmod +x /usr/local/bin/docker-compose
    fi
    
    # Create Docker Compose configuration
    cat > "$PROJECT_DIR/docker-compose.yml" << 'EOL'
version: '3'

services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    volumes:
      - ./www:/usr/share/nginx/html
      - ./configs/nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - php
    networks:
      - webapp

  php:
    image: php:7.4-fpm
    volumes:
      - ./www:/var/www/html
    networks:
      - webapp

  db:
    image: mariadb:latest
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MYSQL_DATABASE: ${DB_NAME}
      MYSQL_USER: ${DB_USER}
      MYSQL_PASSWORD: ${DB_PASSWORD}
    volumes:
      - db_data:/var/lib/mysql
    networks:
      - webapp

networks:
  webapp:

volumes:
  db_data:
EOL
    
    # Create Nginx configuration for Docker
    mkdir -p "$CONFIG_DIR"
    cat > "$CONFIG_DIR/nginx.conf" << 'EOL'
server {
    listen 80;
    server_name localhost;
    
    root /usr/share/nginx/html;
    index index.php index.html;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        fastcgi_pass php:9000;
        fastcgi_index index.php;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        include fastcgi_params;
    }
}
EOL
    
    # Create .env file for Docker Compose
    cat > "$PROJECT_DIR/.env" << EOF
DB_ROOT_PASSWORD=$(grep "Database Root Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f4)
DB_NAME=$(grep "Database Name:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_USER=$(grep "Database User:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_PASSWORD=$(grep "Database Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
EOF
    
    # Create sample index.php file for Docker
    mkdir -p "$WWW_DIR"
    cat > "$WWW_DIR/index.php" << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Docker Web Server</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Docker Web Server Deployment Successful!</h1>
        <p>This page confirms that your Docker web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>Database Connection Test</h2>
        <?php
        $host = 'db';
        $dbname = getenv('DB_NAME');
        $user = getenv('DB_USER');
        $pass = getenv('DB_PASSWORD');
        
        try {
            $conn = new PDO("mysql:host=$host;dbname=$dbname", $user, $pass);
            $conn->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
            echo '<p style="color: green;">Database connection successful!</p>';
        } catch(PDOException $e) {
            echo '<p style="color: red;">Database connection failed: ' . $e->getMessage() . '</p>';
        }
        ?>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Create Docker start script
    cat > "$PROJECT_DIR/scripts/start-docker.sh" << 'EOL'
#!/bin/bash
# start-docker.sh - Start Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose up -d

echo "Docker containers started. Access the web server at http://localhost:8080"
EOL
    
    # Create Docker stop script
    cat > "$PROJECT_DIR/scripts/stop-docker.sh" << 'EOL'
#!/bin/bash
# stop-docker.sh - Stop Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose down

echo "Docker containers stopped"
EOL
    
    # Make Docker scripts executable
    chmod +x "$PROJECT_DIR/scripts/start-docker.sh"
    chmod +x "$PROJECT_DIR/scripts/stop-docker.sh"
    
    log_message "${GREEN}Docker configuration set up successfully${NC}"
    log_message "${YELLOW}To start Docker containers, run: $PROJECT_DIR/scripts/start-docker.sh${NC}"
    log_message "${YELLOW}To stop Docker containers, run: $PROJECT_DIR/scripts/stop-docker.sh${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}Web Server Deployment Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Server IP:${NC} $ip_address"
    echo -e "${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}Docker Web Server:${NC} http://$ip_address:8080 (when Docker is running)"
    echo -e "\n${YELLOW}Database Credentials:${NC} $CONFIG_DIR/db_credentials.txt"
    echo -e "${YELLOW}SSH Key for webadmin:${NC} /home/webadmin/.ssh/id_ed25519"
    echo -e "\n${YELLOW}Scripts:${NC}"
    echo -e "  Backup: $PROJECT_DIR/scripts/backup.sh"
    echo -e "  Monitor: $PROJECT_DIR/scripts/monitor.sh"
    echo -e "  Docker Start: $PROJECT_DIR/scripts/start-docker.sh"
    echo -e "  Docker Stop: $PROJECT_DIR/scripts/stop-docker.sh"
    echo -e "\n${YELLOW}Logs:${NC} $LOGS_DIR"
    echo -e "${YELLOW}Backups:${NC} $BACKUP_DIR"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}Deployment log: $LOG_FILE${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Create directories
    mkdir -p "$CONFIG_DIR" "$LOGS_DIR" "$BACKUP_DIR" "$WWW_DIR"
    
    # Check if running as root
    check_root
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      WEB SERVER DEPLOYMENT SCRIPT     ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages
    install_packages
    
    # Create web server user
    create_web_user
    
    # Configure services
    configure_nginx
    configure_mariadb
    configure_php
    configure_firewall
    configure_fail2ban
    configure_logrotate
    
    # Set up scripts
    setup_backup
    setup_monitoring
    setup_docker
    
    # Display summary
    display_summary
    
    log_message "${GREEN}Web server deployment completed successfully${NC}"
}

# Run main function
main
Make the script executable:

```bash chmod +x ~/web-server-project/scripts/deploy.sh


#### Step 3: Run the Deployment Script

\`\`\`bash
sudo ~/web-server-project/scripts/deploy.sh
This script will:

Install and configure a web server (Nginx, MariaDB, PHP)
Set up a dedicated web server user with SSH key authentication
Configure firewall rules and fail2ban for security
Set up log rotation for proper log management
Create backup and monitoring scripts with cron jobs
Set up Docker and Docker Compose for containerized deployment
Generate a comprehensive deployment report
Step 4: Test the Deployment
After the script completes, you can test the deployment by:

Accessing the web server at http://your-server-ip
Starting the Docker containers with ~/web-server-project/scripts/start-docker.sh
Accessing the containerized web server at http://your-server-ip:8080
Testing the backup script with ~/web-server-project/scripts/backup.sh
Testing the monitoring script with ~/web-server-project/scripts/monitor.sh
Step 5: Document the Project
Create a README.md file for the project:

```markdown

Automated Web Server Deployment and Monitoring System
Overview
This project provides a comprehensive system for deploying, securing, and monitoring a web server environment. It includes automated scripts for installation, configuration, backup, and monitoring.

Features
Automated deployment of Nginx, MariaDB, and PHP
User management with secure SSH key authentication
Firewall configuration and intrusion prevention with fail2ban
Log rotation and management
Automated backup system
Comprehensive monitoring system
Containerized deployment with Docker and Docker Compose
Directory Structure
scripts/ - Contains all automation scripts

deploy.sh - Main deployment script
backup.sh - Automated backup script
monitor.sh - System monitoring script
start-docker.sh - Start Docker containers
stop-docker.sh - Stop Docker containers
configs/ - Configuration files
logs/ - Log files
backups/ - Backup files
www/ - Web files for Docker deployment
Usage
Initial Deployment
```bash sudo ./scripts/deploy.sh


### Managing Backups

\`\`\`bash
# Run a manual backup
./scripts/backup.sh

# Restore from backup
tar -xzf backups/backup_YYYYMMDD_HHMMSS.tar.gz -C /var/www/html
Monitoring
```bash

Run a manual monitoring check
./scripts/monitor.sh


### Docker Deployment

\`\`\`bash
# Start Docker containers
./scripts/start-docker.sh

# Stop Docker containers
./scripts/stop-docker.sh
Security Features
Dedicated web server user with restricted permissions
SSH key authentication
Firewall rules allowing only necessary services
Fail2ban for intrusion prevention
Secure database configuration
HTTPS support
Monitoring Features
Service status monitoring
Disk space monitoring
Memory usage monitoring
System load monitoring
Failed login attempts monitoring
HTTP response monitoring
Backup System
Daily automated backups
Database and file system backups
Rotation system to manage backup storage
Requirements
Ubuntu 20.04 LTS or CentOS 8
Sudo/root access
Internet connection for package installation
License
This project is licensed under the MIT License - see the LICENSE file for details.


#### Day 7 Learning Outcomes

By completing this capstone project, you should be able to:

1. Deploy and configure a complete web server environment
2. Implement proper security measures for a production server
3. Set up automated monitoring and alerting
4. Create a comprehensive backup and recovery system
5. Containerize an application for easy deployment
6. Document a complex system for future reference
7. Apply all the skills learned in Week 1 to a real-world project

#### Additional Resources for Day 7

- [Nginx Documentation](https://nginx.org/en/docs/)
- [MariaDB Documentation](https://mariadb.com/kb/en/documentation/)
- [PHP Documentation](https://www.php.net/docs.php)
- [Docker Documentation](https://docs.docker.com/)
- [Linux Server Security Guide](https://www.digitalocean.com/community/tutorials/7-security-measures-to-protect-your-servers)

## Week 2: Advanced System Administration

In Week 2, we'll build on the foundation established in Week 1 and dive into more advanced system administration topics. This week focuses on advanced shell scripting, system performance, security, networking, storage, and high availability.

### Day 8: Advanced Shell Scripting

Shell scripting is a powerful tool for automating complex tasks. In this section, we'll explore advanced shell scripting techniques that will make your scripts more robust, efficient, and maintainable.

#### Advanced Bash Features

**Bash Arrays:**

\`\`\`bash
# Indexed arrays
declare -a fruits=("Apple" "Banana" "Orange" "Mango")
echo "First fruit: ${fruits[0]}"
echo "All fruits: ${fruits[@]}"
echo "Number of fruits: ${#fruits[@]}"

# Iterating through array
for fruit in "${fruits[@]}"; do
    echo "Processing $fruit"
done

# Array operations
fruits+=(["Pineapple" "Grape"])  # Add elements
unset fruits[1]                  # Remove element
fruits=("${fruits[@]}")          # Reindex array

# Associative arrays (dictionaries)
declare -A user_info
user_info[name]="John"
user_info[age]=30
user_info[city]="New York"

echo "Name: ${user_info[name]}"
echo "Age: ${### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.### The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

I'll develop this into a comprehensive guide using Markdown that's optimized for GitHub. This expanded guide will take you from beginner to exceptional Linux engineer with detailed explanations, practical exercises, and real-world applications.

```markdown file="linux-engineer-roadmap.md" type="code"
# The Ultimate Linux Engineer's Roadmap: From Novice to Exceptional

![Linux Tux](https://upload.wikimedia.org/wikipedia/commons/3/35/Tux.svg)

## Table of Contents

- [Introduction](#introduction)
- [Before You Begin](#before-you-begin)
- [Week 1: Foundation Building](#week-1-foundation-building)
  - [Day 1: Mastering the Shell](#day-1-mastering-the-shell)
  - [Day 2: Filesystem Hierarchy and User Management](#day-2-filesystem-hierarchy-and-user-management)
  - [Day 3: Networking Fundamentals](#day-3-networking-fundamentals)
  - [Day 4: Package Management and Automation](#day-4-package-management-and-automation)
  - [Day 5: System Services and Logs](#day-5-system-services-and-logs)
  - [Day 6: Containers, Git, and Modern Workflows](#day-6-containers-git-and-modern-workflows)
  - [Day 7: Week 1 Capstone Project](#day-7-week-1-capstone-project)
- [Week 2: Advanced System Administration](#week-2-advanced-system-administration)
  - [Day 8: Advanced Shell Scripting](#day-8-advanced-shell-scripting)
  - [Day 9: System Performance and Monitoring](#day-9-system-performance-and-monitoring)
  - [Day 10: Security Hardening](#day-10-security-hardening)
  - [Day 11: Advanced Networking](#day-11-advanced-networking)
  - [Day 12: Storage Management](#day-12-storage-management)
  - [Day 13: High Availability and Clustering](#day-13-high-availability-and-clustering)
  - [Day 14: Week 2 Capstone Project](#day-14-week-2-capstone-project)
- [Week 3: DevOps and Infrastructure as Code](#week-3-devops-and-infrastructure-as-code)
  - [Day 15: Infrastructure as Code Fundamentals](#day-15-infrastructure-as-code-fundamentals)
  - [Day 16: Configuration Management with Ansible](#day-16-configuration-management-with-ansible)
  - [Day 17: Container Orchestration with Kubernetes](#day-17-container-orchestration-with-kubernetes)
  - [Day 18: CI/CD Pipelines](#day-18-cicd-pipelines)
  - [Day 19: Cloud Infrastructure Management](#day-19-cloud-infrastructure-management)
  - [Day 20: Monitoring and Observability](#day-20-monitoring-and-observability)
  - [Day 21: Week 3 Capstone Project](#day-21-week-3-capstone-project)
- [Week 4: Specialization and Real-World Applications](#week-4-specialization-and-real-world-applications)
  - [Day 22: Database Administration on Linux](#day-22-database-administration-on-linux)
  - [Day 23: Web Server Optimization](#day-23-web-server-optimization)
  - [Day 24: Automation at Scale](#day-24-automation-at-scale)
  - [Day 25: Troubleshooting and Debugging](#day-25-troubleshooting-and-debugging)
  - [Day 26: Linux in Enterprise Environments](#day-26-linux-in-enterprise-environments)
  - [Day 27: Career Development and Certification](#day-27-career-development-and-certification)
  - [Day 28: Final Capstone Project](#day-28-final-capstone-project)
- [Beyond the Roadmap](#beyond-the-roadmap)
- [Resources](#resources)
- [Glossary](#glossary)

## Introduction

Welcome to the ultimate roadmap for becoming an exceptional Linux engineer. This comprehensive guide is designed to take you from wherever you are now—whether a complete beginner or an intermediate user—to a highly skilled Linux professional capable of architecting, implementing, and maintaining complex systems.

Linux powers everything from tiny IoT devices to massive supercomputers, from web servers to cloud infrastructure. Mastering Linux isn't just about learning commands; it's about understanding the philosophy, architecture, and ecosystem that makes it the backbone of modern computing.

This roadmap spans four weeks of intensive learning, with each week building upon the previous one:

1. **Week 1: Foundation Building** - Master the essential skills every Linux engineer needs
2. **Week 2: Advanced System Administration** - Deepen your knowledge with advanced concepts
3. **Week 3: DevOps and Infrastructure as Code** - Embrace modern infrastructure practices
4. **Week 4: Specialization and Real-World Applications** - Apply your skills to specific domains

By the end of this journey, you'll have:
- Mastered hundreds of Linux commands and utilities
- Built dozens of practical projects
- Developed a problem-solving mindset
- Created a portfolio of work to showcase your skills
- Gained the confidence to tackle any Linux-related challenge

Let's begin the journey to becoming an exceptional Linux engineer.

## Before You Begin

### Setting Up Your Learning Environment

To get the most out of this roadmap, you'll need:

1. **A Linux system** - Either a dedicated machine, a dual-boot setup, a virtual machine, or a cloud instance. Ubuntu, Debian, CentOS, or Fedora are all good choices for beginners.

2. **Access to the terminal** - Most of your work will happen here.

3. **A text editor** - Vim, Nano, or VS Code with SSH extension if working remotely.

4. **A GitHub account** - For storing your projects and scripts.

5. **A learning journal** - Document your progress, challenges, and solutions.

### Recommended Setup Script

Here's a script to set up a basic learning environment with essential tools:

\`\`\`bash
#!/bin/bash
# Linux Engineer Learning Environment Setup

echo "Setting up your Linux Engineer learning environment..."

# Update system
sudo apt update && sudo apt upgrade -y || sudo yum update -y

# Install essential tools
sudo apt install -y git vim curl wget htop tmux zsh tree nmap tcpdump || 
sudo yum install -y git vim curl wget htop tmux zsh tree nmap tcpdump

# Install Oh My Zsh for better terminal experience
sh -c "$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"

# Create learning directory structure
mkdir -p ~/linux_learning/{scripts,projects,notes,backups}

# Create a basic .vimrc
cat > ~/.vimrc << 'EOL'
syntax on
set number
set tabstop=4
set shiftwidth=4
set expandtab
set autoindent
set hlsearch
set incsearch
EOL

# Create a learning journal template
cat > ~/linux_learning/notes/journal.md << 'EOL'
# Linux Engineering Learning Journal

## Day 1: $(date +%Y-%m-%d)

### What I Learned Today

### Challenges Faced

### Solutions Found

### Commands to Remember

### Tomorrow's Goals

EOL

echo "Setup complete! Your learning environment is ready."
echo "Your learning materials are in ~/linux_learning/"
echo "Start your journal at ~/linux_learning/notes/journal.md"
\`\`\`

### Learning Approach

For each day of this roadmap:

1. **Read the theory** - Understand the concepts before diving into practice
2. **Execute the commands** - Type them yourself, don't copy-paste
3. **Complete the mini-projects** - Apply what you've learned
4. **Document your work** - Keep notes on what you've learned and challenges you've overcome
5. **Reflect and review** - At the end of each day, review what you've learned and plan for tomorrow

Now, let's begin our journey to Linux mastery.

## Week 1: Foundation Building

### Day 1: Mastering the Shell

The shell is your primary interface to the Linux system. Becoming proficient with the shell is the first step toward Linux mastery.

#### Shell Basics

**Understanding the Shell**

The shell is a command interpreter that provides a text-based interface to the operating system. The most common shell is Bash (Bourne Again SHell), but others like Zsh, Fish, and Ksh are also popular.

**Key Concepts:**
- Command syntax and structure
- Standard input, output, and error streams
- Pipes and redirection
- Command history and editing
- Tab completion
- Wildcards and globbing

#### Essential Commands

**Navigation and File Operations:**

\`\`\`bash
# Directory navigation
pwd                     # Print working directory
ls -la                  # List all files with details
cd /path/to/directory   # Change directory
mkdir -p dir1/dir2      # Create nested directories
rmdir dir               # Remove empty directory
rm -rf dir              # Remove directory and contents (use with caution!)
touch file.txt          # Create empty file or update timestamp
cp source dest          # Copy files or directories
mv source dest          # Move or rename files or directories
\`\`\`

**Viewing and Editing Files:**

\`\`\`bash
cat file.txt            # Display file contents
less file.txt           # View file with pagination
head -n 10 file.txt     # Show first 10 lines
tail -n 10 file.txt     # Show last 10 lines
tail -f /var/log/syslog # Follow file updates in real-time
nano file.txt           # Simple text editor
vim file.txt            # Advanced text editor
\`\`\`

**Text Processing:**

\`\`\`bash
grep "pattern" file     # Search for pattern in file
grep -r "pattern" dir   # Recursive search in directory
grep -i "pattern" file  # Case-insensitive search
grep -v "pattern" file  # Invert match (lines NOT containing pattern)

sed 's/old/new/g' file  # Replace text in file
sed -i 's/old/new/g' file # Replace text in-place

awk '{print $1}' file   # Print first column
awk -F: '{print $1,$3}' /etc/passwd # Print columns 1 and 3 with : delimiter

cut -d: -f1 /etc/passwd # Cut first field with : delimiter
sort file.txt           # Sort lines alphabetically
uniq file.txt           # Remove duplicate adjacent lines
wc -l file.txt          # Count lines in file
\`\`\`

**Finding Files:**

\`\`\`bash
find / -name "*.conf"   # Find files by name
find / -type f -size +100M # Find files larger than 100MB
find / -mtime -7        # Find files modified in the last 7 days
locate filename         # Quick file search using database
which command           # Show path of command
whereis command         # Show binary, source, and man page locations
\`\`\`

**Command Chaining and Process Control:**

\`\`\`bash
command1 && command2    # Run command2 only if command1 succeeds
command1 || command2    # Run command2 only if command1 fails
command1 ; command2     # Run command1 then command2
command1 | command2     # Pipe output of command1 to command2

ctrl+c                  # Interrupt (kill) current process
ctrl+z                  # Suspend current process
bg                      # Resume suspended process in background
fg                      # Bring background process to foreground
jobs                    # List background jobs
kill PID                # Kill process by ID
killall process_name    # Kill all processes with given name
\`\`\`

#### Shell Customization

**Bash Configuration Files:**

- `~/.bashrc` - User-specific Bash configuration
- `~/.bash_profile` - Executed for login shells
- `~/.bash_aliases` - Common place to store aliases

**Creating Aliases:**

\`\`\`bash
# Add to ~/.bashrc or ~/.bash_aliases
alias ll='ls -alF'
alias update='sudo apt update && sudo apt upgrade -y'
alias myip='curl ifconfig.me'
alias ports='netstat -tulanp'
\`\`\`

**Customizing Your Prompt:**

\`\`\`bash
# Add to ~/.bashrc
export PS1="\[\033[38;5;11m\]\u\[$(tput sgr0)\]\[\033[38;5;15m\]@\[$(tput sgr0)\]\[\033[38;5;10m\]\h\[$(tput sgr0)\]\[\033[38;5;15m\]:\[$(tput sgr0)\]\[\033[38;5;6m\]\w\[$(tput sgr0)\]\[\033[38;5;15m\]\\$ \[$(tput sgr0)\]"
\`\`\`

**Environment Variables:**

\`\`\`bash
# View all environment variables
env

# Set an environment variable for current session
export VAR_NAME="value"

# Add to ~/.bashrc to make permanent
echo 'export VAR_NAME="value"' >> ~/.bashrc
\`\`\`

#### Mini-Project: Super Sysadmin CLI Toolkit

Create a Bash script that provides a menu-driven interface to common system administration tasks:

\`\`\`bash
#!/bin/bash
# super_sysadmin.sh - A toolkit for common sysadmin tasks

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}       SUPER SYSADMIN TOOLKIT         ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} System Information"
    echo -e "${GREEN}2.${NC} Disk Usage"
    echo -e "${GREEN}3.${NC} Memory Usage"
    echo -e "${GREEN}4.${NC} Process Management"
    echo -e "${GREEN}5.${NC} Network Information"
    echo -e "${GREEN}6.${NC} User Management"
    echo -e "${GREEN}7.${NC} File Search"
    echo -e "${GREEN}8.${NC} Log Analysis"
    echo -e "${GREEN}9.${NC} System Updates"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# System Information
system_info() {
    echo -e "${BLUE}System Information:${NC}"
    echo -e "${YELLOW}Hostname:${NC} $(hostname)"
    echo -e "${YELLOW}Kernel:${NC} $(uname -r)"
    echo -e "${YELLOW}Uptime:${NC} $(uptime -p)"
    echo -e "${YELLOW}OS:${NC} $(grep PRETTY_NAME /etc/os-release | cut -d= -f2 | tr -d '"')"
    echo -e "${YELLOW}CPU:${NC} $(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')"
    echo -e "${YELLOW}CPU Cores:${NC} $(grep -c processor /proc/cpuinfo)"
    pause
}

# Disk Usage
disk_usage() {
    echo -e "${BLUE}Disk Usage:${NC}"
    df -h | grep -v "tmpfs" | grep -v "udev"
    echo -e "\n${BLUE}Largest Directories:${NC}"
    echo "Please wait, scanning..."
    du -h /var /home /usr --max-depth=2 2>/dev/null | sort -hr | head -10
    pause
}

# Memory Usage
memory_usage() {
    echo -e "${BLUE}Memory Usage:${NC}"
    free -h
    echo -e "\n${BLUE}Top Memory Processes:${NC}"
    ps aux --sort=-%mem | head -11
    pause
}

# Process Management
process_management() {
    local choice
    
    echo -e "${BLUE}Process Management:${NC}"
    echo "1. View running processes"
    echo "2. Kill process by PID"
    echo "3. Kill process by name"
    echo "4. View process tree"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1) ps aux | less ;;
        2) 
            echo -ne "Enter PID to kill: "
            read pid
            kill -9 $pid 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process $pid killed${NC}"
            else
                echo -e "${RED}Failed to kill process $pid${NC}"
            fi
            ;;
        3)
            echo -ne "Enter process name to kill: "
            read pname
            pkill -9 $pname 2>/dev/null
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}Process(es) named $pname killed${NC}"
            else
                echo -e "${RED}Failed to kill processes named $pname${NC}"
            fi
            ;;
        4) pstree ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Network Information
network_info() {
    local choice
    
    echo -e "${BLUE}Network Information:${NC}"
    echo "1. IP Configuration"
    echo "2. Routing Table"
    echo "3. Open Ports"
    echo "4. Active Connections"
    echo "5. DNS Resolution Test"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) ip addr ;;
        2) ip route ;;
        3) ss -tulnp ;;
        4) netstat -natup | head -20 ;;
        5)
            echo -ne "Enter domain to resolve: "
            read domain
            echo -e "${YELLOW}DNS Lookup:${NC}"
            dig $domain +short
            echo -e "\n${YELLOW}Traceroute:${NC}"
            traceroute -n $domain
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# User Management
user_management() {
    local choice
    
    echo -e "${BLUE}User Management:${NC}"
    echo "1. List all users"
    echo "2. List all groups"
    echo "3. Create new user"
    echo "4. Delete user"
    echo "5. Add user to group"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) cut -d: -f1,3 /etc/passwd | sort ;;
        2) cut -d: -f1 /etc/group | sort ;;
        3)
            echo -ne "Enter username: "
            read username
            sudo useradd -m $username
            echo -ne "Set password for $username: "
            sudo passwd $username
            ;;
        4)
            echo -ne "Enter username to delete: "
            read username
            sudo userdel -r $username
            echo -e "${GREEN}User $username deleted${NC}"
            ;;
        5)
            echo -ne "Enter username: "
            read username
            echo -ne "Enter group name: "
            read groupname
            sudo usermod -aG $groupname $username
            echo -e "${GREEN}Added $username to $groupname${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# File Search
file_search() {
    local choice
    
    echo -e "${BLUE}File Search:${NC}"
    echo "1. Find files by name"
    echo "2. Find files by content"
    echo "3. Find files by size"
    echo "4. Find files by modification time"
    echo -ne "Enter choice [1-4]: "
    read choice
    
    case $choice in
        1)
            echo -ne "Enter filename pattern: "
            read pattern
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for $pattern in $path..."
            find $path -name "$pattern" 2>/dev/null | head -20
            ;;
        2)
            echo -ne "Enter text to find: "
            read text
            echo -ne "Enter file pattern (e.g., *.conf): "
            read pattern
            echo -ne "Enter search path [/etc]: "
            read path
            path=${path:-/etc}
            echo "Searching for '$text' in $pattern files in $path..."
            grep -r "$text" --include="$pattern" $path 2>/dev/null | head -20
            ;;
        3)
            echo -ne "Enter minimum size in MB: "
            read size
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files larger than ${size}MB in $path..."
            find $path -type f -size +${size}M 2>/dev/null | head -20
            ;;
        4)
            echo -ne "Enter days (files modified within last X days): "
            read days
            echo -ne "Enter search path [/]: "
            read path
            path=${path:-/}
            echo "Searching for files modified in the last $days days in $path..."
            find $path -type f -mtime -$days 2>/dev/null | head -20
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Log Analysis
log_analysis() {
    local choice
    
    echo -e "${BLUE}Log Analysis:${NC}"
    echo "1. View system log (syslog)"
    echo "2. View authentication log (auth.log)"
    echo "3. View kernel log (dmesg)"
    echo "4. Search for errors in logs"
    echo "5. Monitor log in real-time"
    echo -ne "Enter choice [1-5]: "
    read choice
    
    case $choice in
        1) less /var/log/syslog ;;
        2) less /var/log/auth.log ;;
        3) dmesg | less ;;
        4)
            echo -ne "Enter error pattern to search for: "
            read pattern
            grep -i "$pattern" /var/log/syslog /var/log/auth.log 2>/dev/null | tail -20
            ;;
        5)
            echo "Press Ctrl+C to stop monitoring"
            sleep 2
            tail -f /var/log/syslog
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# System Updates
system_updates() {
    local choice
    
    echo -e "${BLUE}System Updates:${NC}"
    echo "1. Check for updates"
    echo "2. Install updates"
    echo "3. Clean package cache"
    echo -ne "Enter choice [1-3]: "
    read choice
    
    # Detect package manager
    if command -v apt &> /dev/null; then
        PKG_MANAGER="apt"
    elif command -v yum &> /dev/null; then
        PKG_MANAGER="yum"
    elif command -v dnf &> /dev/null; then
        PKG_MANAGER="dnf"
    else
        echo -e "${RED}Unsupported package manager${NC}"
        pause
        return
    fi
    
    case $choice in
        1)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum check-update
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf check-update
            fi
            ;;
        2)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt update && sudo apt upgrade -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum update -y
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf update -y
            fi
            ;;
        3)
            if [ "$PKG_MANAGER" = "apt" ]; then
                sudo apt clean && sudo apt autoremove -y
            elif [ "$PKG_MANAGER" = "yum" ]; then
                sudo yum clean all
            elif [ "$PKG_MANAGER" = "dnf" ]; then
                sudo dnf clean all
            fi
            echo -e "${GREEN}Package cache cleaned${NC}"
            ;;
        *) echo -e "${RED}Invalid option${NC}" ;;
    esac
    pause
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) system_info ;;
            2) disk_usage ;;
            3) memory_usage ;;
            4) process_management ;;
            5) network_info ;;
            6) user_management ;;
            7) file_search ;;
            8) log_analysis ;;
            9) system_updates ;;
            0) 
                echo -e "${GREEN}Thank you for using Super Sysadmin Toolkit!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
    done
}

# Check if running as root
if [ "$(id -u)" -eq 0 ]; then
    echo -e "${YELLOW}Running as root. Some operations may modify system files.${NC}"
else
    echo -e "${YELLOW}Not running as root. Some operations may require sudo.${NC}"
fi

# Start the program
main
\`\`\`

Save this script as `super_sysadmin.sh`, make it executable with `chmod +x super_sysadmin.sh`, and run it with `./super_sysadmin.sh`.

#### Day 1 Learning Outcomes

By the end of Day 1, you should be able to:

1. Navigate the Linux filesystem confidently using the command line
2. Manipulate files and directories with ease
3. Process and analyze text using powerful command-line tools
4. Find files and information quickly
5. Customize your shell environment for productivity
6. Create a basic Bash script to automate tasks

#### Additional Resources for Day 1

- [The Linux Command Line](https://linuxcommand.org/tlcl.php) (free book)
- [Bash Guide for Beginners](https://tldp.org/LDP/Bash-Beginners-Guide/html/index.html)
- [Explain Shell](https://explainshell.com/) - Explains command syntax
- [ShellCheck](https://www.shellcheck.net/) - Finds bugs in your shell scripts

### Day 2: Filesystem Hierarchy and User Management

Understanding the Linux filesystem structure and managing users and permissions are fundamental skills for any Linux engineer.

#### Linux Filesystem Hierarchy

The Linux filesystem follows the Filesystem Hierarchy Standard (FHS), which defines the directory structure and contents.

**Key Directories:**

- `/` - Root directory
- `/bin` - Essential user binaries
- `/boot` - Boot loader files
- `/dev` - Device files
- `/etc` - System configuration files
- `/home` - User home directories
- `/lib` - Essential shared libraries
- `/media` - Removable media mount points
- `/mnt` - Temporary mount points
- `/opt` - Optional application software
- `/proc` - Virtual filesystem for process and kernel information
- `/root` - Home directory for the root user
- `/run` - Run-time variable data
- `/sbin` - System binaries
- `/srv` - Data for services provided by the system
- `/sys` - Virtual filesystem for system information
- `/tmp` - Temporary files
- `/usr` - User utilities and applications
- `/var` - Variable files (logs, spool files, temporary files)

**Exploring the Filesystem:**

\`\`\`bash
# View filesystem hierarchy
ls -la /

# View disk usage by directory
du -sh /*

# View mounted filesystems
mount | column -t

# View filesystem types and usage
df -hT
\`\`\`

#### File Types in Linux

Linux recognizes several types of files, each with a specific purpose:

- Regular files (`-`)
- Directories (`d`)
- Symbolic links (`l`)
- Character device files (`c`)
- Block device files (`b`)
- Named pipes (`p`)
- Sockets (`s`)

\`\`\`bash
# View file types in a directory
ls -la /dev | head -20
\`\`\`

#### File Permissions and Ownership

Linux uses a permission model to control access to files and directories.

**Permission Types:**
- Read (`r`): 4
- Write (`w`): 2
- Execute (`x`): 1

**Permission Categories:**
- User/Owner (`u`)
- Group (`g`)
- Others (`o`)

**Changing Permissions:**

\`\`\`bash
# Change permissions
chmod 755 file.sh        # rwxr-xr-x
chmod u+x file.sh        # Add execute permission for user
chmod go-w file.sh       # Remove write permission for group and others
chmod -R 750 directory   # Recursively change permissions

# Change ownership
chown user:group file    # Change user and group ownership
chown -R user:group dir  # Recursively change ownership
\`\`\`

**Special Permissions:**
- Setuid (`s` on user execute): 4000
- Setgid (`s` on group execute): 2000
- Sticky bit (`t` on others execute): 1000

\`\`\`bash
# Set special permissions
chmod 4755 file          # Set setuid bit
chmod 2755 file          # Set setgid bit
chmod 1777 directory     # Set sticky bit (common for /tmp)
\`\`\`

**Default Permissions with umask:**

The `umask` command sets the default permissions for newly created files and directories.

\`\`\`bash
# View current umask
umask

# Set umask (subtract from 666 for files, 777 for directories)
umask 022  # Files: 644, Directories: 755
\`\`\`

#### User and Group Management

Linux is a multi-user system, and proper user management is essential for security and organization.

**User Information Files:**
- `/etc/passwd` - User account information
- `/etc/shadow` - Encrypted passwords
- `/etc/group` - Group information

**User Management Commands:**

\`\`\`bash
# Create a new user
useradd -m -s /bin/bash username  # Create user with home directory and bash shell
adduser username                  # Interactive user creation (Debian/Ubuntu)

# Modify user
usermod -aG sudo username         # Add user to sudo group
usermod -s /bin/zsh username      # Change user's shell
usermod -L username               # Lock user account
usermod -U username               # Unlock user account

# Delete user
userdel username                  # Delete user
userdel -r username               # Delete user and home directory

# Set/change password
passwd username

# Switch user
su - username                     # Switch to user with environment
sudo -i                           # Switch to root with environment
\`\`\`

**Group Management Commands:**

\`\`\`bash
# Create a new group
groupadd groupname

# Modify group
groupmod -n newname oldname       # Rename group

# Delete group
groupdel groupname

# Add user to group
usermod -aG groupname username
gpasswd -a username groupname

# Remove user from group
gpasswd -d username groupname

# View user's groups
groups username
id username
\`\`\`

#### Storage Management

Managing storage devices and filesystems is a critical skill for Linux engineers.

**Disk Partitioning:**

\`\`\`bash
# List block devices
lsblk
fdisk -l

# Create partitions with fdisk (interactive)
sudo fdisk /dev/sdb

# Create partitions with parted (scriptable)
sudo parted /dev/sdb mklabel gpt
sudo parted /dev/sdb mkpart primary ext4 0% 100%

# Format partitions
sudo mkfs.ext4 /dev/sdb1
sudo mkfs.xfs /dev/sdb2
\`\`\`

**Mounting Filesystems:**

\`\`\`bash
# Create mount point
sudo mkdir /mnt/data

# Mount filesystem temporarily
sudo mount /dev/sdb1 /mnt/data

# Unmount filesystem
sudo umount /mnt/data

# Mount with specific options
sudo mount -o rw,noexec,nosuid /dev/sdb1 /mnt/data
\`\`\`

**Persistent Mounts with /etc/fstab:**

\`\`\`bash
# Get UUID of partition
sudo blkid /dev/sdb1

# Add to /etc/fstab
echo "UUID=your-uuid-here /mnt/data ext4 defaults 0 2" | sudo tee -a /etc/fstab

# Test fstab entry
sudo mount -a
\`\`\`

**Logical Volume Management (LVM):**

\`\`\`bash
# Create physical volume
sudo pvcreate /dev/sdb1

# Create volume group
sudo vgcreate vg_data /dev/sdb1

# Create logical volume
sudo lvcreate -n lv_data -L 10G vg_data

# Format and mount logical volume
sudo mkfs.ext4 /dev/vg_data/lv_data
sudo mount /dev/vg_data/lv_data /mnt/data

# Extend logical volume
sudo lvextend -L +5G /dev/vg_data/lv_data
sudo resize2fs /dev/vg_data/lv_data
\`\`\`

#### Mini-Project 1: User Management Script

Create a script to manage users and groups:

\`\`\`bash
#!/bin/bash
# user_manager.sh - A script to manage users and groups

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          USER MANAGER SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Create new user"
    echo -e "${GREEN}2.${NC} Delete user"
    echo -e "${GREEN}3.${NC} Lock/Unlock user"
    echo -e "${GREEN}4.${NC} Create new group"
    echo -e "${GREEN}5.${NC} Add user to group"
    echo -e "${GREEN}6.${NC} Remove user from group"
    echo -e "${GREEN}7.${NC} List all users"
    echo -e "${GREEN}8.${NC} List all groups"
    echo -e "${GREEN}9.${NC} Show user details"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Create new user
create_user() {
    echo -e "${BLUE}Create New User:${NC}"
    read -p "Enter username: " username
    
    # Check if user already exists
    if id "$username" &>/dev/null; then
        echo -e "${RED}User $username already exists${NC}"
        return
    fi
    
    read -p "Create home directory? (y/n): " create_home
    read -p "Set shell (default: /bin/bash): " shell
    read -p "Add to sudo group? (y/n): " add_sudo
    
    # Set defaults
    shell=${shell:-/bin/bash}
    home_opt=""
    
    if [[ "$create_home" =~ ^[Yy]$ ]]; then
        home_opt="-m"
    fi
    
    # Create user
    useradd $home_opt -s $shell $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}User $username created successfully${NC}"
        
        # Set password
        echo -e "${YELLOW}Setting password for $username${NC}"
        passwd $username
        
        # Add to sudo if requested
        if [[ "$add_sudo" =~ ^[Yy]$ ]]; then
            usermod -aG sudo $username
            echo -e "${GREEN}Added $username to sudo group${NC}"
        fi
    else
        echo -e "${RED}Failed to create user $username${NC}"
    fi
}

# Delete user
delete_user() {
    echo -e "${BLUE}Delete User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Delete home directory? (y/n): " delete_home
    
    # Confirm deletion
    read -p "Are you sure you want to delete user $username? (y/n): " confirm
    
    if [[ "$confirm" =~ ^[Yy]$ ]]; then
        if [[ "$delete_home" =~ ^[Yy]$ ]]; then
            userdel -r $username
        else
            userdel $username
        fi
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}User $username deleted successfully${NC}"
        else
            echo -e "${RED}Failed to delete user $username${NC}"
        fi
    else
        echo -e "${YELLOW}User deletion cancelled${NC}"
    fi
}

# Lock/Unlock user
lock_unlock_user() {
    echo -e "${BLUE}Lock/Unlock User:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo "1. Lock user"
    echo "2. Unlock user"
    read -p "Enter choice [1-2]: " choice
    
    case $choice in
        1)
            usermod -L $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username locked successfully${NC}"
            else
                echo -e "${RED}Failed to lock user $username${NC}"
            fi
            ;;
        2)
            usermod -U $username
            if [ $? -eq 0 ]; then
                echo -e "${GREEN}User $username unlocked successfully${NC}"
            else
                echo -e "${RED}Failed to unlock user $username${NC}"
            fi
            ;;
        *)
            echo -e "${RED}Invalid option${NC}"
            ;;
    esac
}

# Create new group
create_group() {
    echo -e "${BLUE}Create New Group:${NC}"
    read -p "Enter group name: " groupname
    
    # Check if group already exists
    if grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname already exists${NC}"
        return
    fi
    
    groupadd $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Group $groupname created successfully${NC}"
    else
        echo -e "${RED}Failed to create group $groupname${NC}"
    fi
}

# Add user to group
add_user_to_group() {
    echo -e "${BLUE}Add User to Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    usermod -aG $groupname $username
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Added $username to $groupname group${NC}"
    else
        echo -e "${RED}Failed to add $username to $groupname group${NC}"
    fi
}

# Remove user from group
remove_user_from_group() {
    echo -e "${BLUE}Remove User from Group:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    read -p "Enter group name: " groupname
    
    # Check if group exists
    if ! grep -q "^$groupname:" /etc/group; then
        echo -e "${RED}Group $groupname does not exist${NC}"
        return
    fi
    
    gpasswd -d $username $groupname
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Removed $username from $groupname group${NC}"
    else
        echo -e "${RED}Failed to remove $username from $groupname group${NC}"
    fi
}

# List all users
list_users() {
    echo -e "${BLUE}List of All Users:${NC}"
    echo -e "${YELLOW}Username UID GID Home Shell${NC}"
    echo "----------------------------------------"
    awk -F: '{print $1 "\t" $3 "\t" $4 "\t" $6 "\t" $7}' /etc/passwd | column -t
}

# List all groups
list_groups() {
    echo -e "${BLUE}List of All Groups:${NC}"
    echo -e "${YELLOW}Group GID Members${NC}"
    echo "----------------------------------------"
    
    while IFS=: read -r group pass gid members; do
        echo -e "$group\t$gid\t$members" | column -t
    done < /etc/group
}

# Show user details
show_user_details() {
    echo -e "${BLUE}User Details:${NC}"
    read -p "Enter username: " username
    
    # Check if user exists
    if ! id "$username" &>/dev/null; then
        echo -e "${RED}User $username does not exist${NC}"
        return
    fi
    
    echo -e "${YELLOW}User Information:${NC}"
    id $username
    
    echo -e "\n${YELLOW}Groups:${NC}"
    groups $username
    
    echo -e "\n${YELLOW}Login Information:${NC}"
    lastlog -u $username
    
    echo -e "\n${YELLOW}Last Login:${NC}"
    last $username | head -3
}

# Main function
main() {
    local choice
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) create_user ;;
            2) delete_user ;;
            3) lock_unlock_user ;;
            4) create_group ;;
            5) add_user_to_group ;;
            6) remove_user_from_group ;;
            7) list_users ;;
            8) list_groups ;;
            9) show_user_details ;;
            0) 
                echo -e "${GREEN}Thank you for using User Manager Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                pause
                ;;
        esac
        
        pause
    done
}

# Start the program
main
\`\`\`

Save this script as `user_manager.sh`, make it executable with `chmod +x user_manager.sh`, and run it with `sudo ./user_manager.sh`.

#### Mini-Project 2: Filesystem Backup Script

Create a script to back up important system directories:

\`\`\`bash
#!/bin/bash
# system_backup.sh - A script to back up important system directories

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Backup destination
BACKUP_DIR="/backup"
DATE=$(date +%Y-%m-%d)
HOSTNAME=$(hostname)

# Directories to back up
BACKUP_DIRS=(
    "/etc"
    "/home"
    "/var/www"
    "/var/log"
    "/root"
)

# Exclude patterns
EXCLUDES=(
    "*.tmp"
    "*.log"
    "*.cache"
    "tmp/*"
    "cache/*"
)

# Check if running as root
if [ "$(id -u)" -ne 0 ]; then
    echo -e "${RED}This script must be run as root${NC}"
    exit 1
fi

# Create backup directory if it doesn't exist
if [ ! -d "$BACKUP_DIR" ]; then
    mkdir -p "$BACKUP_DIR"
    if [ $? -ne 0 ]; then
        echo -e "${RED}Failed to create backup directory $BACKUP_DIR${NC}"
        exit 1
    fi
fi

# Create backup subdirectory for today
BACKUP_PATH="$BACKUP_DIR/$HOSTNAME-$DATE"
mkdir -p "$BACKUP_PATH"

# Function to create exclude options for tar
create_exclude_options() {
    local exclude_opts=""
    for pattern in "${EXCLUDES[@]}"; do
        exclude_opts="$exclude_opts --exclude='$pattern'"
    done
    echo "$exclude_opts"
}

# Backup function
backup_directory() {
    local dir=$1
    local dirname=$(basename "$dir")
    local backup_file="$BACKUP_PATH/${dirname}.tar.gz"
    
    echo -e "${YELLOW}Backing up $dir to $backup_file...${NC}"
    
    # Create exclude options
    local exclude_opts=$(create_exclude_options)
    
    # Execute tar command with excludes
    eval "tar -czf $backup_file $exclude_opts $dir"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Backup of $dir completed successfully${NC}"
        echo -e "Size: $(du -h $backup_file | cut -f1)"
    else
        echo -e "${RED}Backup of $dir failed${NC}"
    fi
}

# Main backup process
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}      SYSTEM BACKUP SCRIPT             ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "${GREEN}Starting backup on $HOSTNAME at $(date)${NC}"
echo -e "${GREEN}Backup destination: $BACKUP_PATH${NC}"

# Back up each directory
for dir in "${BACKUP_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        backup_directory "$dir"
    else
        echo -e "${RED}Directory $dir does not exist, skipping${NC}"
    fi
done

# Create a backup summary
echo -e "${BLUE}========================================${NC}"
echo -e "${YELLOW}          BACKUP SUMMARY               ${NC}"
echo -e "${BLUE}========================================${NC}"
echo -e "Backup completed at $(date)"
echo -e "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
echo -e "Files created:"
ls -lh $BACKUP_PATH

# Create a backup log
{
    echo "Backup completed at $(date)"
    echo "Hostname: $HOSTNAME"
    echo "Backup location: $BACKUP_PATH"
    echo "Directories backed up:"
    for dir in "${BACKUP_DIRS[@]}"; do
        echo "- $dir"
    done
    echo "Total backup size: $(du -sh $BACKUP_PATH | cut -f1)"
} > "$BACKUP_PATH/backup.log"

echo -e "${GREEN}Backup process completed successfully!${NC}"
\`\`\`

Save this script as `system_backup.sh`, make it executable with `chmod +x system_backup.sh`, and run it with `sudo ./system_backup.sh`.

#### Day 2 Learning Outcomes

By the end of Day 2, you should be able to:

1. Understand the Linux filesystem hierarchy and navigate it confidently
2. Manage file permissions and ownership effectively
3. Create, modify, and delete users and groups
4. Manage storage devices, partitions, and filesystems
5. Create backup scripts for important system files
6. Implement proper security practices for files and users

#### Additional Resources for Day 2

- [Linux Filesystem Hierarchy Standard](https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html)
- [Linux User Management](https://www.digitalocean.com/community/tutorials/how-to-manage-users-and-groups-in-linux)
- [Linux Storage Management](https://www.redhat.com/sysadmin/storage-management-basics)
- [Linux Permissions Explained](https://www.redhat.com/sysadmin/linux-file-permissions-explained)

### Day 3: Networking Fundamentals

Networking is a critical aspect of Linux administration. Understanding how to configure, monitor, and troubleshoot network connections is essential for any Linux engineer.

#### Networking Basics

**Key Networking Concepts:**

- IP addressing (IPv4 and IPv6)
- Subnetting and CIDR notation
- Network interfaces
- Routing
- DNS resolution
- Firewalls and security

**Network Configuration Files:**

- `/etc/hosts` - Static hostname to IP mappings
- `/etc/resolv.conf` - DNS resolver configuration
- `/etc/nsswitch.conf` - Name Service Switch configuration
- `/etc/network/interfaces` (Debian/Ubuntu) - Network interface configuration
- `/etc/sysconfig/network-scripts/` (RHEL/CentOS) - Network interface configuration

#### Network Interface Management

**Viewing Network Interfaces:**

\`\`\`bash
# Show all interfaces
ip link show

# Show IP addresses
ip addr show

# Show specific interface
ip addr show dev eth0

# Legacy commands
ifconfig
netstat -i
\`\`\`

**Configuring Network Interfaces:**

\`\`\`bash
# Bring interface up/down
ip link set eth0 up
ip link set eth0 down

# Set IP address
ip addr add 192.168.1.100/24 dev eth0
ip addr del 192.168.1.100/24 dev eth0

# Legacy commands
ifconfig eth0 192.168.1.100 netmask 255.255.255.0
ifconfig eth0 up
\`\`\`

**Network Manager CLI (nmcli):**

\`\`\`bash
# Show connections
nmcli connection show

# Show device status
nmcli device status

# Connect to a network
nmcli connection up "My Connection"

# Create a new connection
nmcli connection add type ethernet con-name "My Connection" ifname eth0

# Modify connection
nmcli connection modify "My Connection" ipv4.addresses 192.168.1.100/24
nmcli connection modify "My Connection" ipv4.gateway 192.168.1.1
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection modify "My Connection" ipv4.method manual

# Apply changes
nmcli connection up "My Connection"
\`\`\`

#### Routing

**Viewing Routing Table:**

\`\`\`bash
# Show routing table
ip route show

# Legacy command
netstat -rn
route -n
\`\`\`

**Configuring Routes:**

\`\`\`bash
# Add a route
ip route add 192.168.2.0/24 via 192.168.1.1
ip route add default via 192.168.1.1

# Delete a route
ip route del 192.168.2.0/24
ip route del default

# Legacy commands
route add -net 192.168.2.0/24 gw 192.168.1.1
route add default gw 192.168.1.1
\`\`\`

#### DNS Configuration

**Configuring DNS Resolvers:**

\`\`\`bash
# View DNS configuration
cat /etc/resolv.conf

# Add DNS servers (temporary)
echo "nameserver 8.8.8.8" > /etc/resolv.conf
echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# Permanent DNS configuration with NetworkManager
nmcli connection modify "My Connection" ipv4.dns "8.8.8.8 8.8.4.4"
nmcli connection up "My Connection"
\`\`\`

**DNS Lookup Tools:**

\`\`\`bash
# Query DNS records
dig example.com
dig example.com MX
dig @8.8.8.8 example.com

# Simple DNS lookup
nslookup example.com
host example.com

# Reverse DNS lookup
dig -x 8.8.8.8
\`\`\`

#### Network Diagnostics

**Connectivity Testing:**

\`\`\`bash
# Ping a host
ping -c 4 example.com

# Trace route to host
traceroute example.com
tracepath example.com

# Check connectivity with specific port
nc -zv example.com 80
telnet example.com 80
\`\`\`

**Network Scanning:**

\`\`\`bash
# Scan ports on a host
nmap -p 1-1000 example.com

# Scan network for hosts
nmap -sP 192.168.1.0/24
\`\`\`

**Packet Capture:**

\`\`\`bash
# Capture packets on interface
tcpdump -i eth0
tcpdump -i eth0 port 80
tcpdump -i eth0 host 192.168.1.100
\`\`\`

#### Firewall Management

**iptables (Traditional Linux Firewall):**

\`\`\`bash
# View firewall rules
iptables -L -v

# Allow incoming SSH
iptables -A INPUT -p tcp --dport 22 -j ACCEPT

# Block an IP address
iptables -A INPUT -s 192.168.1.100 -j DROP

# Save rules (Debian/Ubuntu)
iptables-save > /etc/iptables/rules.v4

# Save rules (RHEL/CentOS)
service iptables save
\`\`\`

**firewalld (Modern Firewall):**

\`\`\`bash
# Check firewall status
firewall-cmd --state

# List allowed services
firewall-cmd --list-services

# Allow a service
firewall-cmd --add-service=http --permanent
firewall-cmd --add-port=8080/tcp --permanent

# Reload firewall
firewall-cmd --reload
\`\`\`

**ufw (Uncomplicated Firewall):**

\`\`\`bash
# Enable firewall
ufw enable

# Allow services
ufw allow ssh
ufw allow 80/tcp

# Block an IP address
ufw deny from 192.168.1.100

# Check status
ufw status verbose
\`\`\`

#### Network Services

**SSH (Secure Shell):**

\`\`\`bash
# Connect to remote host
ssh username@hostname

# Connect with specific port
ssh -p 2222 username@hostname

# Generate SSH key
ssh-keygen -t rsa -b 4096

# Copy SSH key to remote host
ssh-copy-id username@hostname
\`\`\`

**SSH Configuration:**

\`\`\`bash
# SSH client configuration
cat > ~/.ssh/config << 'EOL'
Host myserver
    HostName example.com
    User username
    Port 2222
    IdentityFile ~/.ssh/id_rsa
EOL

# SSH server configuration
sudo nano /etc/ssh/sshd_config
# Common settings:
# PermitRootLogin no
# PasswordAuthentication no
# Port 2222

# Restart SSH service
sudo systemctl restart sshd
\`\`\`

#### Mini-Project: Network Monitoring Script

Create a script to monitor network connectivity and services:

\`\`\`bash
#!/bin/bash
# network_monitor.sh - A script to monitor network connectivity and services

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/network_monitor.log"
HOSTS_FILE="/etc/network_monitor_hosts"
EMAIL_RECIPIENT="admin@example.com"
CHECK_INTERVAL=300  # 5 minutes

# Create hosts file if it doesn't exist
if [ ! -f "$HOSTS_FILE" ]; then
    cat > "$HOSTS_FILE" << 'EOL'
# Format: hostname_or_ip:port:service_name
google.com:80:Google Web
8.8.8.8:53:Google DNS
github.com:443:GitHub HTTPS
192.168.1.1:22:Local Router SSH
EOL
    echo -e "${YELLOW}Created default hosts file at $HOSTS_FILE${NC}"
    echo -e "${YELLOW}Edit this file to add your own hosts to monitor${NC}"
fi

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a host is up
check_host() {
    local host=$1
    ping -c 1 -W 1 "$host" > /dev/null 2>&1
    return $?
}

# Function to check if a port is open
check_port() {
    local host=$1
    local port=$2
    nc -z -w 1 "$host" "$port" > /dev/null 2>&1
    return $?
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo -e "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check hosts and services
check_hosts() {
    log_message "Starting network monitoring check"
    
    # Read hosts file
    while IFS=: read -r host port service || [[ -n "$host" ]]; do
        # Skip comments and empty lines
        [[ "$host" =~ ^#.*$ || -z "$host" ]] && continue
        
        echo -e "${YELLOW}Checking $service ($host:$port)...${NC}"
        
        # Check if host is up
        if check_host "$host"; then
            echo -e "${GREEN}Host $host is up${NC}"
            
            # Check if port is open
            if check_port "$host" "$port"; then
                echo -e "${GREEN}Service $service is running on $host:$port${NC}"
                log_message "Service $service is UP and RUNNING on $host:$port"
            else
                echo -e "${RED}Service $service is DOWN on $host:$port${NC}"
                log_message "ALERT: Service $service is DOWN on $host:$port"
                send_alert "Service Down: $service" "The service $service on $host:$port is not responding."
            fi
        else
            echo -e "${RED}Host $host is down${NC}"
            log_message "ALERT: Host $host is DOWN"
            send_alert "Host Down: $host" "The host $host is not responding to ping."
        fi
    done < "$HOSTS_FILE"
    
    log_message "Network monitoring check completed"
}

# Function to show network interfaces
show_interfaces() {
    echo -e "${BLUE}Network Interfaces:${NC}"
    ip -c addr show
    
    echo -e "\n${BLUE}Routing Table:${NC}"
    ip -c route show
    
    echo -e "\n${BLUE}DNS Configuration:${NC}"
    cat /etc/resolv.conf
}

# Function to show network statistics
show_statistics() {
    echo -e "${BLUE}Network Statistics:${NC}"
    
    echo -e "\n${YELLOW}Active Connections:${NC}"
    ss -tuln
    
    echo -e "\n${YELLOW}Network Traffic:${NC}"
    ifstat 1 5
    
    echo -e "\n${YELLOW}Bandwidth Usage:${NC}"
    iftop -t -s 5
}

# Function to run continuous monitoring
run_monitor() {
    echo -e "${BLUE}Starting continuous network monitoring...${NC}"
    echo -e "${YELLOW}Press Ctrl+C to stop${NC}"
    
    while true; do
        check_hosts
        echo -e "${BLUE}Waiting $CHECK_INTERVAL seconds for next check...${NC}"
        sleep $CHECK_INTERVAL
    done
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script should be run as root for full functionality${NC}"
    fi
    
    # Parse command line arguments
    case "$1" in
        check)
            check_hosts
            ;;
        interfaces)
            show_interfaces
            ;;
        stats)
            show_statistics
            ;;
        monitor)
            run_monitor
            ;;
        *)
            echo -e "${BLUE}Network Monitor Script${NC}"
            echo -e "Usage: $0 [command]"
            echo -e "\nCommands:"
            echo -e "  check       Check all hosts and services once"
            echo -e "  interfaces  Show network interfaces and configuration"
            echo -e "  stats       Show network statistics"
            echo -e "  monitor     Run continuous monitoring"
            ;;
    esac
}

# Run main function with all arguments
main "$@"
\`\`\`

Save this script as `network_monitor.sh`, make it executable with `chmod +x network_monitor.sh`, and run it with `sudo ./network_monitor.sh check`.

#### Day 3 Learning Outcomes

By the end of Day 3, you should be able to:

1. Configure network interfaces using modern tools
2. Understand and manage routing tables
3. Configure DNS resolution
4. Diagnose network connectivity issues
5. Set up and manage firewalls
6. Monitor network services and connectivity
7. Secure network communications with SSH

#### Additional Resources for Day 3

- [Linux Networking Commands](https://www.tecmint.com/linux-networking-commands/)
- [IP Command Guide](https://www.cyberciti.biz/faq/linux-ip-command-examples-usage-syntax/)
- [Linux Firewall Tutorial](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-iptables-on-ubuntu-14-04)
- [SSH Configuration Guide](https://www.ssh.com/academy/ssh/config)

### Day 4: Package Management and Automation

Package management is a core aspect of Linux administration, allowing you to install, update, and remove software efficiently. Automation through shell scripting enables you to streamline repetitive tasks and build powerful workflows.

#### Package Management

Different Linux distributions use different package management systems:

- Debian/Ubuntu: APT (Advanced Package Tool)
- RHEL/CentOS/Fedora: YUM/DNF (Yellowdog Updater, Modified/Dandified YUM)
- Arch Linux: Pacman
- SUSE: Zypper

**APT (Debian/Ubuntu):**

\`\`\`bash
# Update package lists
sudo apt update

# Upgrade installed packages
sudo apt upgrade

# Full system upgrade (including kernel)
sudo apt full-upgrade

# Install a package
sudo apt install package-name

# Remove a package
sudo apt remove package-name

# Remove a package and its configuration
sudo apt purge package-name

# Remove unused dependencies
sudo apt autoremove

# Search for a package
apt search keyword

# Show package information
apt show package-name

# List installed packages
apt list --installed

# Clean package cache
sudo apt clean
\`\`\`

**YUM/DNF (RHEL/CentOS/Fedora):**

\`\`\`bash
# Update package lists
sudo yum check-update
sudo dnf check-update

# Upgrade installed packages
sudo yum update
sudo dnf update

# Install a package
sudo yum install package-name
sudo dnf install package-name

# Remove a package
sudo yum remove package-name
sudo dnf remove package-name

# Search for a package
yum search keyword
dnf search keyword

# Show package information
yum info package-name
dnf info package-name

# List installed packages
yum list installed
dnf list installed

# Clean package cache
sudo yum clean all
sudo dnf clean all
\`\`\`

**Managing Repositories:**

\`\`\`bash
# Debian/Ubuntu: Add a repository
sudo add-apt-repository ppa:repository-name/ppa

# Debian/Ubuntu: Add a repository manually
echo "deb http://repository.url/path distribution component" | sudo tee /etc/apt/sources.list.d/repo-name.list
sudo apt update

# RHEL/CentOS: Add a repository
sudo yum-config-manager --add-repo=https://repository.url/repo.repo
sudo dnf config-manager --add-repo=https://repository.url/repo.repo
\`\`\`

**Package Management with dpkg/rpm:**

\`\`\`bash
# Install a .deb package
sudo dpkg -i package.deb

# Install a .rpm package
sudo rpm -i package.rpm

# List installed packages
dpkg -l
rpm -qa

# Get information about a package
dpkg -s package-name
rpm -qi package-name

# List files in a package
dpkg -L package-name
rpm -ql package-name
\`\`\`

**Alternative Package Managers:**

\`\`\`bash
# Snap packages
sudo snap install package-name
snap list
sudo snap remove package-name

# Flatpak packages
flatpak install application
flatpak list
flatpak uninstall application

# AppImage
# Download the .AppImage file
chmod +x application.AppImage
./application.AppImage
\`\`\`

#### Shell Scripting for Automation

Shell scripting allows you to automate repetitive tasks and create powerful system administration tools.

**Bash Script Structure:**

\`\`\`bash
#!/bin/bash
# Script description

# Variables
NAME="Linux"
VERSION=5.10

# Functions
function greet() {
    local name=$1
    echo "Hello, $name!"
}

# Main script
echo "Welcome to $NAME version $VERSION"
greet "User"

exit 0
\`\`\`

**Variables and Data Types:**

\`\`\`bash
# String variables
NAME="Linux"
echo "Hello, $NAME"
echo "Length of name: ${#NAME}"
echo "Uppercase: ${NAME^^}"
echo "Lowercase: ${NAME,,}"

# Numeric variables
COUNT=10
RESULT=$((COUNT * 2))
echo "Result: $RESULT"

# Arrays
FRUITS=("Apple" "Banana" "Orange")
echo "First fruit: ${FRUITS[0]}"
echo "All fruits: ${FRUITS[@]}"
echo "Number of fruits: ${#FRUITS[@]}"

# Add to array
FRUITS+=("Mango")

# Associative arrays (dictionaries)
declare -A USER
USER[name]="John"
USER[age]=30
echo "User name: ${USER[name]}"
\`\`\`

**Control Structures:**

\`\`\`bash
# If statements
if [ "$1" = "start" ]; then
    echo "Starting service..."
elif [ "$1" = "stop" ]; then
    echo "Stopping service..."
else
    echo "Usage: $0 [start|stop]"
fi

# Case statement
case "$1" in
    start)
        echo "Starting service..."
        ;;
    stop)
        echo "Stopping service..."
        ;;
    restart)
        echo "Restarting service..."
        ;;
    *)
        echo "Usage: $0 [start|stop|restart]"
        ;;
esac

# For loop
for i in {1..5}; do
    echo "Number: $i"
done

# For loop with array
for fruit in "${FRUITS[@]}"; do
    echo "Fruit: $fruit"
done

# While loop
count=1
while [ $count -le 5 ]; do
    echo "Count: $count"
    ((count++))
done

# Until loop
count=1
until [ $count -gt 5 ]; do
    echo "Count: $count"
    ((count++))
done
\`\`\`

**Input and Output:**

\`\`\`bash
# Command line arguments
echo "Script name: $0"
echo "First argument: $1"
echo "All arguments: $@"
echo "Number of arguments: $#"

# Reading user input
read -p "Enter your name: " name
echo "Hello, $name!"

# Reading with default value
read -p "Enter your age [30]: " age
age=${age:-30}
echo "Age: $age"

# Reading password (hidden input)
read -sp "Enter password: " password
echo -e "\nPassword length: ${#password}"

# Reading multiple values
read -p "Enter first and last name: " first last
echo "First name: $first"
echo "Last name: $last"

# Reading from file
while IFS= read -r line; do
    echo "Line: $line"
done < input.txt
\`\`\`

**Error Handling:**

\`\`\`bash
# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Custom error handling
error_exit() {
    echo "Error: $1" >&2
    exit 1
}

# Check command success
if ! command -v docker &> /dev/null; then
    error_exit "Docker is not installed"
fi

# Try-catch style
{
    # Try block
    command_that_might_fail
} || {
    # Catch block
    echo "Command failed"
    exit 1
}
\`\`\`

**Command Substitution and Process Management:**

\`\`\`bash
# Command substitution
current_date=$(date +%Y-%m-%d)
echo "Today is $current_date"

# Process substitution
diff <(ls -l) <(ls -la)

# Background processes
long_running_command &
pid=$!
echo "Process ID: $pid"

# Wait for background process
wait $pid
echo "Process completed"

# Trap signals
trap "echo 'Script interrupted'; exit 1" INT TERM
trap "echo 'Cleaning up...'; rm -f temp_file.txt" EXIT
\`\`\`

#### Scheduling Tasks with Cron

Cron allows you to schedule tasks to run at specific times or intervals.

**Cron Syntax:**

\`\`\`
# ┌───────────── minute (0 - 59)
# │ ┌───────────── hour (0 - 23)
# │ │ ┌───────────── day of the month (1 - 31)
# │ │ │ ┌───────────── month (1 - 12)
# │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
# │ │ │ │ │
# * * * * * command to execute
\`\`\`

**Common Cron Examples:**

\`\`\`bash
# Edit user's crontab
crontab -e

# List user's crontab
crontab -l

# Example crontab entries:

# Run every minute
* * * * * /path/to/script.sh

# Run every hour at minute 0
0 * * * * /path/to/script.sh

# Run at 2:30 AM every day
30 2 * * * /path/to/script.sh

# Run at 6:00 PM every weekday (Monday to Friday)
0 18 * * 1-5 /path/to/script.sh

# Run on the first day of every month at midnight
0 0 1 * * /path/to/script.sh

# Run every 15 minutes
*/15 * * * * /path/to/script.sh

# Run at system startup (using @reboot)
@reboot /path/to/script.sh
\`\`\`

**System-wide Cron Directories:**

- `/etc/crontab` - System crontab
- `/etc/cron.d/` - Directory for crontab fragments
- `/etc/cron.daily/` - Scripts run daily
- `/etc/cron.hourly/` - Scripts run hourly
- `/etc/cron.monthly/` - Scripts run monthly
- `/etc/cron.weekly/` - Scripts run weekly

#### Mini-Project: LAMP Stack Installation Script

Create a script to automate the installation of a LAMP (Linux, Apache, MySQL, PHP) stack:

\`\`\`bash
#!/bin/bash
# lamp_installer.sh - Automated LAMP stack installer

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Log file
LOG_FILE="/var/log/lamp_installer.log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if a command exists
command_exists() {
    command -v "$1" &> /dev/null
}

# Function to detect Linux distribution
detect_distro() {
    if command_exists apt-get; then
        echo "debian"
    elif command_exists yum; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install packages on Debian/Ubuntu
install_debian() {
    log_message "${BLUE}Updating package lists...${NC}"
    apt-get update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    apt-get install -y apache2 >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL...${NC}"
    # Pre-set MySQL root password to avoid prompt
    debconf-set-selections <<< "mysql-server mysql-server/root_password password $MYSQL_ROOT_PASSWORD"
    debconf-set-selections <<< "mysql-server mysql-server/root_password_again password $MYSQL_ROOT_PASSWORD"
    apt-get install -y mysql-server >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    apt-get install -y php libapache2-mod-php php-mysql php-cli php-common php-mbstring php-gd php-intl php-xml php-mysql php-zip php-curl php-xmlrpc >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    apt-get install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Enable Apache modules
    a2enmod rewrite >> "$LOG_FILE" 2>&1
    
    # Restart services
    systemctl restart apache2 >> "$LOG_FILE" 2>&1
    systemctl restart mysql >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable apache2 >> "$LOG_FILE" 2>&1
    systemctl enable mysql >> "$LOG_FILE" 2>&1
}

# Function to install packages on RHEL/CentOS
install_rhel() {
    log_message "${BLUE}Updating package lists...${NC}"
    yum update -y >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing Apache...${NC}"
    yum install -y httpd >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing MySQL (MariaDB)...${NC}"
    yum install -y mariadb-server mariadb >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing PHP...${NC}"
    yum install -y php php-common php-mysqlnd php-cli php-gd php-curl php-xml php-mbstring php-zip >> "$LOG_FILE" 2>&1
    
    log_message "${BLUE}Installing additional tools...${NC}"
    yum install -y curl git unzip >> "$LOG_FILE" 2>&1
    
    # Configure firewall
    if command_exists firewall-cmd; then
        log_message "${BLUE}Configuring firewall...${NC}"
        firewall-cmd --permanent --add-service=http >> "$LOG_FILE" 2>&1
        firewall-cmd --permanent --add-service=https >> "$LOG_FILE" 2>&1
        firewall-cmd --reload >> "$LOG_FILE" 2>&1
    fi
    
    # SELinux configuration
    if command_exists setsebool; then
        log_message "${BLUE}Configuring SELinux...${NC}"
        setsebool -P httpd_can_network_connect=1 >> "$LOG_FILE" 2>&1
        setsebool -P httpd_can_network_connect_db=1 >> "$LOG_FILE" 2>&1
    fi
    
    # Restart services
    systemctl restart httpd >> "$LOG_FILE" 2>&1
    systemctl restart mariadb >> "$LOG_FILE" 2>&1
    
    # Enable services on boot
    systemctl enable httpd >> "$LOG_FILE" 2>&1
    systemctl enable mariadb >> "$LOG_FILE" 2>&1
}

# Function to secure MySQL installation
secure_mysql() {
    log_message "${BLUE}Securing MySQL installation...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Debian/Ubuntu
        mysql -u root -p"$MYSQL_ROOT_PASSWORD" <<EOF
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '$MYSQL_ROOT_PASSWORD';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    else
        # RHEL/CentOS
        mysql -u root <<EOF
UPDATE mysql.user SET Password=PASSWORD('$MYSQL_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    fi
    
    log_message "${GREEN}MySQL secured successfully${NC}"
}

# Function to create a test PHP file
create_test_php() {
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
    else
        web_root="/var/www/html"
    fi
    
    log_message "${BLUE}Creating test PHP file...${NC}"
    
    cat > "$web_root/info.php" << 'EOL'
<?php
phpinfo();
EOL
    
    # Set proper permissions
    if [ "$DISTRO" = "debian" ]; then
        chown www-data:www-data "$web_root/info.php"
    else
        chown apache:apache "$web_root/info.php"
    fi
    
    chmod 644 "$web_root/info.php"
    
    log_message "${GREEN}Test PHP file created at http://localhost/info.php${NC}"
}

# Function to install phpMyAdmin
install_phpmyadmin() {
    if [ "$INSTALL_PHPMYADMIN" != "y" ]; then
        return
    fi
    
    log_message "${BLUE}Installing phpMyAdmin...${NC}"
    
    local web_root
    
    if [ "$DISTRO" = "debian" ]; then
        web_root="/var/www/html"
        # Debian/Ubuntu
        debconf-set-selections <<< "phpmyadmin phpmyadmin/dbconfig-install boolean true"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/app-password-confirm password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/admin-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/mysql/app-pass password $MYSQL_ROOT_PASSWORD"
        debconf-set-selections <<< "phpmyadmin phpmyadmin/reconfigure-webserver multiselect apache2"
        apt-get install -y phpmyadmin >> "$LOG_FILE" 2>&1
    else
        web_root="/var/www/html"
        # RHEL/CentOS
        yum install -y epel-release >> "$LOG_FILE" 2>&1
        yum install -y phpmyadmin >> "$LOG_FILE" 2>&1
        
        # Configure phpMyAdmin
        sed -i 's/Require ip 127.0.0.1/Require all granted/' /etc/httpd/conf.d/phpMyAdmin.conf
        sed -i 's/Deny from All/Allow from All/' /etc/httpd/conf.d/phpMyAdmin.conf
        systemctl restart httpd >> "$LOG_FILE" 2>&1
    fi
    
    log_message "${GREEN}phpMyAdmin installed successfully${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}LAMP Stack Installation Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Apache:${NC} Installed and running"
    echo -e "${YELLOW}MySQL:${NC} Installed and secured"
    echo -e "${YELLOW}PHP:${NC} Installed and configured"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        echo -e "${YELLOW}phpMyAdmin:${NC} Installed"
    fi
    
    echo -e "\n${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}PHP Info:${NC} http://$ip_address/info.php"
    
    if [ "$INSTALL_PHPMYADMIN" = "y" ]; then
        if [ "$DISTRO" = "debian" ]; then
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpmyadmin"
        else
            echo -e "${YELLOW}phpMyAdmin:${NC} http://$ip_address/phpMyAdmin"
        fi
    fi
    
    echo -e "\n${YELLOW}MySQL Root Password:${NC} $MYSQL_ROOT_PASSWORD"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Installation Log:${NC} $LOG_FILE"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LAMP STACK INSTALLER             ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    
    if [ "$DISTRO" = "unknown" ]; then
        echo -e "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    # Get MySQL root password
    read -sp "Enter MySQL root password: " MYSQL_ROOT_PASSWORD
    echo
    
    # Confirm password
    read -sp "Confirm MySQL root password: " MYSQL_ROOT_PASSWORD_CONFIRM
    echo
    
    if [ "$MYSQL_ROOT_PASSWORD" != "$MYSQL_ROOT_PASSWORD_CONFIRM" ]; then
        echo -e "${RED}Passwords do not match${NC}"
        exit 1
    fi
    
    # Ask about phpMyAdmin
    read -p "Install phpMyAdmin? (y/n): " INSTALL_PHPMYADMIN
    
    # Start installation
    log_message "${GREEN}Starting LAMP stack installation...${NC}"
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages based on distribution
    if [ "$DISTRO" = "debian" ]; then
        install_debian
    else
        install_rhel
    fi
    
    # Secure MySQL
    secure_mysql
    
    # Create test PHP file
    create_test_php
    
    # Install phpMyAdmin if requested
    install_phpmyadmin
    
    # Display summary
    display_summary
    
    log_message "${GREEN}LAMP stack installation completed successfully${NC}"
}

# Run main function
main
\`\`\`

Save this script as `lamp_installer.sh`, make it executable with `chmod +x lamp_installer.sh`, and run it with `sudo ./lamp_installer.sh`.

#### Day 4 Learning Outcomes

By the end of Day 4, you should be able to:

1. Manage packages using different package managers
2. Write shell scripts to automate system administration tasks
3. Use variables, control structures, and functions in shell scripts
4. Handle errors and edge cases in scripts
5. Schedule tasks using cron
6. Automate complex installations and configurations
7. Create well-documented and maintainable scripts

#### Additional Resources for Day 4

- [Bash Guide](https://mywiki.wooledge.org/BashGuide)
- [Advanced Bash Scripting Guide](https://tldp.org/LDP/abs/html/)
- [Package Management Cheatsheet](https://www.digitalocean.com/community/tutorials/package-management-basics-apt-yum-dnf-pkg)
- [Cron Job Examples](https://www.ostechnix.com/a-beginners-guide-to-cron-jobs/)

### Day 5: System Services and Logs

Understanding how to manage system services and analyze logs is crucial for maintaining and troubleshooting Linux systems.

#### Systemd Service Management

Systemd is the init system and service manager used in most modern Linux distributions.

**Basic Service Management:**

\`\`\`bash
# Check service status
systemctl status service-name

# Start a service
systemctl start service-name

# Stop a service
systemctl stop service-name

# Restart a service
systemctl restart service-name

# Reload service configuration
systemctl reload service-name

# Enable service to start at boot
systemctl enable service-name

# Disable service from starting at boot
systemctl disable service-name

# Check if service is enabled
systemctl is-enabled service-name
\`\`\`

**Viewing Service Information:**

\`\`\`bash
# List all services
systemctl list-units --type=service

# List running services
systemctl list-units --type=service --state=running

# List failed services
systemctl list-units --type=service --state=failed

# Show service dependencies
systemctl list-dependencies service-name

# Show service properties
systemctl show service-name
\`\`\`

**Managing System State:**

\`\`\`bash
# Shutdown the system
systemctl poweroff

# Reboot the system
systemctl reboot

# Suspend the system
systemctl suspend

# Hibernate the system
systemctl hibernate
\`\`\`

#### Creating Systemd Services

You can create custom systemd services to manage your applications.

**Service Unit File Structure:**

```ini
[Unit]
Description=My Custom Service
After=network.target

[Service]
Type=simple
User=myuser
WorkingDirectory=/opt/myapp
ExecStart=/usr/bin/python3 /opt/myapp/app.py
Restart=on-failure
RestartSec=5
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myapp

[Install]
WantedBy=multi-user.target
Creating a Custom Service:

```bash

Create service file
sudo nano /etc/systemd/system/myapp.service

Reload systemd to recognize new service
sudo systemctl daemon-reload

Enable and start the service
sudo systemctl enable myapp sudo systemctl start myapp


#### System Logging

Linux uses various logging mechanisms to record system events and application messages.

**Traditional Syslog:**

\`\`\`bash
# View system log
less /var/log/syslog

# View authentication log
less /var/log/auth.log

# View kernel log
less /var/log/kern.log

# View boot log
less /var/log/boot.log

# View application-specific logs
less /var/log/apache2/error.log
less /var/log/mysql/error.log
Systemd Journal:

```bash

View all journal logs
journalctl

View logs for specific service
journalctl -u service-name

View logs since last boot
journalctl -b

View logs for specific time period
journalctl --since "2023-01-01" --until "2023-01-02"

View logs for specific priority
journalctl -p err

Follow logs in real-time
journalctl -f

View kernel messages
journalctl -k


**Log Rotation:**

Log rotation is managed by the `logrotate` utility, which ensures logs don't consume too much disk space.

\`\`\`bash
# View logrotate configuration
cat /etc/logrotate.conf

# View service-specific configurations
ls -l /etc/logrotate.d/

# Test logrotate configuration
logrotate -d /etc/logrotate.conf

# Force log rotation
logrotate -f /etc/logrotate.conf
Creating Custom Log Rotation:

```bash

Create custom logrotate configuration
cat > /etc/logrotate.d/myapp << 'EOL' /var/log/myapp/*.log { daily missingok rotate 14 compress delaycompress notifempty create 0640 myapp myapp sharedscripts postrotate systemctl reload myapp endscript } EOL


#### Log Analysis Tools

Several tools can help you analyze and monitor logs effectively.

**grep, awk, and sed:**

\`\`\`bash
# Find error messages
grep -i error /var/log/syslog

# Count occurrences of a pattern
grep -c "Failed password" /var/log/auth.log

# Extract specific fields
awk '{print $1, $3}' /var/log/auth.log

# Filter logs by date
grep "Jan 15" /var/log/syslog

# Transform log format
sed 's/error/ERROR/g' /var/log/syslog
Specialized Log Analysis Tools:

```bash

GoAccess (web log analyzer)
goaccess /var/log/apache2/access.log -o report.html --log-format=COMBINED

Logwatch (log summarizer)
logwatch --detail high --range yesterday --service all --output stdout

Lnav (log file navigator)
lnav /var/log/syslog /var/log/auth.log


#### System Monitoring

Monitoring system resources and performance is essential for maintaining healthy systems.

**Process Monitoring:**

\`\`\`bash
# View running processes
ps aux

# View process tree
pstree

# Interactive process viewer
top
htop

# Monitor specific process
watch -n 1 "ps aux | grep nginx"
Resource Monitoring:

```bash

CPU and memory usage
free -h vmstat 1 mpstat -P ALL 1

Disk usage
df -h du -sh /var/*

I/O statistics
iostat -xz 1

Network statistics
netstat -tuln ss -tuln iftop


**System Load and Uptime:**

\`\`\`bash
# System uptime and load
uptime

# Load average explanation:
# 1.00 = 100% of 1 CPU core
# 4.00 on a 4-core system = 100% CPU utilization
Mini-Project: Service Monitor and Auto-Restart Script
Create a script to monitor critical services and automatically restart them if they fail:

```bash #!/bin/bash

service_monitor.sh - Monitor and auto-restart critical services
Colors
RED='\033[0;31m' GREEN='\033[0;32m' YELLOW='\033[0;33m' BLUE='\033[0;34m' NC='\033[0m' # No Color

Configuration
LOG_FILE="/var/log/service_monitor.log" SERVICES_FILE="/etc/service_monitor.conf" EMAIL_RECIPIENT="admin@example.com" MAX_RESTARTS=3 RESTART_INTERVAL=300 # 5 minutes

Create services file if it doesn't exist
if [ ! -f "$SERVICES_FILE" ]; then cat > "$SERVICES_FILE" << 'EOL'

Format: service_name:max_restarts:notification_email
Example:
apache2:3:admin@example.com mysql:3:admin@example.com ssh:3:admin@example.com

Add more services as needed
EOL echo -e "${YELLOW}Created default services file at $SERVICES_FILE${NC}" echo -e "${YELLOW}Edit this file to add your own services to monitor${NC}" fi

Function to log messages
log_message() { local message="$1" local timestamp=$(date "+%Y-%m-%d %H:%M:%S") echo -e "$timestamp - $message" | tee -a "$LOG_FILE" }

Function to send email alert
send_alert() { local subject="$1" local message="$2" local recipient="$3"

if command -v mail > /dev/null; then
    echo -e "$message" | mail -s "$subject" "$recipient"
    log_message "Alert email sent to $recipient"
else
    log_message "mail command not found, could not send alert"
fi
}

Function to check service status
check_service() { local service=$1 systemctl is-active --quiet "$service" return $? }

Function to restart service
restart_service() { local service=$1 local max_restarts=$2 local email=$3

# Check current restart count
local restart_count_file="/tmp/service_monitor_${service}.count"
local restart_time_file="/tmp/service_monitor_${service}.time"

# Initialize count if file doesn't exist
if [ ! -f "$restart_count_file" ]; then
    echo "0" > "$restart_count_file"
fi

# Read current count
local restart_count=$(cat "$restart_count_file")

# Check if we've exceeded max restarts
if [ "$restart_count" -ge "$max_restarts" ]; then
    # Check if enough time has passed since last restart
    if [ -f "$restart_time_file" ]; then
        local last_restart=$(cat "$restart_time_file")
        local current_time=$(date +%s)
        local time_diff=$((current_time - last_restart))
        
        if [ "$time_diff" -lt "$RESTART_INTERVAL" ]; then
            log_message "${RED}Service $service has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Not restarting again.${NC}"
            send_alert "Service $service failed - Too many restarts" "Service $service has failed and has been restarted $restart_count times in the last $((time_diff / 60)) minutes. Manual intervention required." "$email"
            return 1
        fi
    fi
    
    # Reset counter if interval has passed
    echo "0" > "$restart_count_file"
fi

# Increment restart count
restart_count=$((restart_count + 1))
echo "$restart_count" > "$restart_count_file"

# Update restart time
date +%s > "$restart_time_file"

# Restart the service
log_message "${YELLOW}Restarting service $service (attempt $restart_count of $max_restarts)...${NC}"

systemctl restart "$service"

if [ $? -eq 0 ]; then
    log_message "${GREEN}Service $service restarted successfully${NC}"
    
    # Send alert if this is not the first restart
    if [ "$restart_count" -gt 1 ]; then
        send_alert "Service $service restarted" "Service $service was down and has been successfully restarted (attempt $restart_count of $max_restarts)." "$email"
    fi
    
    return 0
else
    log_message "${RED}Failed to restart service $service${NC}"
    send_alert "Service $service restart failed" "Service $service is down and could not be restarted. Manual intervention required." "$email"
    return 1
fi
}

Function to monitor services
monitor_services() { log_message "${BLUE}Starting service monitoring...${NC}"

# Read services file
while IFS=: read -r service max_restarts email || [[ -n "$service" ]]; do
    # Skip comments and empty lines
    [[ "$service" =~ ^#.*$ || -z "$service" ]] && continue
    
    # Set defaults if values are missing
    max_restarts=${max_restarts:-$MAX_RESTARTS}
    email=${email:-$EMAIL_RECIPIENT}
    
    echo -e "${YELLOW}Checking service: $service${NC}"
    
    # Check if service exists
    if ! systemctl list-unit-files --type=service | grep -q "$service.service"; then
        log_message "${RED}Service $service does not exist${NC}"
        continue
    fi
    
    # Check service status
    if check_service "$service"; then
        log_message "${GREEN}Service $service is running${NC}"
    else
        log_message "${RED}Service $service is down${NC}"
        restart_service "$service" "$max_restarts" "$email"
    fi
done < "$SERVICES_FILE"

log_message "${BLUE}Service monitoring completed${NC}"
}

Function to run as a daemon
run_daemon() { local interval=$1

log_message "${BLUE}Starting service monitor daemon with interval of $interval seconds${NC}"

while true; do
    monitor_services
    echo -e "${BLUE}Sleeping for $interval seconds...${NC}"
    sleep $interval
done
}

Function to install as a systemd service
install_service() { log_message "${BLUE}Installing service monitor as a systemd service...${NC}"

# Create service file
cat > /etc/systemd/system/service-monitor.service << EOL
[Unit] Description=Service Monitor and Auto-Restart After=network.target

[Service] Type=simple ExecStart=$(readlink -f "$0") daemon 300 Restart=on-failure RestartSec=5 StandardOutput=syslog StandardError=syslog SyslogIdentifier=service-monitor

[Install] WantedBy=multi-user.target EOL

# Reload systemd
systemctl daemon-reload

# Enable and start service
systemctl enable service-monitor
systemctl start service-monitor

log_message "${GREEN}Service monitor installed and started${NC}"
log_message "${YELLOW}Check status with: systemctl status service-monitor${NC}"
}

Main function
main() { # Check if running as root if [ "$(id -u)" -ne 0 ]; then echo -e "${RED}This script must be run as root${NC}" exit 1 fi

# Parse command line arguments
case "$1" in
    check)
        monitor_services
        ;;
    daemon)
        interval=${2:-300}  # Default to 5 minutes
        run_daemon $interval
        ;;
    install)
        install_service
        ;;
    *)
        echo -e "${BLUE}Service Monitor Script${NC}"
        echo -e "Usage: $0 [command]"
        echo -e "\nCommands:"
        echo -e "  check       Check all services once"
        echo -e "  daemon [n]  Run as daemon, checking every n seconds (default: 300)"
        echo -e "  install     Install as systemd service"
        ;;
esac
}

Run main function with all arguments
main "$@"


Save this script as `service_monitor.sh`, make it executable with `chmod +x service_monitor.sh`, and run it with `sudo ./service_monitor.sh check`.

#### Mini-Project: Log Analysis Script

Create a script to analyze system logs and generate a summary report:

\`\`\`bash
#!/bin/bash
# log_analyzer.sh - Analyze system logs and generate a summary report

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
REPORT_DIR="/var/log/reports"
DATE=$(date +%Y-%m-%d)
REPORT_FILE="$REPORT_DIR/log_report_$DATE.txt"
HTML_REPORT="$REPORT_DIR/log_report_$DATE.html"
EMAIL_RECIPIENT="admin@example.com"

# Log files to analyze
LOG_FILES=(
    "/var/log/syslog"
    "/var/log/auth.log"
    "/var/log/kern.log"
    "/var/log/apache2/access.log"
    "/var/log/apache2/error.log"
    "/var/log/mysql/error.log"
)

# Patterns to search for
PATTERNS=(
    "error"
    "warning"
    "fail"
    "denied"
    "segfault"
    "crash"
    "exception"
    "critical"
)

# Function to create report directory
create_report_dir() {
    if [ ! -d "$REPORT_DIR" ]; then
        mkdir -p "$REPORT_DIR"
        chmod 750 "$REPORT_DIR"
    fi
}

# Function to check if log file exists
check_log_file() {
    local file=$1
    if [ ! -f "$file" ]; then
        echo -e "${YELLOW}Log file $file does not exist, skipping${NC}"
        return 1
    fi
    return 0
}

# Function to count occurrences of a pattern in a file
count_pattern() {
    local pattern=$1
    local file=$2
    
    if ! check_log_file "$file"; then
        echo "0"
        return
    fi
    
    grep -i "$pattern" "$file" | wc -l
}

# Function to extract recent occurrences of a pattern
extract_recent() {
    local pattern=$1
    local file=$2
    local count=$3
    
    if ! check_log_file "$file"; then
        echo "No log file found"
        return
    fi
    
    grep -i "$pattern" "$file" | tail -n $count
}

# Function to get failed login attempts
get_failed_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Failed Login Attempts ===${NC}"
    grep "Failed password" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get successful login attempts
get_successful_logins() {
    local file="/var/log/auth.log"
    
    if ! check_log_file "$file"; then
        echo "No auth log file found"
        return
    fi
    
    echo -e "${BLUE}=== Successful Login Attempts ===${NC}"
    grep "Accepted password\|Accepted publickey" "$file" | awk '{print $1, $2, $3, $9, $11}' | sort | uniq -c | sort -nr
}

# Function to get system resource warnings
get_resource_warnings() {
    local file="/var/log/syslog"
    
    if ! check_log_file "$file"; then
        echo "No syslog file found"
        return
    fi
    
    echo -e "${BLUE}=== System Resource Warnings ===${NC}"
    grep -i "memory\|cpu\|load\|disk space\|i/o" "$file" | grep -i "warning\|error\|critical" | tail -n 20
}

# Function to get kernel errors
get_kernel_errors() {
    local file="/var/log/kern.log"
    
    if ! check_log_file "$file"; then
        echo "No kernel log file found"
        return
    fi
    
    echo -e "${BLUE}=== Kernel Errors ===${NC}"
    grep -i "error\|fail\|segfault" "$file" | tail -n 20
}

# Function to get web server errors
get_web_errors() {
    local file="/var/log/apache2/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/nginx/error.log"
        if ! check_log_file "$file"; then
            echo "No web server error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Web Server Errors ===${NC}"
    grep -i "error\|warn\|crit" "$file" | tail -n 20
}

# Function to get database errors
get_db_errors() {
    local file="/var/log/mysql/error.log"
    
    if ! check_log_file "$file"; then
        file="/var/log/postgresql/postgresql-error.log"
        if ! check_log_file "$file"; then
            echo "No database error log found"
            return
        fi
    fi
    
    echo -e "${BLUE}=== Database Errors ===${NC}"
    grep -i "error\|warn\|fail" "$file" | tail -n 20
}

# Function to generate text report
generate_text_report() {
    echo -e "${BLUE}Generating text report...${NC}"
    
    {
        echo "====================================================="
        echo "           SYSTEM LOG ANALYSIS REPORT"
        echo "====================================================="
        echo "Date: $(date)"
        echo "Hostname: $(hostname)"
        echo "====================================================="
        echo
        
        echo "SUMMARY OF ERROR PATTERNS"
        echo "========================="
        
        for pattern in "${PATTERNS[@]}"; do
            echo "Pattern: $pattern"
            echo "-----------------"
            
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    echo "  $file: $count occurrences"
                fi
            done
            
            echo
        done
        
        echo "====================================================="
        echo "DETAILED ANALYSIS"
        echo "====================================================="
        echo
        
        get_failed_logins
        echo
        
        get_successful_logins
        echo
        
        get_resource_warnings
        echo
        
        get_kernel_errors
        echo
        
        get_web_errors
        echo
        
        get_db_errors
        echo
        
        echo "====================================================="
        echo "TOP 10 MOST FREQUENT ERRORS"
        echo "====================================================="
        
        for file in "${LOG_FILES[@]}"; do
            if check_log_file "$file" > /dev/null; then
                echo "File: $file"
                echo "-----------------"
                grep -i "error\|warn\|fail\|crit" "$file" | sort | uniq -c | sort -nr | head -10
                echo
            fi
        done
        
        echo "====================================================="
        echo "SYSTEM INFORMATION"
        echo "====================================================="
        echo
        
        echo "Uptime: $(uptime)"
        echo
        
        echo "Disk Usage:"
        df -h | grep -v "tmpfs" | grep -v "udev"
        echo
        
        echo "Memory Usage:"
        free -h
        echo
        
        echo "Load Average: $(cat /proc/loadavg)"
        echo
        
        echo "====================================================="
        echo "End of Report"
        echo "====================================================="
    } > "$REPORT_FILE"
    
    echo -e "${GREEN}Text report generated: $REPORT_FILE${NC}"
}

# Function to generate HTML report
generate_html_report() {
    echo -e "${BLUE}Generating HTML report...${NC}"
    
    {
        cat << 'EOL'
&lt;!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>System Log Analysis Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            color: #333;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        h1 {
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 2px solid #eee;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        .header {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 20px;
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        th {
            background-color: #f2f2f2;
        }
        tr:hover {
            background-color: #f5f5f5;
        }
        .error {
            color: #e74c3c;
        }
        .warning {
            color: #f39c12;
        }
        .success {
            color: #27ae60;
        }
        .info {
            color: #3498db;
        }
        pre {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>System Log Analysis Report</h1>
        
        <div class="header">
            <p><strong>Date:</strong> $(date)</p>
            <p><strong>Hostname:</strong> $(hostname)</p>
            <p><strong>Generated by:</strong> Log Analyzer Script</p>
        </div>
EOL
        
        # Summary Section
        cat << 'EOL'
        <div class="section">
            <h2>Summary of Error Patterns</h2>
            <table>
                <tr>
                    <th>Pattern</th>
                    <th>Log File</th>
                    <th>Occurrences</th>
                </tr>
EOL
        
        for pattern in "${PATTERNS[@]}"; do
            for file in "${LOG_FILES[@]}"; do
                if check_log_file "$file" > /dev/null; then
                    count=$(count_pattern "$pattern" "$file")
                    if [ "$count" -gt 0 ]; then
                        echo "<tr>"
                        echo "    <td>$pattern</td>"
                        echo "    <td>$file</td>"
                        echo "    <td>$count</td>"
                        echo "</tr>"
                    fi
                fi
            done
        done
        
        cat << 'EOL'
            </table>
        </div>
EOL
        
        # Failed Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Failed Login Attempts</h2>
            <pre>
EOL
        
        get_failed_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Successful Logins Section
        cat << 'EOL'
        <div class="section">
            <h2>Successful Login Attempts</h2>
            <pre>
EOL
        
        get_successful_logins | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Resource Warnings Section
        cat << 'EOL'
        <div class="section">
            <h2>System Resource Warnings</h2>
            <pre>
EOL
        
        get_resource_warnings | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Kernel Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Kernel Errors</h2>
            <pre>
EOL
        
        get_kernel_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Web Server Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Web Server Errors</h2>
            <pre>
EOL
        
        get_web_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # Database Errors Section
        cat << 'EOL'
        <div class="section">
            <h2>Database Errors</h2>
            <pre>
EOL
        
        get_db_errors | sed 's/\x1b\[[0-9;]*m//g'
        
        cat << 'EOL'
            </pre>
        </div>
EOL
        
        # System Information Section
        cat << 'EOL'
        <div class="section">
            <h2>System Information</h2>
            
            <h3>Uptime</h3>
            <pre>$(uptime)</pre>
            
            <h3>Disk Usage</h3>
            <pre>$(df -h | grep -v "tmpfs" | grep -v "udev")</pre>
            
            <h3>Memory Usage</h3>
            <pre>$(free -h)</pre>
            
            <h3>Load Average</h3>
            <pre>$(cat /proc/loadavg)</pre>
        </div>
EOL
        
        # Footer
        cat << 'EOL'
        <div class="section">
            <p style="text-align: center;">Generated on $(date) by Log Analyzer Script</p>
        </div>
    </div>
</body>
</html>
EOL
    } > "$HTML_REPORT"
    
    echo -e "${GREEN}HTML report generated: $HTML_REPORT${NC}"
}

# Function to email report
email_report() {
    if [ "$EMAIL_REPORT" != "y" ]; then
        return
    fi
    
    echo -e "${BLUE}Emailing report to $EMAIL_RECIPIENT...${NC}"
    
    if command -v mail > /dev/null; then
        if [ -f "$HTML_REPORT" ]; then
            (echo "Please see the attached log analysis report."; uuencode "$HTML_REPORT" "log_report_$DATE.html") | mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT"
        else
            mail -s "Log Analysis Report for $(hostname) - $DATE" "$EMAIL_RECIPIENT" &lt; "$REPORT_FILE"
        fi
        
        echo -e "${GREEN}Report emailed to $EMAIL_RECIPIENT${NC}"
    else
        echo -e "${RED}mail command not found, could not send email${NC}"
    fi
}

# Main function
main() {
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      LOG ANALYZER SCRIPT              ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Ask about email report
    read -p "Email report when complete? (y/n): " EMAIL_REPORT
    
    # Create report directory
    create_report_dir
    
    # Generate reports
    generate_text_report
    generate_html_report
    
    # Email report if requested
    email_report
    
    echo -e "${GREEN}Log analysis completed successfully${NC}"
    echo -e "${YELLOW}Text report: $REPORT_FILE${NC}"
    echo -e "${YELLOW}HTML report: $HTML_REPORT${NC}"
}

# Run main function
main
Save this script as log_analyzer.sh, make it executable with chmod +x log_analyzer.sh, and run it with sudo ./log_analyzer.sh.

Day 5 Learning Outcomes
By the end of Day 5, you should be able to:

Manage system services using systemd
Create custom systemd service units
Understand and navigate system logs
Configure log rotation
Use tools to analyze and monitor logs
Monitor system resources and performance
Create scripts to automate service monitoring and log analysis
Additional Resources for Day 5
Systemd Documentation
Linux Logging Basics
Log Rotation with Logrotate
Linux Performance Monitoring Tools
Day 6: Containers, Git, and Modern Workflows
Modern Linux engineers need to be proficient with containerization, version control, and DevOps workflows. These technologies enable efficient development, deployment, and management of applications.

Docker Fundamentals
Docker is a platform for developing, shipping, and running applications in containers.

Docker Installation:

```bash

Install Docker on Debian/Ubuntu
sudo apt update sudo apt install -y apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" sudo apt update sudo apt install -y docker-ce docker-ce-cli containerd.io

Install Docker on RHEL/CentOS
sudo yum install -y yum-utils sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo yum install -y docker-ce docker-ce-cli containerd.io

Start and enable Docker service
sudo systemctl start docker sudo systemctl enable docker

Add current user to docker group (to run Docker without sudo)
sudo usermod -aG docker $USER


**Basic Docker Commands:**

\`\`\`bash
# Check Docker version
docker --version

# View Docker system info
docker info

# List Docker images
docker images

# Pull an image from Docker Hub
docker pull ubuntu:20.04

# Run a container
docker run -it ubuntu:20.04 bash

# List running containers
docker ps

# List all containers (including stopped)
docker ps -a

# Stop a container
docker stop container_id

# Remove a container
docker rm container_id

# Remove an image
docker rmi image_id
Building Docker Images:

```bash

Create a Dockerfile
cat > Dockerfile << 'EOL' FROM ubuntu:20.04 LABEL maintainer="Your Name your.email@example.com"

Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

Update and install packages
RUN apt-get update && apt-get install -y
nginx
curl
vim
&& apt-get clean
&& rm -rf /var/lib/apt/lists/*

Copy files
COPY index.html /var/www/html/

Expose ports
EXPOSE 80

Set working directory
WORKDIR /var/www/html

Command to run when container starts
CMD ["nginx", "-g", "daemon off;"] EOL

Build an image
docker build -t myapp:1.0 .

Tag an image
docker tag myapp:1.0 username/myapp:1.0

Push an image to Docker Hub
docker login docker push username/myapp:1.0


**Docker Networking:**

\`\`\`bash
# List networks
docker network ls

# Create a network
docker network create mynetwork

# Run a container with a specific network
docker run -d --name web --network mynetwork nginx

# Connect a container to a network
docker network connect mynetwork container_id

# Inspect network
docker network inspect mynetwork
Docker Volumes:

```bash

List volumes
docker volume ls

Create a volume
docker volume create mydata

Run a container with a volume
docker run -d --name db -v mydata:/var/lib/mysql mysql:5.7

Inspect volume
docker volume inspect mydata

Remove volume
docker volume rm mydata


#### Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications.

**Docker Compose Installation:**

\`\`\`bash
# Install Docker Compose on Debian/Ubuntu
sudo curl -L "https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Verify installation
docker-compose --version
Docker Compose Example:

```yaml

docker-compose.yml
version: '3'

services: web: image: nginx:latest ports: - "80:80" volumes: - ./html:/usr/share/nginx/html depends_on: - app networks: - frontend - backend

app: build: ./app environment: - DB_HOST=db - DB_USER=myuser - DB_PASSWORD=mypassword depends_on: - db networks: - backend

db: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=rootpassword - MYSQL_DATABASE=mydb - MYSQL_USER=myuser - MYSQL_PASSWORD=mypassword volumes: - db_data:/var/lib/mysql networks: - backend

networks: frontend: backend:

volumes: db_data:


**Docker Compose Commands:**

\`\`\`bash
# Start services
docker-compose up -d

# View running services
docker-compose ps

# View logs
docker-compose logs

# Stop services
docker-compose down

# Stop services and remove volumes
docker-compose down -v

# Build or rebuild services
docker-compose build

# Execute a command in a service
docker-compose exec app bash
Git Version Control
Git is a distributed version control system that allows you to track changes in your code and collaborate with others.

Git Installation:

```bash

Install Git on Debian/Ubuntu
sudo apt update sudo apt install -y git

Install Git on RHEL/CentOS
sudo yum install -y git

Configure Git
git config --global user.name "Your Name" git config --global user.email "your.email@example.com"


**Basic Git Commands:**

\`\`\`bash
# Initialize a new Git repository
git init

# Clone a repository
git clone https://github.com/username/repository.git

# Check repository status
git status

# Add files to staging area
git add filename
git add .  # Add all files

# Commit changes
git commit -m "Commit message"

# View commit history
git log
git log --oneline

# Create a branch
git branch branch-name

# Switch to a branch
git checkout branch-name

# Create and switch to a new branch
git checkout -b new-branch

# Merge a branch
git merge branch-name

# Pull changes from remote repository
git pull origin main

# Push changes to remote repository
git push origin main
Git Branching Workflow:

```bash

Create a feature branch
git checkout -b feature/new-feature

Make changes and commit
git add . git commit -m "Add new feature"

Push feature branch to remote
git push origin feature/new-feature

Switch back to main branch
git checkout main

Pull latest changes
git pull origin main

Merge feature branch
git merge feature/new-feature

Push changes to main
git push origin main

Delete feature branch
git branch -d feature/new-feature git push origin --delete feature/new-feature


**Git Configuration:**

\`\`\`bash
# View all configurations
git config --list

# Set default editor
git config --global core.editor "vim"

# Set default branch name
git config --global init.defaultBranch main

# Configure line endings
git config --global core.autocrlf input  # Linux/Mac
git config --global core.autocrlf true   # Windows

# Configure aliases
git config --global alias.co checkout
git config --global alias.br branch
git config --global alias.ci commit
git config --global alias.st status
GitHub CLI
GitHub CLI is a command-line tool that brings GitHub functionality to your terminal.

GitHub CLI Installation:

```bash

Install GitHub CLI on Debian/Ubuntu
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-key C99B11DEB97541F0 sudo apt-add-repository https://cli.github.com/packages sudo apt update sudo apt install -y gh

Install GitHub CLI on RHEL/CentOS
sudo dnf config-manager --add-repo https://cli.github.com/packages/rpm/gh-cli.repo sudo dnf install -y gh

Authenticate with GitHub
gh auth login


**GitHub CLI Commands:**

\`\`\`bash
# Create a repository
gh repo create repo-name --public

# Clone a repository
gh repo clone username/repo-name

# View repository
gh repo view username/repo-name

# Create an issue
gh issue create --title "Issue title" --body "Issue description"

# List issues
gh issue list

# Create a pull request
gh pr create --title "PR title" --body "PR description"

# List pull requests
gh pr list

# Check out a pull request
gh pr checkout 123

# Merge a pull request
gh pr merge 123
SSH Keys for Git and Remote Access
SSH keys provide a secure way to authenticate with Git repositories and remote servers.

Generating SSH Keys:

```bash

Generate SSH key
ssh-keygen -t ed25519 -C "your.email@example.com"

Start SSH agent
eval "$(ssh-agent -s)"

Add SSH key to agent
ssh-add ~/.ssh/id_ed25519

Display public key (to add to GitHub/GitLab)
cat ~/.ssh/id_ed25519.pub


**Adding SSH Key to GitHub:**

1. Copy the output of `cat ~/.ssh/id_ed25519.pub`
2. Go to GitHub Settings > SSH and GPG keys > New SSH key
3. Paste your public key and save

**Testing SSH Connection:**

\`\`\`bash
# Test GitHub SSH connection
ssh -T git@github.com

# Clone repository using SSH
git clone git@github.com:username/repository.git
CI/CD Workflows
Continuous Integration and Continuous Deployment (CI/CD) automate the building, testing, and deployment of applications.

GitHub Actions Example:

Create a .github/workflows/main.yml file in your repository:

```yaml name: CI/CD Pipeline

on: push: branches: [ main ] pull_request: branches: [ main ]

jobs: build: runs-on: ubuntu-latest

steps:
- uses: actions/checkout@v2

- name: Set up Node.js
  uses: actions/setup-node@v2
  with:
    node-version: '14'
    
- name: Install dependencies
  run: npm install
  
- name: Run tests
  run: npm test
  
- name: Build application
  run: npm run build
  
- name: Deploy to production
  if: github.ref == 'refs/heads/main'
  run: |
    echo "Deploying to production server"
    # Add deployment commands here

#### Mini-Project: Docker Compose WordPress Setup

Create a Docker Compose configuration for a WordPress site with MySQL:

\`\`\`yaml
# docker-compose.yml
version: '3'

services:
  db:
    image: mysql:5.7
    volumes:
      - db_data:/var/lib/mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    networks:
      - wpsite

  wordpress:
    depends_on:
      - db
    image: wordpress:latest
    ports:
      - "8080:80"
    restart: always
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
      WORDPRESS_DB_NAME: wordpress
    volumes:
      - wordpress_data:/var/www/html
    networks:
      - wpsite

  phpmyadmin:
    depends_on:
      - db
    image: phpmyadmin/phpmyadmin
    ports:
      - "8081:80"
    environment:
      PMA_HOST: db
      MYSQL_ROOT_PASSWORD: rootpassword
    networks:
      - wpsite

networks:
  wpsite:

volumes:
  db_data:
  wordpress_data:
Save this as docker-compose.yml and run it with:

```bash docker-compose up -d


Access WordPress at http://localhost:8080 and phpMyAdmin at http://localhost:8081.

#### Mini-Project: Git Workflow Script

Create a script to automate common Git workflows:

\`\`\`bash
#!/bin/bash
# git_workflow.sh - Automate common Git workflows

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to display menu
show_menu() {
    clear
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}          GIT WORKFLOW SCRIPT          ${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}1.${NC} Initialize a new Git repository"
    echo -e "${GREEN}2.${NC} Clone a repository"
    echo -e "${GREEN}3.${NC} Create a new feature branch"
    echo -e "${GREEN}4.${NC} Commit changes"
    echo -e "${GREEN}5.${NC} Push changes to remote"
    echo -e "${GREEN}6.${NC} Pull latest changes"
    echo -e "${GREEN}7.${NC} Merge branches"
    echo -e "${GREEN}8.${NC} View commit history"
    echo -e "${GREEN}9.${NC} View repository status"
    echo -e "${GREEN}10.${NC} Create a GitHub repository"
    echo -e "${GREEN}0.${NC} Exit"
    echo -e "${BLUE}========================================${NC}"
    echo -ne "${YELLOW}Please select an option:${NC} "
}

# Function to pause
pause() {
    echo
    read -p "Press [Enter] to continue..." fackEnterKey
}

# Function to check if git is installed
check_git() {
    if ! command -v git &> /dev/null; then
        echo -e "${RED}Git is not installed. Please install Git first.${NC}"
        exit 1
    fi
}

# Function to check if gh (GitHub CLI) is installed
check_gh() {
    if ! command -v gh &> /dev/null; then
        echo -e "${RED}GitHub CLI is not installed. Please install it first.${NC}"
        return 1
    fi
    return 0
}

# Function to initialize a new Git repository
init_repo() {
    echo -e "${BLUE}Initialize a new Git repository:${NC}"
    read -p "Enter directory name (default: current directory): " dir_name
    
    if [ -z "$dir_name" ]; then
        dir_name="."
    else
        mkdir -p "$dir_name"
        cd "$dir_name"
    fi
    
    git init
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Git repository initialized successfully in $dir_name${NC}"
        
        # Create .gitignore
        read -p "Create a basic .gitignore file? (y/n): " create_gitignore
        
        if [[ "$create_gitignore" =~ ^[Yy]$ ]]; then
            cat > .gitignore << 'EOL'
# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Editor directories and files
.idea/
.vscode/
*.swp
*.swo

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
vendor/

# Build directories
dist/
build/
out/

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local
EOL
            echo -e "${GREEN}.gitignore file created${NC}"
        fi
        
        # Create README.md
        read -p "Create a README.md file? (y/n): " create_readme
        
        if [[ "$create_readme" =~ ^[Yy]$ ]]; then
            read -p "Enter project name: " project_name
            project_name=${project_name:-"My Project"}
            
            cat > README.md << EOL
# $project_name

## Description
A brief description of the project.

## Installation
Installation instructions go here.

## Usage
Usage instructions go here.

## Contributing
Contribution guidelines go here.

## License
License information goes here.
EOL
            echo -e "${GREEN}README.md file created${NC}"
        fi
        
        # Initial commit
        read -p "Make initial commit? (y/n): " make_commit
        
        if [[ "$make_commit" =~ ^[Yy]$ ]]; then
            git add .
            git commit -m "Initial commit"
            echo -e "${GREEN}Initial commit created${NC}"
        fi
    else
        echo -e "${RED}Failed to initialize Git repository${NC}"
    fi
}

# Function to clone a repository
clone_repo() {
    echo -e "${BLUE}Clone a repository:${NC}"
    read -p "Enter repository URL: " repo_url
    
    if [ -z "$repo_url" ]; then
        echo -e "${RED}Repository URL is required${NC}"
        return
    fi
    
    read -p "Enter directory name (default: auto): " dir_name
    
    if [ -z "$dir_name" ]; then
        git clone "$repo_url"
    else
        git clone "$repo_url" "$dir_name"
    fi
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Repository cloned successfully${NC}"
    else
        echo -e "${RED}Failed to clone repository${NC}"
    fi
}

# Function to create a new feature branch
create_branch() {
    echo -e "${BLUE}Create a new feature branch:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for branch type
    echo -e "${YELLOW}Branch type:${NC}"
    echo "1. feature - New feature"
    echo "2. bugfix - Bug fix"
    echo "3. hotfix - Critical fix"
    echo "4. release - Release preparation"
    echo "5. custom - Custom branch name"
    read -p "Select branch type [1-5]: " branch_type
    
    case $branch_type in
        1) prefix="feature/" ;;
        2) prefix="bugfix/" ;;
        3) prefix="hotfix/" ;;
        4) prefix="release/" ;;
        5) prefix="" ;;
        *) prefix="feature/" ;;
    esac
    
    # Get branch name
    read -p "Enter branch name: " branch_name
    
    if [ -z "$branch_name" ]; then
        echo -e "${RED}Branch name is required${NC}"
        return
    fi
    
    # Create and checkout branch
    full_branch_name="${prefix}${branch_name}"
    git checkout -b "$full_branch_name"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Created and switched to branch $full_branch_name${NC}"
    else
        echo -e "${RED}Failed to create branch${NC}"
    fi
}

# Function to commit changes
commit_changes() {
    echo -e "${BLUE}Commit changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    echo -e "${YELLOW}Current status:${NC}"
    git status
    
    # Ask which files to add
    read -p "Add all files? (y/n): " add_all
    
    if [[ "$add_all" =~ ^[Yy]$ ]]; then
        git add .
    else
        read -p "Enter files to add (space-separated): " files
        git add $files
    fi
    
    # Show what's staged
    echo -e "${YELLOW}Files staged for commit:${NC}"
    git diff --cached --name-status
    
    # Get commit message
    read -p "Enter commit message: " commit_message
    
    if [ -z "$commit_message" ]; then
        echo -e "${RED}Commit message is required${NC}"
        return
    fi
    
    # Commit changes
    git commit -m "$commit_message"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes committed successfully${NC}"
    else
        echo -e "${RED}Failed to commit changes${NC}"
    fi
}

# Function to push changes to remote
push_changes() {
    echo -e "${BLUE}Push changes to remote:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Check if remote exists
    if ! git remote -v | grep -q origin; then
        echo -e "${YELLOW}No remote repository configured${NC}"
        read -p "Enter remote repository URL: " remote_url
        
        if [ -z "$remote_url" ]; then
            echo -e "${RED}Remote URL is required${NC}"
            return
        fi
        
        git remote add origin "$remote_url"
        echo -e "${GREEN}Remote 'origin' added${NC}"
    fi
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Push changes
    git push -u "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pushed to $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to push changes${NC}"
    fi
}

# Function to pull latest changes
pull_changes() {
    echo -e "${BLUE}Pull latest changes:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # Ask for remote and branch
    read -p "Enter remote name (default: origin): " remote_name
    remote_name=${remote_name:-"origin"}
    
    read -p "Enter remote branch (default: $current_branch): " remote_branch
    remote_branch=${remote_branch:-"$current_branch"}
    
    # Pull changes
    git pull "$remote_name" "$remote_branch"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}Changes pulled from $remote_name/$remote_branch successfully${NC}"
    else
        echo -e "${RED}Failed to pull changes${NC}"
    fi
}

# Function to merge branches
merge_branches() {
    echo -e "${BLUE}Merge branches:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Get current branch
    current_branch=$(git branch --show-current)
    echo -e "${YELLOW}Current branch: $current_branch${NC}"
    
    # List available branches
    echo -e "${YELLOW}Available branches:${NC}"
    git branch
    
    # Ask for source branch
    read -p "Enter source branch to merge from: " source_branch
    
    if [ -z "$source_branch" ]; then
        echo -e "${RED}Source branch is required${NC}"
        return
    fi
    
    # Confirm merge
    read -p "Merge $source_branch into $current_branch? (y/n): " confirm_merge
    
    if [[ "$confirm_merge" =~ ^[Yy]$ ]]; then
        git merge "$source_branch"
        
        if [ $? -eq 0 ]; then
            echo -e "${GREEN}Merged $source_branch into $current_branch successfully${NC}"
        else
            echo -e "${RED}Merge conflict occurred${NC}"
            echo -e "${YELLOW}Resolve conflicts and then run:${NC}"
            echo "git add <resolved-files>"
            echo "git commit -m \"Merge $source_branch into $current_branch\""
        fi
    else
        echo -e "${YELLOW}Merge cancelled${NC}"
    fi
}

# Function to view commit history
view_history() {
    echo -e "${BLUE}View commit history:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Ask for history format
    echo -e "${YELLOW}History format:${NC}"
    echo "1. Simple (one line per commit)"
    echo "2. Detailed (full commit info)"
    echo "3. Graph (with branch visualization)"
    echo "4. Stats (with file changes)"
    read -p "Select format [1-4]: " format
    
    case $format in
        1) git log --oneline | head -20 ;;
        2) git log | head -50 ;;
        3) git log --graph --oneline --all | head -30 ;;
        4) git log --stat | head -50 ;;
        *) git log --oneline | head -20 ;;
    esac
}

# Function to view repository status
view_status() {
    echo -e "${BLUE}View repository status:${NC}"
    
    # Check if in a git repository
    if ! git rev-parse --is-inside-work-tree &> /dev/null; then
        echo -e "${RED}Not in a Git repository${NC}"
        return
    fi
    
    # Show status
    git status
    
    # Show branch info
    echo -e "\n${YELLOW}Branch information:${NC}"
    git branch -v
    
    # Show remote info
    echo -e "\n${YELLOW}Remote information:${NC}"
    git remote -v
}

# Function to create a GitHub repository
create_github_repo() {
    echo -e "${BLUE}Create a GitHub repository:${NC}"
    
    # Check if GitHub CLI is installed
    if ! check_gh; then
        echo -e "${YELLOW}GitHub CLI not found. You can install it from: https://cli.github.com/${NC}"
        return
    fi
    
    # Check if authenticated
    if ! gh auth status &> /dev/null; then
        echo -e "${YELLOW}Not authenticated with GitHub. Please login:${NC}"
        gh auth login
    fi
    
    # Get repository name
    read -p "Enter repository name: " repo_name
    
    if [ -z "$repo_name" ]; then
        echo -e "${RED}Repository name is required${NC}"
        return
    fi
    
    # Get repository visibility
    read -p "Make repository public? (y/n): " repo_public
    
    if [[ "$repo_public" =~ ^[Yy]$ ]]; then
        visibility="--public"
    else
        visibility="--private"
    fi
    
    # Get repository description
    read -p "Enter repository description (optional): " repo_desc
    
    if [ -n "$repo_desc" ]; then
        description="--description \"$repo_desc\""
    else
        description=""
    fi
    
    # Create repository
    eval "gh repo create $repo_name $visibility $description"
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}GitHub repository created successfully${NC}"
        
        # Check if in a git repository
        if git rev-parse --is-inside-work-tree &> /dev/null; then
            read -p "Add this GitHub repository as remote? (y/n): " add_remote
            
            if [[ "$add_remote" =~ ^[Yy]$ ]]; then
                git remote add origin "git@github.com:$(gh api user | jq -r .login)/$repo_name.git"
                echo -e "${GREEN}Remote 'origin' added${NC}"
            fi
        fi
    else
        echo -e "${RED}Failed to create GitHub repository${NC}"
    fi
}

# Main function
main() {
    local choice
    
    # Check if git is installed
    check_git
    
    while true; do
        show_menu
        read choice
        
        case $choice in
            1) init_repo ;;
            2) clone_repo ;;
            3) create_branch ;;
            4) commit_changes ;;
            5) push_changes ;;
            6) pull_changes ;;
            7) merge_branches ;;
            8) view_history ;;
            9) view_status ;;
            10) create_github_repo ;;
            0) 
                echo -e "${GREEN}Thank you for using Git Workflow Script!${NC}"
                exit 0
                ;;
            *) 
                echo -e "${RED}Invalid option. Please try again.${NC}"
                ;;
        esac
        
        pause
    done
}

# Run main function
main
Save this script as git_workflow.sh, make it executable with chmod +x git_workflow.sh, and run it with ./git_workflow.sh.

Day 6 Learning Outcomes
By the end of Day 6, you should be able to:

Understand and use Docker for containerization
Create and manage Docker images and containers
Use Docker Compose for multi-container applications
Master Git for version control
Work with GitHub and GitHub CLI
Set up SSH keys for secure authentication
Understand CI/CD workflows
Create scripts to automate Git workflows
Additional Resources for Day 6
Docker Documentation
Docker Compose Documentation
Git Documentation
GitHub CLI Documentation
GitHub Actions Documentation
Day 7: Week 1 Capstone Project
It's time to apply everything you've learned in Week 1 to a comprehensive project. This capstone project will integrate shell scripting, user management, networking, package management, service management, and containerization.

Project: Automated Web Server Deployment and Monitoring System
In this project, you'll create a comprehensive system that:

Automates the deployment of a web server with a database backend
Sets up proper user permissions and security
Configures networking and firewall rules
Implements monitoring and logging
Creates a backup and recovery system
Containerizes the application for easy deployment
Step 1: Create the Project Structure
```bash mkdir -p ~/web-server-project/{scripts,configs,logs,backups,www} cd ~/web-server-project


#### Step 2: Create the Main Deployment Script

Create a file called `deploy.sh` in the `scripts` directory:

\`\`\`bash
#!/bin/bash
# deploy.sh - Main deployment script for web server project

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
CONFIG_DIR="$PROJECT_DIR/configs"
LOGS_DIR="$PROJECT_DIR/logs"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="$PROJECT_DIR/www"

# Log file
LOG_FILE="$LOGS_DIR/deployment_$(date +%Y%m%d_%H%M%S).log"

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to check if running as root
check_root() {
    if [ "$(id -u)" -ne 0 ]; then
        log_message "${RED}This script must be run as root${NC}"
        exit 1
    fi
}

# Function to detect Linux distribution
detect_distro() {
    if command -v apt-get &> /dev/null; then
        echo "debian"
    elif command -v yum &> /dev/null; then
        echo "rhel"
    else
        echo "unknown"
    fi
}

# Function to install required packages
install_packages() {
    log_message "${BLUE}Installing required packages...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        apt-get update -y >> "$LOG_FILE" 2>&1
        apt-get install -y nginx mariadb-server php-fpm php-mysql \
            fail2ban ufw logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    elif [ "$DISTRO" = "rhel" ]; then
        yum update -y >> "$LOG_FILE" 2>&1
        yum install -y nginx mariadb-server php-fpm php-mysqlnd \
            fail2ban firewalld logrotate rsync curl git unzip \
            python3 python3-pip >> "$LOG_FILE" 2>&1
    else
        log_message "${RED}Unsupported Linux distribution${NC}"
        exit 1
    fi
    
    log_message "${GREEN}Packages installed successfully${NC}"
}

# Function to create web server user
create_web_user() {
    log_message "${BLUE}Creating web server user...${NC}"
    
    # Check if user already exists
    if id "webadmin" &>/dev/null; then
        log_message "${YELLOW}User webadmin already exists${NC}"
    else
        useradd -m -s /bin/bash webadmin
        echo "webadmin:$(openssl rand -base64 12)" | chpasswd
        usermod -aG sudo webadmin
        log_message "${GREEN}User webadmin created successfully${NC}"
    fi
    
    # Set up SSH key authentication for webadmin
    if [ ! -d "/home/webadmin/.ssh" ]; then
        mkdir -p /home/webadmin/.ssh
        chmod 700 /home/webadmin/.ssh
        
        # Generate SSH key pair
        ssh-keygen -t ed25519 -f /home/webadmin/.ssh/id_ed25519 -N "" -C "webadmin@$(hostname)"
        
        # Set up authorized_keys
        touch /home/webadmin/.ssh/authorized_keys
        chmod 600 /home/webadmin/.ssh/authorized_keys
        
        # Set ownership
        chown -R webadmin:webadmin /home/webadmin/.ssh
        
        log_message "${GREEN}SSH key authentication set up for webadmin${NC}"
        log_message "${YELLOW}Public key: $(cat /home/webadmin/.ssh/id_ed25519.pub)${NC}"
    fi
}

# Function to configure Nginx
configure_nginx() {
    log_message "${BLUE}Configuring Nginx...${NC}"
    
    # Create Nginx configuration
    cat > /etc/nginx/sites-available/default << 'EOL'
server {
    listen 80 default_server;
    listen [::]:80 default_server;
    
    root /var/www/html;
    index index.php index.html index.htm;
    
    server_name _;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        include snippets/fastcgi-php.conf;
        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
    }
    
    location ~ /\.ht {
        deny all;
    }
    
    # Additional security headers
    add_header X-Content-Type-Options nosniff;
    add_header X-Frame-Options SAMEORIGIN;
    add_header X-XSS-Protection "1; mode=block";
}
EOL
    
    # Create a sample index.php file
    cat > /var/www/html/index.php << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Web Server Deployment</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Web Server Deployment Successful!</h1>
        <p>This page confirms that your web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Set proper permissions
    chown -R www-data:www-data /var/www/html
    chmod -R 755 /var/www/html
    
    # Restart Nginx
    systemctl restart nginx
    systemctl enable nginx
    
    log_message "${GREEN}Nginx configured successfully${NC}"
}

# Function to configure MariaDB
configure_mariadb() {
    log_message "${BLUE}Configuring MariaDB...${NC}"
    
    # Generate a random password for the database root user
    DB_ROOT_PASSWORD=$(openssl rand -base64 12)
    
    # Start MariaDB service
    systemctl start mariadb
    systemctl enable mariadb
    
    # Secure MariaDB installation
    mysql -u root << EOF
UPDATE mysql.user SET Password=PASSWORD('$DB_ROOT_PASSWORD') WHERE User='root';
DELETE FROM mysql.user WHERE User='';
DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1');
DROP DATABASE IF EXISTS test;
DELETE FROM mysql.db WHERE Db='test' OR Db='test\\_%';
FLUSH PRIVILEGES;
EOF
    
    # Create a database and user for the web application
    DB_NAME="webapp"
    DB_USER="webappuser"
    DB_PASSWORD=$(openssl rand -base64 12)
    
    mysql -u root -p"$DB_ROOT_PASSWORD" << EOF
CREATE DATABASE $DB_NAME;
CREATE USER '$DB_USER'@'localhost' IDENTIFIED BY '$DB_PASSWORD';
GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'localhost';
FLUSH PRIVILEGES;
EOF
    
    # Save database credentials to a secure file
    cat > "$CONFIG_DIR/db_credentials.txt" << EOF
Database Name: $DB_NAME
Database User: $DB_USER
Database Password: $DB_PASSWORD
Database Root Password: $DB_ROOT_PASSWORD
EOF
    
    chmod 600 "$CONFIG_DIR/db_credentials.txt"
    
    log_message "${GREEN}MariaDB configured successfully${NC}"
    log_message "${YELLOW}Database credentials saved to $CONFIG_DIR/db_credentials.txt${NC}"
}

# Function to configure PHP
configure_php() {
    log_message "${BLUE}Configuring PHP...${NC}"
    
    # Find the PHP configuration file
    if [ -f /etc/php/7.4/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.4/fpm/php.ini"
    elif [ -f /etc/php/7.3/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.3/fpm/php.ini"
    elif [ -f /etc/php/7.2/fpm/php.ini ]; then
        PHP_INI="/etc/php/7.2/fpm/php.ini"
    elif [ -f /etc/php.ini ]; then
        PHP_INI="/etc/php.ini"
    else
        log_message "${YELLOW}PHP configuration file not found${NC}"
        return
    fi
    
    # Backup original PHP configuration
    cp "$PHP_INI" "$PHP_INI.bak"
    
    # Update PHP configuration
    sed -i 's/^max_execution_time = .*/max_execution_time = 60/' "$PHP_INI"
    sed -i 's/^memory_limit = .*/memory_limit = 256M/' "$PHP_INI"
    sed -i 's/^upload_max_filesize = .*/upload_max_filesize = 20M/' "$PHP_INI"
    sed -i 's/^post_max_size = .*/post_max_size = 20M/' "$PHP_INI"
    sed -i 's/^;date.timezone.*/date.timezone = UTC/' "$PHP_INI"
    
    # Restart PHP-FPM
    if [ "$DISTRO" = "debian" ]; then
        systemctl restart php7.4-fpm 2>/dev/null || systemctl restart php7.3-fpm 2>/dev/null || systemctl restart php7.2-fpm
    elif [ "$DISTRO" = "rhel" ]; then
        systemctl restart php-fpm
    fi
    
    log_message "${GREEN}PHP configured successfully${NC}"
}

# Function to configure firewall
configure_firewall() {
    log_message "${BLUE}Configuring firewall...${NC}"
    
    if [ "$DISTRO" = "debian" ]; then
        # Configure UFW
        ufw default deny incoming
        ufw default allow outgoing
        ufw allow ssh
        ufw allow http
        ufw allow https
        
        # Enable UFW
        echo "y" | ufw enable
        
        log_message "${GREEN}UFW firewall configured successfully${NC}"
    elif [ "$DISTRO" = "rhel" ]; then
        # Configure firewalld
        systemctl start firewalld
        systemctl enable firewalld
        
        firewall-cmd --permanent --add-service=ssh
        firewall-cmd --permanent --add-service=http
        firewall-cmd --permanent --add-service=https
        firewall-cmd --reload
        
        log_message "${GREEN}Firewalld configured successfully${NC}"
    fi
}

# Function to configure fail2ban
configure_fail2ban() {
    log_message "${BLUE}Configuring fail2ban...${NC}"
    
    # Create fail2ban configuration
    cat > /etc/fail2ban/jail.local << 'EOL'
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 5

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3

[nginx-http-auth]
enabled = true
filter = nginx-http-auth
port = http,https
logpath = /var/log/nginx/error.log
EOL
    
    # Restart fail2ban
    systemctl restart fail2ban
    systemctl enable fail2ban
    
    log_message "${GREEN}Fail2ban configured successfully${NC}"
}

# Function to set up log rotation
configure_logrotate() {
    log_message "${BLUE}Configuring log rotation...${NC}"
    
    # Create logrotate configuration for application logs
    cat > /etc/logrotate.d/webapp << 'EOL'
/var/www/html/logs/*.log {
    daily
    missingok
    rotate 14
    compress
    delaycompress
    notifempty
    create 0640 www-data www-data
    sharedscripts
    postrotate
        systemctl reload nginx
    endscript
}
EOL
    
    log_message "${GREEN}Log rotation configured successfully${NC}"
}

# Function to set up backup script
setup_backup() {
    log_message "${BLUE}Setting up backup system...${NC}"
    
    # Create backup script
    cat > "$PROJECT_DIR/scripts/backup.sh" << 'EOL'
#!/bin/bash
# backup.sh - Backup script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
BACKUP_DIR="$PROJECT_DIR/backups"
WWW_DIR="/var/www/html"
DB_NAME="webapp"
DB_USER="webappuser"
DB_PASSWORD=$(grep "Database Password:" "$PROJECT_DIR/configs/db_credentials.txt" | cut -d' ' -f3)
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/backup_$DATE.tar.gz"
DB_BACKUP_FILE="$BACKUP_DIR/db_backup_$DATE.sql"

# Create backup directory if it doesn't exist
mkdir -p "$BACKUP_DIR"

# Backup database
mysqldump -u "$DB_USER" -p"$DB_PASSWORD" "$DB_NAME" > "$DB_BACKUP_FILE"

# Backup web files
tar -czf "$BACKUP_FILE" -C "$WWW_DIR" .

# Add database backup to archive
tar -rf "${BACKUP_FILE%.tar.gz}.tar" -C "$BACKUP_DIR" "$(basename "$DB_BACKUP_FILE")"
gzip -f "${BACKUP_FILE%.tar.gz}.tar"

# Remove temporary database backup file
rm "$DB_BACKUP_FILE"

# Keep only the last 7 backups
ls -t "$BACKUP_DIR"/backup_*.tar.gz | tail -n +8 | xargs -r rm

echo "Backup completed: $BACKUP_FILE"
EOL
    
    # Make backup script executable
    chmod +x "$PROJECT_DIR/scripts/backup.sh"
    
    # Set up cron job for daily backups
    (crontab -l 2>/dev/null; echo "0 2 * * * $PROJECT_DIR/scripts/backup.sh > $LOGS_DIR/backup.log 2>&1") | crontab -
    
    log_message "${GREEN}Backup system set up successfully${NC}"
}

# Function to set up monitoring script
setup_monitoring() {
    log_message "${BLUE}Setting up monitoring system...${NC}"
    
    # Create monitoring script
    cat > "$PROJECT_DIR/scripts/monitor.sh" << 'EOL'
#!/bin/bash
# monitor.sh - Monitoring script for web server

# Configuration
PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
LOGS_DIR="$PROJECT_DIR/logs"
MONITOR_LOG="$LOGS_DIR/monitor.log"
EMAIL_RECIPIENT="admin@example.com"
HOSTNAME=$(hostname)
DATE=$(date +%Y-%m-%d)
TIME=$(date +%H:%M:%S)

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo "$timestamp - $message" >> "$MONITOR_LOG"
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Check if services are running
check_services() {
    log_message "Checking services..."
    
    # Check Nginx
    if ! systemctl is-active --quiet nginx; then
        log_message "ERROR: Nginx is not running"
        send_alert "[$HOSTNAME] Nginx is down" "Nginx service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart nginx
    else
        log_message "Nginx is running"
    fi
    
    # Check MariaDB
    if ! systemctl is-active --quiet mariadb; then
        log_message "ERROR: MariaDB is not running"
        send_alert "[$HOSTNAME] MariaDB is down" "MariaDB service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart mariadb
    else
        log_message "MariaDB is running"
    fi
    
    # Check PHP-FPM
    if ! systemctl is-active --quiet php7.4-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.3-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php7.2-fpm 2>/dev/null && 
       ! systemctl is-active --quiet php-fpm 2>/dev/null; then
        log_message "ERROR: PHP-FPM is not running"
        send_alert "[$HOSTNAME] PHP-FPM is down" "PHP-FPM service is not running on $HOSTNAME at $DATE $TIME"
        systemctl restart php7.4-fpm 2>/dev/null || 
        systemctl restart php7.3-fpm 2>/dev/null || 
        systemctl restart php7.2-fpm 2>/dev/null || 
        systemctl restart php-fpm 2>/dev/null
    else
        log_message "PHP-FPM is running"
    fi
}

# Check disk space
check_disk_space() {
    log_message "Checking disk space..."
    
    # Get disk usage percentage
    DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    
    if [ "$DISK_USAGE" -gt 90 ]; then
        log_message "WARNING: Disk space is critically low ($DISK_USAGE%)"
        send_alert "[$HOSTNAME] Disk space critical" "Disk space usage is at $DISK_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$DISK_USAGE" -gt 80 ]; then
        log_message "WARNING: Disk space is running low ($DISK_USAGE%)"
    else
        log_message "Disk space is OK ($DISK_USAGE%)"
    fi
}

# Check memory usage
check_memory() {
    log_message "Checking memory usage..."
    
    # Get memory usage percentage
    MEM_USAGE=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
    
    if [ "$MEM_USAGE" -gt 90 ]; then
        log_message "WARNING: Memory usage is critically high ($MEM_USAGE%)"
        send_alert "[$HOSTNAME] Memory usage critical" "Memory usage is at $MEM_USAGE% on $HOSTNAME at $DATE $TIME"
    elif [ "$MEM_USAGE" -gt 80 ]; then
        log_message "WARNING: Memory usage is high ($MEM_USAGE%)"
    else
        log_message "Memory usage is OK ($MEM_USAGE%)"
    fi
}

# Check load average
check_load() {
    log_message "Checking system load..."
    
    # Get number of CPU cores
    CPU_CORES=$(nproc)
    
    # Get load average for 1 minute
    LOAD_AVG=$(cat /proc/loadavg | awk '{print $1}')
    
    # Calculate load per core
    LOAD_PER_CORE=$(echo "$LOAD_AVG / $CPU_CORES" | bc -l)
    
    if (( $(echo "$LOAD_PER_CORE > 2.0" | bc -l) )); then
        log_message "WARNING: System load is critically high (${LOAD_AVG})"
        send_alert "[$HOSTNAME] System load critical" "System load is at ${LOAD_AVG} (${LOAD_PER_CORE} per core) on $HOSTNAME at $DATE $TIME"
    elif (( $(echo "$LOAD_PER_CORE > 1.0" | bc -l) )); then
        log_message "WARNING: System load is high (${LOAD_AVG})"
    else
        log_message "System load is OK (${LOAD_AVG})"
    fi
}

# Check for failed login attempts
check_failed_logins() {
    log_message "Checking for failed login attempts..."
    
    # Count failed SSH login attempts in the last hour
    FAILED_LOGINS=$(grep "Failed password" /var/log/auth.log | grep -c "$(date +%b' '%d' '%H)")
    
    if [ "$FAILED_LOGINS" -gt 10 ]; then
        log_message "WARNING: High number of failed login attempts ($FAILED_LOGINS in the last hour)"
        send_alert "[$HOSTNAME] Security alert" "High number of failed login attempts ($FAILED_LOGINS in the last hour) on $HOSTNAME at $DATE $TIME"
    elif [ "$FAILED_LOGINS" -gt 5 ]; then
        log_message "WARNING: Multiple failed login attempts ($FAILED_LOGINS in the last hour)"
    else
        log_message "Failed login attempts are OK ($FAILED_LOGINS in the last hour)"
    fi
}

# Check HTTP response
check_http_response() {
    log_message "Checking HTTP response..."
    
    # Get HTTP status code
    HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" http://localhost)
    
    if [ "$HTTP_STATUS" != "200" ]; then
        log_message "ERROR: HTTP response is not OK (status code: $HTTP_STATUS)"
        send_alert "[$HOSTNAME] Website is down" "Website returned HTTP status code $HTTP_STATUS on $HOSTNAME at $DATE $TIME"
    else
        log_message "HTTP response is OK (status code: $HTTP_STATUS)"
    fi
}

# Main function
main() {
    log_message "Starting monitoring check..."
    
    check_services
    check_disk_space
    check_memory
    check_load
    check_failed_logins
    check_http_response
    
    log_message "Monitoring check completed"
}

# Create logs directory if it doesn't exist
mkdir -p "$LOGS_DIR"

# Run main function
main
EOL
    
    # Make monitoring script executable
    chmod +x "$PROJECT_DIR/scripts/monitor.sh"
    
    # Set up cron job for monitoring every 15 minutes
    (crontab -l 2>/dev/null; echo "*/15 * * * * $PROJECT_DIR/scripts/monitor.sh > /dev/null 2>&1") | crontab -
    
    log_message "${GREEN}Monitoring system set up successfully${NC}"
}

# Function to create Docker configuration
setup_docker() {
    log_message "${BLUE}Setting up Docker configuration...${NC}"
    
    # Check if Docker is installed
    if ! command -v docker &> /dev/null; then
        log_message "${YELLOW}Docker is not installed. Installing Docker...${NC}"
        
        if [ "$DISTRO" = "debian" ]; then
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release >> "$LOG_FILE" 2>&1
            curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
            echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
            apt-get update -y >> "$LOG_FILE" 2>&1
            apt-get install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        elif [ "$DISTRO" = "rhel" ]; then
            yum install -y yum-utils >> "$LOG_FILE" 2>&1
            yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo >> "$LOG_FILE" 2>&1
            yum install -y docker-ce docker-ce-cli containerd.io >> "$LOG_FILE" 2>&1
        fi
        
        systemctl start docker
        systemctl enable docker
    fi
    
    # Check if Docker Compose is installed
    if ! command -v docker-compose &> /dev/null; then
        log_message "${YELLOW}Docker Compose is not installed. Installing Docker Compose...${NC}"
        
        curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        chmod +x /usr/local/bin/docker-compose
    fi
    
    # Create Docker Compose configuration
    cat > "$PROJECT_DIR/docker-compose.yml" << 'EOL'
version: '3'

services:
  web:
    image: nginx:latest
    ports:
      - "8080:80"
    volumes:
      - ./www:/usr/share/nginx/html
      - ./configs/nginx.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - php
    networks:
      - webapp

  php:
    image: php:7.4-fpm
    volumes:
      - ./www:/var/www/html
    networks:
      - webapp

  db:
    image: mariadb:latest
    environment:
      MYSQL_ROOT_PASSWORD: ${DB_ROOT_PASSWORD}
      MYSQL_DATABASE: ${DB_NAME}
      MYSQL_USER: ${DB_USER}
      MYSQL_PASSWORD: ${DB_PASSWORD}
    volumes:
      - db_data:/var/lib/mysql
    networks:
      - webapp

networks:
  webapp:

volumes:
  db_data:
EOL
    
    # Create Nginx configuration for Docker
    mkdir -p "$CONFIG_DIR"
    cat > "$CONFIG_DIR/nginx.conf" << 'EOL'
server {
    listen 80;
    server_name localhost;
    
    root /usr/share/nginx/html;
    index index.php index.html;
    
    location / {
        try_files $uri $uri/ =404;
    }
    
    location ~ \.php$ {
        fastcgi_pass php:9000;
        fastcgi_index index.php;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        include fastcgi_params;
    }
}
EOL
    
    # Create .env file for Docker Compose
    cat > "$PROJECT_DIR/.env" << EOF
DB_ROOT_PASSWORD=$(grep "Database Root Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f4)
DB_NAME=$(grep "Database Name:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_USER=$(grep "Database User:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
DB_PASSWORD=$(grep "Database Password:" "$CONFIG_DIR/db_credentials.txt" | cut -d' ' -f3)
EOF
    
    # Create sample index.php file for Docker
    mkdir -p "$WWW_DIR"
    cat > "$WWW_DIR/index.php" << 'EOL'
&lt;!DOCTYPE html>
<html>
<head>
    <title>Docker Web Server</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }
        .info {
            background-color: #e7f3fe;
            border-left: 6px solid #2196F3;
            padding: 10px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Docker Web Server Deployment Successful!</h1>
        <p>This page confirms that your Docker web server has been successfully deployed.</p>
        
        <div class="info">
            <h2>Server Information</h2>
            <p>Server: <?php echo $_SERVER['SERVER_SOFTWARE']; ?></p>
            <p>PHP Version: <?php echo phpversion(); ?></p>
            <p>Hostname: <?php echo gethostname(); ?></p>
            <p>Date/Time: <?php echo date('Y-m-d H:i:s'); ?></p>
        </div>
        
        <h2>Database Connection Test</h2>
        <?php
        $host = 'db';
        $dbname = getenv('DB_NAME');
        $user = getenv('DB_USER');
        $pass = getenv('DB_PASSWORD');
        
        try {
            $conn = new PDO("mysql:host=$host;dbname=$dbname", $user, $pass);
            $conn->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
            echo '<p style="color: green;">Database connection successful!</p>';
        } catch(PDOException $e) {
            echo '<p style="color: red;">Database connection failed: ' . $e->getMessage() . '</p>';
        }
        ?>
        
        <h2>PHP Information</h2>
        <?php phpinfo(); ?>
    </div>
</body>
</html>
EOL
    
    # Create Docker start script
    cat > "$PROJECT_DIR/scripts/start-docker.sh" << 'EOL'
#!/bin/bash
# start-docker.sh - Start Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose up -d

echo "Docker containers started. Access the web server at http://localhost:8080"
EOL
    
    # Create Docker stop script
    cat > "$PROJECT_DIR/scripts/stop-docker.sh" << 'EOL'
#!/bin/bash
# stop-docker.sh - Stop Docker containers

PROJECT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

cd "$PROJECT_DIR"
docker-compose down

echo "Docker containers stopped"
EOL
    
    # Make Docker scripts executable
    chmod +x "$PROJECT_DIR/scripts/start-docker.sh"
    chmod +x "$PROJECT_DIR/scripts/stop-docker.sh"
    
    log_message "${GREEN}Docker configuration set up successfully${NC}"
    log_message "${YELLOW}To start Docker containers, run: $PROJECT_DIR/scripts/start-docker.sh${NC}"
    log_message "${YELLOW}To stop Docker containers, run: $PROJECT_DIR/scripts/stop-docker.sh${NC}"
}

# Function to display summary
display_summary() {
    local ip_address=$(hostname -I | awk '{print $1}')
    
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${GREEN}Web Server Deployment Complete!${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}Server IP:${NC} $ip_address"
    echo -e "${YELLOW}Web Server:${NC} http://$ip_address"
    echo -e "${YELLOW}Docker Web Server:${NC} http://$ip_address:8080 (when Docker is running)"
    echo -e "\n${YELLOW}Database Credentials:${NC} $CONFIG_DIR/db_credentials.txt"
    echo -e "${YELLOW}SSH Key for webadmin:${NC} /home/webadmin/.ssh/id_ed25519"
    echo -e "\n${YELLOW}Scripts:${NC}"
    echo -e "  Backup: $PROJECT_DIR/scripts/backup.sh"
    echo -e "  Monitor: $PROJECT_DIR/scripts/monitor.sh"
    echo -e "  Docker Start: $PROJECT_DIR/scripts/start-docker.sh"
    echo -e "  Docker Stop: $PROJECT_DIR/scripts/stop-docker.sh"
    echo -e "\n${YELLOW}Logs:${NC} $LOGS_DIR"
    echo -e "${YELLOW}Backups:${NC} $BACKUP_DIR"
    echo -e "${BLUE}========================================${NC}"
    echo -e "${GREEN}Deployment log: $LOG_FILE${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# Main function
main() {
    # Create directories
    mkdir -p "$CONFIG_DIR" "$LOGS_DIR" "$BACKUP_DIR" "$WWW_DIR"
    
    # Check if running as root
    check_root
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      WEB SERVER DEPLOYMENT SCRIPT     ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Detect distribution
    DISTRO=$(detect_distro)
    log_message "${YELLOW}Detected distribution: $DISTRO${NC}"
    
    # Install packages
    install_packages
    
    # Create web server user
    create_web_user
    
    # Configure services
    configure_nginx
    configure_mariadb
    configure_php
    configure_firewall
    configure_fail2ban
    configure_logrotate
    
    # Set up scripts
    setup_backup
    setup_monitoring
    setup_docker
    
    # Display summary
    display_summary
    
    log_message "${GREEN}Web server deployment completed successfully${NC}"
}

# Run main function
main
Make the script executable:

```bash chmod +x ~/web-server-project/scripts/deploy.sh


#### Step 3: Run the Deployment Script

\`\`\`bash
sudo ~/web-server-project/scripts/deploy.sh
This script will:

Install and configure a web server (Nginx, MariaDB, PHP)
Set up a dedicated web server user with SSH key authentication
Configure firewall rules and fail2ban for security
Set up log rotation for proper log management
Create backup and monitoring scripts with cron jobs
Set up Docker and Docker Compose for containerized deployment
Generate a comprehensive deployment report
Step 4: Test the Deployment
After the script completes, you can test the deployment by:

Accessing the web server at http://your-server-ip
Starting the Docker containers with ~/web-server-project/scripts/start-docker.sh
Accessing the containerized web server at http://your-server-ip:8080
Testing the backup script with ~/web-server-project/scripts/backup.sh
Testing the monitoring script with ~/web-server-project/scripts/monitor.sh
Step 5: Document the Project
Create a README.md file for the project:

```markdown

Automated Web Server Deployment and Monitoring System
Overview
This project provides a comprehensive system for deploying, securing, and monitoring a web server environment. It includes automated scripts for installation, configuration, backup, and monitoring.

Features
Automated deployment of Nginx, MariaDB, and PHP
User management with secure SSH key authentication
Firewall configuration and intrusion prevention with fail2ban
Log rotation and management
Automated backup system
Comprehensive monitoring system
Containerized deployment with Docker and Docker Compose
Directory Structure
scripts/ - Contains all automation scripts

deploy.sh - Main deployment script
backup.sh - Automated backup script
monitor.sh - System monitoring script
start-docker.sh - Start Docker containers
stop-docker.sh - Stop Docker containers
configs/ - Configuration files
logs/ - Log files
backups/ - Backup files
www/ - Web files for Docker deployment
Usage
Initial Deployment
```bash sudo ./scripts/deploy.sh


### Managing Backups

\`\`\`bash
# Run a manual backup
./scripts/backup.sh

# Restore from backup
tar -xzf backups/backup_YYYYMMDD_HHMMSS.tar.gz -C /var/www/html
Monitoring
```bash

Run a manual monitoring check
./scripts/monitor.sh


### Docker Deployment

\`\`\`bash
# Start Docker containers
./scripts/start-docker.sh

# Stop Docker containers
./scripts/stop-docker.sh
Security Features
Dedicated web server user with restricted permissions
SSH key authentication
Firewall rules allowing only necessary services
Fail2ban for intrusion prevention
Secure database configuration
HTTPS support
Monitoring Features
Service status monitoring
Disk space monitoring
Memory usage monitoring
System load monitoring
Failed login attempts monitoring
HTTP response monitoring
Backup System
Daily automated backups
Database and file system backups
Rotation system to manage backup storage
Requirements
Ubuntu 20.04 LTS or CentOS 8
Sudo/root access
Internet connection for package installation
License
This project is licensed under the MIT License - see the LICENSE file for details.


#### Day 7 Learning Outcomes

By completing this capstone project, you should be able to:

1. Deploy and configure a complete web server environment
2. Implement proper security measures for a production server
3. Set up automated monitoring and alerting
4. Create a comprehensive backup and recovery system
5. Containerize an application for easy deployment
6. Document a complex system for future reference
7. Apply all the skills learned in Week 1 to a real-world project

#### Additional Resources for Day 7

- [Nginx Documentation](https://nginx.org/en/docs/)
- [MariaDB Documentation](https://mariadb.com/kb/en/documentation/)
- [PHP Documentation](https://www.php.net/docs.php)
- [Docker Documentation](https://docs.docker.com/)
- [Linux Server Security Guide](https://www.digitalocean.com/community/tutorials/7-security-measures-to-protect-your-servers)

## Week 2: Advanced System Administration

In Week 2, we'll build on the foundation established in Week 1 and dive into more advanced system administration topics. This week focuses on advanced shell scripting, system performance, security, networking, storage, and high availability.

### Day 8: Advanced Shell Scripting

Shell scripting is a powerful tool for automating complex tasks. In this section, we'll explore advanced shell scripting techniques that will make your scripts more robust, efficient, and maintainable.

#### Advanced Bash Features

**Bash Arrays:**

\`\`\`bash
# Indexed arrays
declare -a fruits=("Apple" "Banana" "Orange" "Mango")
echo "First fruit: ${fruits[0]}"
echo "All fruits: ${fruits[@]}"
echo "Number of fruits: ${#fruits[@]}"

# Iterating through array
for fruit in "${fruits[@]}"; do
    echo "Processing $fruit"
done

# Array operations
fruits+=(["Pineapple" "Grape"])  # Add elements
unset fruits[1]                  # Remove element
fruits=("${fruits[@]}")          # Reindex array

# Associative arrays (dictionaries)
declare -A user_info
user_info[name]="John"
user_info[age]=30
user_info[city]="New York"

echo "Name: ${user_info[name]}"
echo "Age: ${user_info[age]}"

# Iterating through associative array
for key in "${!user_info[@]}"; do
    echo "$key: ${user_info[$key]}"
done
String Manipulation:

```bash

String length
string="Hello, World!" echo "Length: ${#string}"

Substring extraction
echo "Substring: ${string:7:5}" # Start at position 7, length 5

String replacement
echo "Replace first: ${string/o/O}" # Replace first occurrence echo "Replace all: ${string//o/O}" # Replace all occurrences echo "Replace prefix: ${string/#Hello/Hi}" # Replace at beginning echo "Replace suffix: ${string/%World/Earth}" # Replace at end

Case conversion
echo "Uppercase: ${string^^}" echo "Lowercase: ${string,,}" echo "First char uppercase: ${string^}" echo "First char lowercase: ${string,}"

String trimming
string=" Hello, World! " echo "Trim leading spaces: ${string#"${string%%[![:space:]]}"}" echo "Trim trailing spaces: ${string%"${string##[![:space:]]}"}"


**Parameter Expansion and Default Values:**

\`\`\`bash
# Default values
name=${1:-"Anonymous"}  # Use $1 if set, otherwise "Anonymous"
echo "Hello, $name"

# Default assignment
count=${count:=0}  # Assign 0 to count if it's unset or null

# Error if unset
required=${required:?"Required parameter is missing"}

# Use alternate value
optional=${optional:+"Optional parameter is set to: $optional"}

# Substring removal
filename="script.test.sh"
echo "Remove prefix: ${filename#*.}"      # Remove shortest match from beginning
echo "Remove prefix: ${filename##*.}"     # Remove longest match from beginning
echo "Remove suffix: ${filename%.*}"      # Remove shortest match from end
echo "Remove suffix: ${filename%%.*}"     # Remove longest match from end
Brace Expansion:

```bash

Range expansion
echo {1..10} # 1 2 3 4 5 6 7 8 9 10 echo {a..z} # a b c d ... z echo {01..10..2} # 01 03 05 07 09

String combinations
echo {apple,banana,cherry} echo file.{txt,md,pdf} echo {2023..2025}-{01..12}

Nested brace expansion
echo {a,b{1,2,3},c} # a b1 b2 b3 c


**Process Substitution:**

\`\`\`bash
# Use command output as file
diff <(ls -l /etc) <(ls -l /tmp)
grep "pattern" <(cat file1.txt file2.txt)

# Feed command output to another command
cat <(echo "Header") file.txt <(echo "Footer")

# Multiple process substitutions
paste <(cut -f1 data.txt) <(cut -f3 data.txt)
Advanced Error Handling
Trap Command for Signal Handling:

```bash #!/bin/bash

Temporary files
TEMP_FILE1=$(mktemp) TEMP_FILE2=$(mktemp)

Cleanup function
cleanup() { echo "Cleaning up temporary files..." rm -f "$TEMP_FILE1" "$TEMP_FILE2" exit }

Trap signals
trap cleanup EXIT INT TERM

Trap specific signals with different handlers
trap 'echo "Received SIGINT"; cleanup' INT trap 'echo "Received SIGTERM"; cleanup' TERM

Rest of the script
echo "Script is running..." echo "Temporary files: $TEMP_FILE1 $TEMP_FILE2" echo "Sleeping for 30 seconds. Try pressing Ctrl+C..." sleep 30 echo "Script completed normally."


**Advanced Error Handling:**

\`\`\`bash
#!/bin/bash

# Exit on error
set -e

# Exit on undefined variable
set -u

# Exit on pipe failure
set -o pipefail

# Enable debug mode
# set -x

# Error handling function
error_exit() {
    local line=$1
    local command=$2
    local code=${3:-1}
    echo "Error on line $line running command '$command', exit code $code" >&2
    exit $code
}

# Trap errors
trap 'error_exit $LINENO "$BASH_COMMAND" $?' ERR

# Function with error checking
run_command() {
    local cmd=$1
    local error_msg=${2:-"Command failed"}
    
    echo "Running: $cmd"
    if ! eval "$cmd"; then
        echo "$error_msg" >&2
        return 1
    fi
    return 0
}

# Example usage
run_command "ls -la /etc" "Failed to list /etc directory"
run_command "ls -la /nonexistent" "Failed to list nonexistent directory" || echo "Continuing despite error"

# This will trigger the error trap
cat /nonexistent/file.txt

echo "This line will not be executed due to the error above"
Advanced Input/Output
Here Documents and Here Strings:

```bash

Here document (heredoc)
cat << EOF > output.txt This is a multi-line text block that will be written to output.txt. Current date: $(date) EOF

Here document with variable substitution disabled
cat << 'EOF' > script.sh #!/bin/bash echo "The current date is $(date)" echo "My home directory is $HOME" EOF

Here document with custom delimiter
cat << 'CUSTOM_DELIMITER' > config.ini [database] host=localhost user=dbuser password=secret123 CUSTOM_DELIMITER

Here document with indentation preserved
cat <<- EOF > indented.txt This text will have leading tabs removed. This line has two tabs, which will be removed. But the relative indentation is preserved. EOF

Here string
grep "pattern" <<< "This is a string to search for pattern" while read -r line; do echo "Line: $line" done <<< "Line 1 Line 2 Line 3"


**Advanced File Descriptors:**

\`\`\`bash
#!/bin/bash

# Redirect stdout to a file
exec 1>output.log

# Redirect stderr to a file
exec 2>error.log

# Create a new file descriptor for a file
exec 3>custom.log

# Write to custom file descriptor
echo "This goes to custom.log" >&3

# Create a file descriptor for reading
exec 4<input.txt

# Read from custom file descriptor
read -r line <&4
echo "Read from input.txt: $line"

# Duplicate file descriptors
exec 5>&1  # Save stdout to fd 5
exec 1>combined.log  # Redirect stdout to file
echo "This goes to combined.log"
exec 1>&5  # Restore stdout
echo "This goes to the terminal"

# Close file descriptors
exec 3>&-
exec 4<&-
exec 5>&-
Capturing Command Output:

```bash

Basic command substitution
current_date=$(date +%Y-%m-%d) echo "Today is $current_date"

Capturing exit status
if output=$(some_command 2>&1); then echo "Command succeeded: $output" else echo "Command failed with status $?: $output" fi

Capturing both stdout and stderr separately
{ stdout=$(eval "$cmd" 2>/tmp/stderr.) status=$? stderr=$(cat /tmp/stderr.) rm /tmp/stderr.$$ }

Using a function to capture output
capture_output() { local cmd=$1 local stdout_var=$2 local stderr_var=$3 local status_var=$4

local stdout_file=$(mktemp)
local stderr_file=$(mktemp)

eval "$cmd" > "$stdout_file" 2> "$stderr_file"
local status=$?

eval "$stdout_var='$(cat "$stdout_file")'"
eval "$stderr_var='$(cat "$stderr_file")'"
eval "$status_var=$status"

rm -f "$stdout_file" "$stderr_file"
return $status
}

Example usage
capture_output "ls -la" STDOUT STDERR STATUS echo "Exit status: $STATUS" echo "Standard output: $STDOUT" echo "Standard error: $STDERR"


#### Advanced Control Structures

**Select Loop for Menus:**

\`\`\`bash
#!/bin/bash

echo "Select a fruit:"
select fruit in "Apple" "Banana" "Orange" "Quit"; do
    case $fruit in
        "Apple")
            echo "You selected Apple"
            ;;
        "Banana")
            echo "You selected Banana"
            ;;
        "Orange")
            echo "You selected Orange"
            ;;
        "Quit")
            echo "Exiting..."
            break
            ;;
        *)
            echo "Invalid selection"
            ;;
    esac
done
Advanced Case Statements:

```bash #!/bin/bash

read -p "Enter a value: " input

case $input in [0-9]) echo "You entered a single digit" ;; [0-9][0-9]) echo "You entered a two-digit number" ;; [0-9][0-9][0-9]) echo "You entered a three-digit number" ;; [a-zA-Z]) echo "You entered a string starting with a letter" ;; [0-9]) echo "You entered a string ending with a digit" ;; @.) echo "You entered what looks like an email address" ;; .txt|.md|.doc) echo "You entered a document filename" ;; *) echo "I don't recognize the pattern of your input" ;; esac


**Advanced Loops:**

\`\`\`bash
#!/bin/bash

# Loop with step value
for ((i=0; i&lt;=20; i+=5)); do
    echo "i = $i"
done

# Loop with multiple variables
for ((i=1, j=10; i&lt;=5; i++, j--)); do
    echo "i = $i, j = $j"
done

# Loop with early termination and continuation
for file in /etc/*.conf; do
    # Skip if not a regular file
    [ -f "$file" ] || continue
    
    # Skip files larger than 10KB
    size=$(du -k "$file" | cut -f1)
    [ "$size" -gt 10 ] && continue
    
    # Process file
    echo "Processing $file (size: ${size}KB)"
    
    # Break if we've processed 5 files
    ((count++))
    [ "$count" -ge 5 ] && break
done

# Loop with named iteration
while IFS=: read -r username password uid gid info home shell; do
    # Skip system users
    [ "$uid" -lt 1000 ] && continue
    
    echo "User: $username"
    echo "  UID: $uid"
    echo "  Home: $home"
    echo "  Shell: $shell"
done &lt; /etc/passwd
Advanced Functions
Functions with Return Values:

```bash #!/bin/bash

Function with return code
is_number() { local input=$1 [[ $input =~ ^[0-9]+$ ]] return $? }

Function that returns a value via echo
get_user_home() { local username=$1 local home=$(grep "^$username:" /etc/passwd | cut -d: -f6) echo "$home" }

Function with multiple return values
get_file_info() { local file=$1 if [ ! -f "$file" ]; then echo "" echo "" return 1 fi

local size=$(du -h "$file" | cut -f1)
local type=$(file -b "$file")

echo "$size"
echo "$type"
return 0
}

Example usage
if is_number "123"; then echo "123 is a number" else echo "123 is not a number" fi

home_dir=$(get_user_home "root") echo "Root's home directory: $home_dir"

Capturing multiple return values
read -r file_size file_type < <(get_file_info "/etc/passwd") if [ -n "$file_size" ]; then echo "File size: $file_size" echo "File type: $file_type" else echo "File not found" fi


**Function Libraries:**

\`\`\`bash
#!/bin/bash
# file: lib_string.sh

# String utility functions

# Convert string to lowercase
to_lowercase() {
    local input=$1
    echo "${input,,}"
}

# Convert string to uppercase
to_uppercase() {
    local input=$1
    echo "${input^^}"
}

# Trim whitespace from string
trim() {
    local input=$1
    # Remove leading whitespace
    input="${input#"${input%%[![:space:]]*}"}"
    # Remove trailing whitespace
    input="${input%"${input##*[![:space:]]}"}"
    echo "$input"
}

# Check if string contains substring
contains() {
    local string=$1
    local substring=$2
    [[ "$string" == *"$substring"* ]]
    return $?
}

# Count occurrences of substring in string
count_occurrences() {
    local string=$1
    local substring=$2
    local count=$(grep -o "$substring" <<< "$string" | wc -l)
    echo "$count"
}

# Replace substring in string
replace_string() {
    local string=$1
    local search=$2
    local replace=$3
    echo "${string//$search/$replace}"
}
```bash #!/bin/bash

file: lib_file.sh
File utility functions
Check if file exists and is readable
is_readable_file() { local file=$1 [ -f "$file" ] && [ -r "$file" ] return $? }

Get file size in human-readable format
get_file_size() { local file=$1 if is_readable_file "$file"; then du -h "$file" | cut -f1 else echo "0" fi }

Count lines in file
count_lines() { local file=$1 if is_readable_file "$file"; then wc -l < "$file" else echo "0" fi }

Get file modification time
get_file_mtime() { local file=$1 if is_readable_file "$file"; then stat -c %y "$file" else echo "" fi }

Create backup of file
backup_file() { local file=$1 local backup="${file}.bak" if is_readable_file "$file"; then cp -f "$file" "$backup" return $? else return 1 fi }


\`\`\`bash
#!/bin/bash
# file: main.sh

# Source function libraries
source ./lib_string.sh
source ./lib_file.sh

# Example usage
filename="/etc/passwd"

# String functions
echo "Lowercase: $(to_lowercase "HELLO World")"
echo "Uppercase: $(to_uppercase "hello World")"
echo "Trimmed: '$(trim "  hello world  ")'"

if contains "hello world" "world"; then
    echo "String contains 'world'"
fi

echo "Occurrences of 'o': $(count_occurrences "hello world" "o")"
echo "Replaced: $(replace_string "hello world" "world" "universe")"

# File functions
if is_readable_file "$filename"; then
    echo "File size: $(get_file_size "$filename")"
    echo "Line count: $(count_lines "$filename")"
    echo "Modified: $(get_file_mtime "$filename")"
    
    if backup_file "$filename"; then
        echo "Backup created: ${filename}.bak"
    fi
else
    echo "File $filename is not readable"
fi
Advanced Script Organization
Modular Script Design:

```bash #!/bin/bash

file: config.sh
Configuration variables
APP_NAME="MyApp" APP_VERSION="1.0.0" LOG_DIR="/var/log/$APP_NAME" CONFIG_DIR="/etc/$APP_NAME" DATA_DIR="/var/lib/$APP_NAME" TEMP_DIR="/tmp/$APP_NAME"

Default settings
DEBUG_MODE=false VERBOSE_MODE=false MAX_RETRIES=3 TIMEOUT=30


\`\`\`bash
#!/bin/bash
# file: utils.sh

# Source configuration
source ./config.sh

# Utility functions

# Logging function
log() {
    local level=$1
    local message=$2
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    
    # Create log directory if it doesn't exist
    mkdir -p "$LOG_DIR"
    
    # Log to file
    echo "[$timestamp] [$level] $message" >> "$LOG_DIR/app.log"
    
    # Log to console if verbose mode is enabled
    if [ "$VERBOSE_MODE" = true ] || [ "$level" = "ERROR" ]; then
        echo "[$timestamp] [$level] $message"
    fi
}

# Debug logging
debug() {
    if [ "$DEBUG_MODE" = true ]; then
        log "DEBUG" "$1"
    fi
}

# Info logging
info() {
    log "INFO" "$1"
}

# Warning logging
warn() {
    log "WARNING" "$1"
}

# Error logging
error() {
    log "ERROR" "$1"
}

# Create required directories
create_dirs() {
    mkdir -p "$LOG_DIR" "$CONFIG_DIR" "$DATA_DIR" "$TEMP_DIR"
    
    # Check if directories were created successfully
    if [ ! -d "$LOG_DIR" ] || [ ! -d "$CONFIG_DIR" ] || [ ! -d "$DATA_DIR" ] || [ ! -d "$TEMP_DIR" ]; then
        error "Failed to create required directories"
        return 1
    fi
    
    debug "Created required directories"
    return 0
}

# Clean up temporary files
cleanup() {
    debug "Cleaning up temporary files"
    rm -rf "$TEMP_DIR"/*
    debug "Cleanup completed"
}
```bash #!/bin/bash

file: app.sh
Source configuration and utilities
source ./config.sh source ./utils.sh

Parse command line arguments
parse_args() { while [[ $# -gt 0 ]]; do case $1 in --debug) DEBUG_MODE=true shift ;; --verbose) VERBOSE_MODE=true shift ;; --config=) CONFIG_FILE="${1#=}" shift ;; --help) show_help exit 0 ;; *) error "Unknown option: $1" show_help exit 1 ;; esac done }

Show help message
show_help() { echo "Usage: $0 [options]" echo echo "Options:" echo " --debug Enable debug mode" echo " --verbose Enable verbose output" echo " --config=FILE Use specified config file" echo " --help Show this help message" }

Main application function
main() { info "Starting $APP_NAME v$APP_VERSION"

# Parse command line arguments
parse_args "$@"

# Create required directories
if ! create_dirs; then
    error "Failed to initialize application"
    exit 1
fi

# Set up cleanup on exit
trap cleanup EXIT

# Application logic here
info "Application initialized successfully"
debug "Debug mode is enabled"

# Simulate some work
info "Performing task 1"
sleep 1

info "Performing task 2"
sleep 1

info "Application completed successfully"
return 0
}

Run main function with all arguments
main "$@"


#### Mini-Project: Advanced System Information Dashboard

Create a comprehensive system information dashboard script that uses advanced shell scripting techniques:

\`\`\`bash
#!/bin/bash
# system_dashboard.sh - Advanced System Information Dashboard

# Colors and formatting
RESET="\033[0m"
BOLD="\033[1m"
RED="\033[31m"
GREEN="\033[32m"
YELLOW="\033[33m"
BLUE="\033[34m"
MAGENTA="\033[35m"
CYAN="\033[36m"
WHITE="\033[37m"
BG_RED="\033[41m"
BG_GREEN="\033[42m"
BG_YELLOW="\033[43m"
BG_BLUE="\033[44m"

# Configuration
TEMP_DIR="/tmp/system_dashboard"
HISTORY_FILE="$TEMP_DIR/history.dat"
REFRESH_INTERVAL=5  # seconds
MAX_HISTORY=60      # data points to keep

# Create temporary directory
mkdir -p "$TEMP_DIR"

# Trap for cleanup
trap 'rm -rf "$TEMP_DIR"; echo -e "\n${GREEN}Dashboard terminated.${RESET}"; exit 0' EXIT INT TERM

# Function to print section header
print_header() {
    local title="$1"
    local width=$(tput cols)
    local padding=$(( (width - ${#title} - 4) / 2 ))
    
    echo -e "\n${BOLD}${BLUE}"
    printf "%${width}s" | tr ' ' '='
    printf "\n%${padding}s %s %${padding}s\n" "=" "$title" "="
    printf "%${width}s" | tr ' ' '='
    echo -e "${RESET}"
}

# Function to print formatted key-value pair
print_info() {
    local key="$1"
    local value="$2"
    local color="${3:-$WHITE}"
    
    printf "${BOLD}%-25s${RESET} : ${color}%s${RESET}\n" "$key" "$value"
}

# Function to print progress bar
print_progress_bar() {
    local value=$1
    local max=$2
    local width=50
    local title=$3
    local percentage=$((value * 100 / max))
    local filled=$((value * width / max))
    local empty=$((width - filled))
    
    # Choose color based on percentage
    local color=$GREEN
    if [ $percentage -gt 80 ]; then
        color=$RED
    elif [ $percentage -gt 60 ]; then
        color=$YELLOW
    fi
    
    printf "%-20s [${color}" "$title"
    printf "%${filled}s" | tr ' ' '#'
    printf "${RESET}"
    printf "%${empty}s" | tr ' ' ' '
    printf "] %3d%%\n" $percentage
}

# Function to get system information
get_system_info() {
    print_header "SYSTEM INFORMATION"
    
    # Hostname and kernel
    print_info "Hostname" "$(hostname)" $CYAN
    print_info "Kernel" "$(uname -r)" $CYAN
    print_info "Operating System" "$(grep PRETTY_NAME /etc/os-release 2>/dev/null | cut -d= -f2 | tr -d '"')" $CYAN
    print_info "Architecture" "$(uname -m)" $CYAN
    
    # Uptime
    local uptime_seconds=$(cat /proc/uptime | awk '{print $1}' | cut -d. -f1)
    local uptime_days=$((uptime_seconds / 86400))
    local uptime_hours=$(((uptime_seconds % 86400) / 3600))
    local uptime_minutes=$(((uptime_seconds % 3600) / 60))
    print_info "Uptime" "${uptime_days}d ${uptime_hours}h ${uptime_minutes}m" $CYAN
    
    # Last boot
    print_info "Last Boot" "$(who -b | awk '{print $3, $4}')" $CYAN
    
    # Load average
    local load=$(cat /proc/loadavg)
    local load_1m=$(echo $load | awk '{print $1}')
    local load_5m=$(echo $load | awk '{print $2}')
    local load_15m=$(echo $load | awk '{print $3}')
    
    local cpu_cores=$(nproc)
    local load_color=$GREEN
    
    if (( $(echo "$load_1m > $cpu_cores" | bc -l) )); then
        load_color=$RED
    elif (( $(echo "$load_1m > $cpu_cores * 0.7" | bc -l) )); then
        load_color=$YELLOW
    fi
    
    print_info "Load Average" "${load_1m} (1m), ${load_5m} (5m), ${load_15m} (15m)" $load_color
    print_info "CPU Cores" "$cpu_cores" $CYAN
}

# Function to get CPU information
get_cpu_info() {
    print_header "CPU INFORMATION"
    
    # CPU model
    local cpu_model=$(grep "model name" /proc/cpuinfo | head -1 | cut -d: -f2 | sed 's/^[ \t]*//')
    print_info "CPU Model" "$cpu_model" $CYAN
    
    # CPU usage
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2 + $4}')
    print_info "CPU Usage" "${cpu_usage}%" $([ $(echo "$cpu_usage > 80" | bc -l) -eq 1 ] && echo $RED || [ $(echo "$cpu_usage > 50" | bc -l) -eq 1 ] && echo $YELLOW || echo $GREEN)
    
    # CPU frequency
    if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq ]; then
        local cpu_freq=$(cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq)
        cpu_freq=$(echo "scale=2; $cpu_freq / 1000000" | bc)
        print_info "CPU Frequency" "${cpu_freq} GHz" $CYAN
    fi
    
    # CPU temperature
    if [ -f /sys/class/thermal/thermal_zone0/temp ]; then
        local cpu_temp=$(cat /sys/class/thermal/thermal_zone0/temp)
        cpu_temp=$(echo "scale=1; $cpu_temp / 1000" | bc)
        local temp_color=$GREEN
        if [ $(echo "$cpu_temp > 80" | bc -l) -eq 1 ]; then
            temp_color=$RED
        elif [ $(echo "$cpu_temp > 60" | bc -l) -eq 1 ]; then
            temp_color=$YELLOW
        fi
        print_info "CPU Temperature" "${cpu_temp}°C" $temp_color
    fi
    
    # CPU governor
    if [ -f /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor ]; then
        local cpu_governor=$(cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor)
        print_info "CPU Governor" "$cpu_governor" $CYAN
    fi
    
    # Show CPU usage bar
    print_progress_bar ${cpu_usage%.*} 100 "CPU Usage"
    
    # Store CPU usage history
    echo "$(date +%s) $cpu_usage" >> "$TEMP_DIR/cpu_history.dat"
}

# Function to get memory information
get_memory_info() {
    print_header "MEMORY INFORMATION"
    
    # Get memory info
    local mem_total=$(grep MemTotal /proc/meminfo | awk '{print $2}')
    local mem_free=$(grep MemFree /proc/meminfo | awk '{print $2}')
    local mem_available=$(grep MemAvailable /proc/meminfo | awk '{print $2}')
    local mem_cached=$(grep "^Cached" /proc/meminfo | awk '{print $2}')
    local mem_buffers=$(grep "^Buffers" /proc/meminfo | awk '{print $2}')
    
    # Calculate used memory
    local mem_used=$((mem_total - mem_free - mem_cached - mem_buffers))
    local mem_used_percent=$((mem_used * 100 / mem_total))
    
    # Convert to human-readable format
    mem_total_hr=$(echo "scale=2; $mem_total / 1024 / 1024" | bc)
    mem_used_hr=$(echo "scale=2; $mem_used / 1024 / 1024" | bc)
    mem_free_hr=$(echo "scale=2; $mem_free / 1024 / 1024" | bc)
    mem_cached_hr=$(echo "scale=2; $mem_cached / 1024 / 1024" | bc)
    
    # Print memory information
    print_info "Total Memory" "${mem_total_hr} GB" $CYAN
    
    local mem_color=$GREEN
    if [ $mem_used_percent -gt 80 ]; then
        mem_color=$RED
    elif [ $mem_used_percent -gt 60 ]; then
        mem_color=$YELLOW
    fi
    
    print_info "Used Memory" "${mem_used_hr} GB (${mem_used_percent}%)" $mem_color
    print_info "Free Memory" "${mem_free_hr} GB" $CYAN
    print_info "Cached Memory" "${mem_cached_hr} GB" $CYAN
    
    # Get swap info
    local swap_total=$(grep SwapTotal /proc/meminfo | awk '{print $2}')
    local swap_free=$(grep SwapFree /proc/meminfo | awk '{print $2}')
    
    if [ $swap_total -gt 0 ]; then
        local swap_used=$((swap_total - swap_free))
        local swap_used_percent=$((swap_used * 100 / swap_total))
        
        # Convert to human-readable format
        swap_total_hr=$(echo "scale=2; $swap_total / 1024 / 1024" | bc)
        swap_used_hr=$(echo "scale=2; $swap_used / 1024 / 1024" | bc)
        
        local swap_color=$GREEN
        if [ $swap_used_percent -gt 50 ]; then
            swap_color=$RED
        elif [ $swap_used_percent -gt 25 ]; then
            swap_color=$YELLOW
        fi
        
        print_info "Total Swap" "${swap_total_hr} GB" $CYAN
        print_info "Used Swap" "${swap_used_hr} GB (${swap_used_percent}%)" $swap_color
        
        # Show swap usage bar
        print_progress_bar $swap_used_percent 100 "Swap Usage"
    else
        print_info "Swap" "Not configured" $YELLOW
    fi
    
    # Show memory usage bar
    print_progress_bar $mem_used_percent 100 "Memory Usage"
    
    # Store memory usage history
    echo "$(date +%s) $mem_used_percent" >> "$TEMP_DIR/mem_history.dat"
}

# Function to get disk information
get_disk_info() {
    print_header "DISK INFORMATION"
    
    # Get filesystem information
    echo -e "${BOLD}Filesystem Usage:${RESET}\n"
    
    # Print header
    printf "${BOLD}%-20s %-10s %-10s %-10s %-6s %s${RESET}\n" "Filesystem" "Size" "Used" "Avail" "Use%" "Mounted on"
    
    # Get disk usage
    df -h | grep -v "tmpfs\|udev" | grep -v "^Filesystem" | while read -r line; do
        local filesystem=$(echo "$line" | awk '{print $1}')
        local size=$(echo "$line" | awk '{print $2}')
        local used=$(echo "$line" | awk '{print $3}')
        local avail=$(echo "$line" | awk '{print $4}')
        local use_percent=$(echo "$line" | awk '{print $5}' | tr -d '%')
        local mount=$(echo "$line" | awk '{print $6}')
        
        local color=$GREEN
        if [ "$use_percent" -gt 90 ]; then
            color=$RED
        elif [ "$use_percent" -gt 70 ]; then
            color=$YELLOW
        fi
        
        printf "%-20s %-10s %-10s %-10s ${color}%-6s${RESET} %s\n" "$filesystem" "$size" "$used" "$avail" "${use_percent}%" "$mount"
    done
    
    echo -e "\n${BOLD}Disk I/O Statistics:${RESET}\n"
    
    # Get disk I/O statistics
    local disk_stats=$(cat /proc/diskstats | grep -E 'sd[a-z]|nvme[0-9]n[0-9]' | grep -v 'sd[a-z][0-9]')
    
    printf "${BOLD}%-10s %-12s %-12s %-12s %-12s${RESET}\n" "Device" "Reads" "Writes" "Read KB" "Write KB"
    
    echo "$disk_stats" | while read -r line; do
        local device=$(echo "$line" | awk '{print $3}')
        local reads=$(echo "$line" | awk '{print $4}')
        local writes=$(echo "$line" | awk '{print $8}')
        local read_sectors=$(echo "$line" | awk '{print $6}')
        local write_sectors=$(echo "$line" | awk '{print $10}')
        
        # Convert sectors to KB (sector size is typically 512 bytes)
        local read_kb=$((read_sectors / 2))
        local write_kb=$((write_sectors / 2))
        
        printf "%-10s %-12s %-12s %-12s %-12s\n" "/dev/$device" "$reads" "$writes" "$read_kb" "$write_kb"
    done
}

# Function to get network information
get_network_info() {
    print_header "NETWORK INFORMATION"
    
    # Get network interfaces
    echo -e "${BOLD}Network Interfaces:${RESET}\n"
    
    # Print header
    printf "${BOLD}%-10s %-15s %-15s %-10s %-10s${RESET}\n" "Interface" "IP Address" "MAC Address" "RX Bytes" "TX Bytes"
    
    # Get interface information
    ip -o addr show | grep -v "lo\|docker\|br-\|veth" | while read -r line; do
        local interface=$(echo "$line" | awk '{print $2}')
        local ip_address=$(echo "$line" | awk '{print $4}' | cut -d/ -f1)
        local mac_address=$(ip link show "$interface" | grep -o "link/ether [0-9a-f:]\+" | cut -d' ' -f2)
        
        # Get RX/TX bytes
        local rx_bytes=$(cat /sys/class/net/$interface/statistics/rx_bytes 2>/dev/null || echo "N/A")
        local tx_bytes=$(cat /sys/class/net/$interface/statistics/tx_bytes 2>/dev/null || echo "N/A")
        
        # Convert to human-readable format
        if [ "$rx_bytes" != "N/A" ]; then
            rx_bytes=$(echo "scale=2; $rx_bytes / 1024 / 1024" | bc)
            rx_bytes="${rx_bytes} MB"
        fi
        
        if [ "$tx_bytes" != "N/A" ]; then
            tx_bytes=$(echo "scale=2; $tx_bytes / 1024 / 1024" | bc)
            tx_bytes="${tx_bytes} MB"
        fi
        
        printf "%-10s %-15s %-15s %-10s %-10s\n" "$interface" "$ip_address" "$mac_address" "$rx_bytes" "$tx_bytes"
    done
    
    echo -e "\n${BOLD}Network Connections:${RESET}\n"
    
    # Get network connections
    local connections=$(netstat -tuln | grep -v "Active\|Proto")
    
    printf "${BOLD}%-10s %-10s %-20s %-20s %-10s${RESET}\n" "Protocol" "State" "Local Address" "Foreign Address" "PID/Program"
    
    echo "$connections" | head -10 | while read -r line; do
        local proto=$(echo "$line" | awk '{print $1}')
        local state=$(echo "$line" | awk '{print $6}')
        local local_addr=$(echo "$line" | awk '{print $4}')
        local foreign_addr=$(echo "$line" | awk '{print $5}')
        local pid_program=$(echo "$line" | awk '{print $7}')
        
        printf "%-10s %-10s %-20s %-20s %-10s\n" "$proto" "$state" "$local_addr" "$foreign_addr" "$pid_program"
    done
    
    # Get public IP address
    echo -e "\n${BOLD}Public IP Address:${RESET}"
    local public_ip=$(curl -s ifconfig.me 2>/dev/null || echo "N/A")
    print_info "Public IP" "$public_ip" $CYAN
}

# Function to get process information
get_process_info() {
    print_header "PROCESS INFORMATION"
    
    # Get top CPU processes
    echo -e "${BOLD}Top CPU Processes:${RESET}\n"
    
    printf "${BOLD}%-6s %-10s %-8s %-8s %-10s %s${RESET}\n" "PID" "USER" "CPU%" "MEM%" "TIME" "COMMAND"
    
    ps aux --sort=-%cpu | head -6 | tail -5 | while read -r line; do
        local pid=$(echo "$line" | awk '{print $2}')
        local user=$(echo "$line" | awk '{print $1}')
        local cpu=$(echo "$line" | awk '{print $3}')
        local mem=$(echo "$line" | awk '{print $4}')
        local time=$(echo "$line" | awk '{print $10}')
        local command=$(echo "$line" | awk '{print $11}')
        
        local cpu_color=$GREEN
        if [ $(echo "$cpu > 50" | bc -l) -eq 1 ]; then
            cpu_color=$RED
        elif [ $(echo "$cpu > 20" | bc -l) -eq 1 ]; then
            cpu_color=$YELLOW
        fi
        
        printf "%-6s %-10s ${cpu_color}%-8s${RESET} %-8s %-10s %s\n" "$pid" "$user" "$cpu" "$mem" "$time" "$command"
    done
    
    # Get top memory processes
    echo -e "\n${BOLD}Top Memory Processes:${RESET}\n"
    
    printf "${BOLD}%-6s %-10s %-8s %-8s %-10s %s${RESET}\n" "PID" "USER" "CPU%" "MEM%" "TIME" "COMMAND"
    
    ps aux --sort=-%mem | head -6 | tail -5 | while read -r line; do
        local pid=$(echo "$line" | awk '{print $2}')
        local user=$(echo "$line" | awk '{print $1}')
        local cpu=$(echo "$line" | awk '{print $3}')
        local mem=$(echo "$line" | awk '{print $4}')
        local time=$(echo "$line" | awk '{print $10}')
        local command=$(echo "$line" | awk '{print $11}')
        
        local mem_color=$GREEN
        if [ $(echo "$mem > 50" | bc -l) -eq 1 ]; then
            mem_color=$RED
        elif [ $(echo "$mem > 20" | bc -l) -eq 1 ]; then
            mem_color=$YELLOW
        fi
        
        printf "%-6s %-10s %-8s ${mem_color}%-8s${RESET} %-10s %s\n" "$pid" "$user" "$cpu" "$mem" "$time" "$command"
    done
    
    # Get process count
    local process_count=$(ps aux | wc -l)
    local user_process_count=$(ps -U $(whoami) | wc -l)
    
    echo -e "\n${BOLD}Process Summary:${RESET}"
    print_info "Total Processes" "$process_count" $CYAN
    print_info "User Processes" "$user_process_count" $CYAN
    print_info "Running Processes" "$(ps r | wc -l)" $CYAN
    print_info "Zombie Processes" "$(ps aux | grep -c 'Z')" $CYAN
}

# Function to get security information
get_security_info() {
    print_header "SECURITY INFORMATION"
    
    # Get failed login attempts
    local failed_logins=$(grep "Failed password" /var/log/auth.log 2>/dev/null | wc -l)
    local failed_logins_today=$(grep "Failed password" /var/log/auth.log 2>/dev/null | grep "$(date +%b' '%d)" | wc -l)
    
    local login_color=$GREEN
    if [ $failed_logins_today -gt 10 ]; then
        login_color=$RED
    elif [ $failed_logins_today -gt 5 ]; then
        login_color=$YELLOW
    fi
    
    print_info "Failed Login Attempts" "$failed_logins (total), $failed_logins_today (today)" $login_color
    
    # Get last logins
    echo -e "\n${BOLD}Last Logins:${RESET}\n"
    last -n 5 | head -5
    
    # Get listening ports
    echo -e "\n${BOLD}Listening Ports:${RESET}\n"
    printf "${BOLD}%-10s %-20s %-10s %s${RESET}\n" "Protocol" "Address" "Port" "Process"
    
    netstat -tulpn 2>/dev/null | grep LISTEN | grep -v "127.0.0.1" | head -5 | while read -r line; do
        local proto=$(echo "$line" | awk '{print $1}')
        local addr=$(echo "$line" | awk '{print $4}' | cut -d: -f1)
        local port=$(echo "$line" | awk '{print $4}' | cut -d: -f2)
        local process=$(echo "$line" | awk '{print $7}')
        
        printf "%-10s %-20s %-10s %s\n" "$proto" "$addr" "$port" "$process"
    done
    
    # Get firewall status
    echo -e "\n${BOLD}Firewall Status:${RESET}"
    
    if command -v ufw &>/dev/null; then
        local ufw_status=$(ufw status | grep Status | cut -d: -f2 | tr -d ' ')
        local ufw_color=$GREEN
        
        if [ "$ufw_status" = "inactive" ]; then
            ufw_color=$RED
        fi
        
        print_info "UFW Firewall" "$ufw_status" $ufw_color
    elif command -v firewalld &>/dev/null; then
        local firewalld_status=$(firewall-cmd --state 2>/dev/null || echo "inactive")
        local firewalld_color=$GREEN
        
        if [ "$firewalld_status" = "inactive" ]; then
            firewalld_color=$RED
        fi
        
        print_info "FirewallD" "$firewalld_status" $firewalld_color
    else
        print_info "Firewall" "Not detected" $RED
    fi
    
    # Get SSH configuration
    echo -e "\n${BOLD}SSH Configuration:${RESET}"
    
    if [ -f /etc/ssh/sshd_config ]; then
        local root_login=$(grep "^PermitRootLogin" /etc/ssh/sshd_config | awk '{print $2}')
        local password_auth=$(grep "^PasswordAuthentication" /etc/ssh/sshd_config | awk '{print $2}')
        
        local root_login_color=$GREEN
        if [ "$root_login" = "yes" ]; then
            root_login_color=$RED
        fi
        
        local password_auth_color=$GREEN
        if [ "$password_auth" = "yes" ]; then
            password_auth_color=$YELLOW
        fi
        
        print_info "Root Login" "${root_login:-"not set"}" $root_login_color
        print_info "Password Authentication" "${password_auth:-"not set"}" $password_auth_color
    else
        print_info "SSH Configuration" "Not found" $YELLOW
    fi
}

# Function to display dashboard
display_dashboard() {
    clear
    
    echo -e "${BOLD}${MAGENTA}"
    echo "  _____            _                     _____            _     _                         _ "
    echo " / ____|          | |                   |  __ \          | |   | |                       | |"
    echo "| (___  _   _ ___| |_ ___ _ __ ___     | |  | | __ _ ___| |__ | |__   ___   __ _ _ __ __| |"
    echo " \___ \| | | / __| __/ _ \ '_ \` _ \    | |  | |/ _\` / __| '_ \| '_ \ / _ \ / _\` | '__/ _\` |"
    echo " ____) | |_| \__ \ ||  __/ | | | | |   | |__| | (_| \__ \ | | | |_) | (_) | (_| | | | (_| |"
    echo "|_____/ \__, |___/\__\___|_| |_| |_|   |_____/ \__,_|___/_| |_|_.__/ \___/ \__,_|_|  \__,_|"
    echo "         __/ |"
    echo "        |___/"
    echo -e "${RESET}"
    
    echo -e "${BOLD}${CYAN}Date:${RESET} $(date)"
    echo -e "${BOLD}${CYAN}Refresh Interval:${RESET} ${REFRESH_INTERVAL} seconds"
    echo -e "${BOLD}${CYAN}Press Ctrl+C to exit${RESET}"
    
    get_system_info
    get_cpu_info
    get_memory_info
    get_disk_info
    get_network_info
    get_process_info
    get_security_info
    
    echo -e "\n${BOLD}${BLUE}Dashboard will refresh in ${REFRESH_INTERVAL} seconds...${RESET}"
}

# Main loop
while true; do
    display_dashboard
    sleep $REFRESH_INTERVAL
done
Save this script as system_dashboard.sh, make it executable with chmod +x system_dashboard.sh, and run it with sudo ./system_dashboard.sh.

Day 8 Learning Outcomes
By the end of Day 8, you should be able to:

Use advanced Bash features like arrays, string manipulation, and parameter expansion
Implement robust error handling in shell scripts
Work with advanced input/output techniques
Create modular and maintainable shell scripts
Use advanced control structures and functions
Build comprehensive system monitoring tools using shell scripting
Additional Resources for Day 8
Advanced Bash-Scripting Guide
Bash Reference Manual
Shell Style Guide
Bash Pitfalls
Defensive Bash Programming
Day 9: System Performance Tuning
System performance tuning is a critical skill for Linux engineers. In this section, we'll explore techniques for identifying performance bottlenecks and optimizing system performance.

Performance Monitoring Tools
Basic Monitoring Tools:

```bash

CPU and memory usage
top htop atop

Process monitoring
ps aux pstree pgrep pkill

I/O monitoring
iostat iotop

Network monitoring
netstat ss iftop nethogs

Disk usage
df -h du -sh /var/* ncdu

System load
uptime w


**Advanced Monitoring Tools:**

\`\`\`bash
# System activity reporter
sar -u  # CPU usage
sar -r  # Memory usage
sar -b  # I/O usage
sar -n DEV  # Network usage

# Process monitoring
pidstat -u  # CPU usage
pidstat -r  # Memory usage
pidstat -d  # I/O usage

# Disk I/O statistics
iostat -xz 1

# Network statistics
nicstat
ip -s link

# Memory statistics
vmstat 1
free -m
slabtop

# System calls and signals
strace
ltrace

# Kernel events
perf
ftrace
Graphical Monitoring Tools:

```bash

Install graphical monitoring tools
sudo apt-get install -y glances nmon dstat sysstat

Glances - comprehensive monitoring
glances

Nmon - performance monitor
nmon

Dstat - versatile resource statistics
dstat -cdngy


#### CPU Performance Tuning

**CPU Governors:**

\`\`\`bash
# View available CPU governors
cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors

# View current CPU governor
cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor

# Set CPU governor
echo "performance" | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# Set CPU governor permanently
sudo apt-get install -y cpufrequtils
sudo cpufreq-set -g performance
CPU Affinity:

```bash

View process CPU affinity
taskset -p PID

Set process CPU affinity
taskset -c 0,1 command # Run command on CPU cores 0 and 1 taskset -pc 0,1 PID # Set affinity for existing process

Set CPU affinity for a service
systemctl set-property service_name.service CPUAffinity=0,1


**Process Priorities:**

\`\`\`bash
# View process nice value
ps -o pid,comm,nice -p PID

# Start a process with a specific nice value
nice -n 10 command  # Lower priority (higher nice value)
nice -n -10 command  # Higher priority (lower nice value)

# Change nice value of a running process
renice -n 10 -p PID

# Set I/O priority
ionice -c 2 -n 7 command  # Best-effort class, lowest priority
ionice -c 1 -n 0 command  # Real-time class, highest priority
CPU Isolation:

```bash

Isolate CPU cores from the kernel scheduler
Add to kernel command line in /etc/default/grub
GRUB_CMDLINE_LINUX="isolcpus=2,3"

Update grub and reboot
sudo update-grub sudo reboot


#### Memory Performance Tuning

**Memory Management:**

\`\`\`bash
# View current memory settings
sysctl -a | grep vm

# Adjust swappiness (0-100, lower values reduce swap usage)
sudo sysctl -w vm.swappiness=10
echo "vm.swappiness=10" | sudo tee -a /etc/sysctl.conf

# Adjust cache pressure (0-100, lower values keep more inode and dentry cache)
sudo sysctl -w vm.vfs_cache_pressure=50
echo "vm.vfs_cache_pressure=50" | sudo tee -a /etc/sysctl.conf

# Adjust dirty ratio (percentage of memory that can be filled with dirty pages)
sudo sysctl -w vm.dirty_ratio=20
sudo sysctl -w vm.dirty_background_ratio=10
echo "vm.dirty_ratio=20" | sudo tee -a /etc/sysctl.conf
echo "vm.dirty_background_ratio=10" | sudo tee -a /etc/sysctl.conf
Transparent Huge Pages:

```bash

View current THP settings
cat /sys/kernel/mm/transparent_hugepage/enabled

Disable THP (can improve performance for some applications)
echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled echo never | sudo tee /sys/kernel/mm/transparent_hugepage/defrag

Add to /etc/rc.local for persistence
echo "echo never > /sys/kernel/mm/transparent_hugepage/enabled" | sudo tee -a /etc/rc.local echo "echo never > /sys/kernel/mm/transparent_hugepage/defrag" | sudo tee -a /etc/rc.local


**Memory Limits:**

\`\`\`bash
# Set memory limits for a service
systemctl set-property service_name.service MemoryLimit=2G

# Set memory limits using cgroups
cgcreate -g memory:mygroup
echo 2G > /sys/fs/cgroup/memory/mygroup/memory.limit_in_bytes
cgexec -g memory:mygroup command
Disk I/O Performance Tuning
Disk Schedulers:

```bash

View available schedulers
cat /sys/block/sda/queue/scheduler

Set scheduler
echo "deadline" | sudo tee /sys/block/sda/queue/scheduler

Set scheduler permanently in /etc/default/grub
GRUB_CMDLINE_LINUX="elevator=deadline" sudo update-grub


**I/O Queue Settings:**

\`\`\`bash
# View current queue settings
cat /sys/block/sda/queue/read_ahead_kb
cat /sys/block/sda/queue/nr_requests

# Adjust read-ahead buffer
echo 1024 | sudo tee /sys/block/sda/queue/read_ahead_kb

# Adjust queue depth
echo 256 | sudo tee /sys/block/sda/queue/nr_requests
File System Tuning:

```bash

Mount options for ext4
sudo mount -o remount,noatime,nodiratime,data=writeback /dev/sda1 /mount/point

Add to /etc/fstab for persistence
/dev/sda1 /mount/point ext4 defaults,noatime,nodiratime,data=writeback 0 0

Tune ext4 filesystem
sudo tune2fs -o journal_data_writeback /dev/sda1


**Disk Caching:**

\`\`\`bash
# Install bcache for SSD caching
sudo apt-get install -y bcache-tools

# Create a cache device
sudo make-bcache -C /dev/sdc

# Create a backing device
sudo make-bcache -B /dev/sdb

# Attach backing device to cache device
echo /dev/sdc > /sys/block/bcache0/bcache/attach
Network Performance Tuning
Network Stack Settings:

```bash

View current network settings
sysctl -a | grep net

Increase TCP buffer sizes
sudo sysctl -w net.core.rmem_max=16777216 sudo sysctl -w net.core.wmem_max=16777216 sudo sysctl -w net.ipv4.tcp_rmem="4096 87380 16777216" sudo sysctl -w net.ipv4.tcp_wmem="4096 65536 16777216"

Enable TCP window scaling
sudo sysctl -w net.ipv4.tcp_window_scaling=1

Increase connection tracking
sudo sysctl -w net.netfilter.nf_conntrack_max=1000000 sudo sysctl -w net.nf_conntrack_max=1000000

Add to /etc/sysctl.conf for persistence
echo "net.core.rmem_max=16777216" | sudo tee -a /etc/sysctl.conf echo "net.core.wmem_max=16777216" | sudo tee -a /etc/sysctl.conf echo "net.ipv4.tcp_rmem=4096 87380 16777216" | sudo tee -a /etc/sysctl.conf echo "net.ipv4.tcp_wmem=4096 65536 16777216" | sudo tee -a /etc/sysctl.conf echo "net.ipv4.tcp_window_scaling=1" | sudo tee -a /etc/sysctl.conf echo "net.netfilter.nf_conntrack_max=1000000" | sudo tee -a /etc/sysctl.conf echo "net.nf_conntrack_max=1000000" | sudo tee -a /etc/sysctl.conf


**Network Interface Tuning:**

\`\`\`bash
# View network interface settings
ethtool eth0

# Adjust ring buffer sizes
sudo ethtool -g eth0  # View current ring buffer sizes
sudo ethtool -G eth0 rx 4096 tx 4096  # Set ring buffer sizes

# Enable/disable offloading features
sudo ethtool -K eth0 tso on gso on gro on  # Enable offloading
sudo ethtool -K eth0 tso off gso off gro off  # Disable offloading

# Set interface to use multiple queues
sudo ethtool -L eth0 combined 4  # Use 4 combined queues
Network Bonding:

```bash

Install bonding driver
sudo modprobe bonding

Create a bond interface in /etc/network/interfaces
auto bond0 iface bond0 inet static address 192.168.1.10 netmask 255.255.255.0 gateway 192.168.1.1 bond-slaves eth0 eth1 bond-mode 802.3ad bond-miimon 100 bond-downdelay 200 bond-updelay 200


#### Application Performance Tuning

**Web Server Tuning (Nginx):**

\`\`\`bash
# Nginx worker processes and connections
worker_processes auto;
worker_rlimit_nofile 65535;
events {
    worker_connections 65535;
    multi_accept on;
    use epoll;
}

# Nginx buffer sizes
http {
    client_body_buffer_size 10K;
    client_header_buffer_size 1k;
    client_max_body_size 8m;
    large_client_header_buffers 2 1k;
}

# Nginx timeouts
http {
    client_body_timeout 12;
    client_header_timeout 12;
    keepalive_timeout 15;
    send_timeout 10;
}

# Nginx gzip compression
http {
    gzip on;
    gzip_comp_level 5;
    gzip_min_length 256;
    gzip_proxied any;
    gzip_vary on;
    gzip_types
        application/atom+xml
        application/javascript
        application/json
        application/ld+json
        application/manifest+json
        application/rss+xml
        application/vnd.geo+json
        application/vnd.ms-fontobject
        application/x-font-ttf
        application/x-web-app-manifest+json
        application/xhtml+xml
        application/xml
        font/opentype
        image/bmp
        image/svg+xml
        image/x-icon
        text/cache-manifest
        text/css
        text/plain
        text/vcard
        text/vnd.rim.location.xloc
        text/vtt
        text/x-component
        text/x-cross-domain-policy;
}
Database Tuning (MySQL/MariaDB):

```bash

Memory settings
innodb_buffer_pool_size = 4G # 70-80% of available RAM innodb_buffer_pool_instances = 4 # One per CPU core innodb_log_buffer_size = 16M key_buffer_size = 256M # For MyISAM tables

I/O settings
innodb_flush_log_at_trx_commit = 2 # 1 for ACID compliance, 2 for better performance innodb_flush_method = O_DIRECT innodb_file_per_table = 1 innodb_io_capacity = 1000 # Adjust based on IOPS capability

Connection settings
max_connections = 500 thread_cache_size = 128 table_open_cache = 4000

Query cache (disable for high-write workloads)
query_cache_type = 0 query_cache_size = 0


**Java Application Tuning:**

\`\`\`bash
# JVM memory settings
java -Xms4g -Xmx4g -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=512m -jar app.jar

# Garbage collection settings
java -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -jar app.jar

# Thread stack size
java -Xss256k -jar app.jar

# JVM tuning for server applications
java -server -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:+UseStringDeduplication -XX:+UseCompressedOops -XX:+OptimizeStringConcat -jar app.jar
System-Wide Performance Tuning
Kernel Parameters:

```bash

File handle limits
sudo sysctl -w fs.file-max=2097152 echo "fs.file-max=2097152" | sudo tee -a /etc/sysctl.conf

Process limits
sudo sysctl -w kernel.pid_max=4194303 echo "kernel.pid_max=4194303" | sudo tee -a /etc/sysctl.conf

Shared memory limits
sudo sysctl -w kernel.shmmax=68719476736 sudo sysctl -w kernel.shmall=4294967296 echo "kernel.shmmax=68719476736" | sudo tee -a /etc/sysctl.conf echo "kernel.shmall=4294967296" | sudo tee -a /etc/sysctl.conf


**User Limits:**

\`\`\`bash
# Set user limits in /etc/security/limits.conf
* soft nofile 65536
* hard nofile 65536
* soft nproc 65536
* hard nproc 65536
* soft memlock unlimited
* hard memlock unlimited
System Services:

```bash

Disable unnecessary services
sudo systemctl disable bluetooth.service sudo systemctl disable cups.service sudo systemctl disable avahi-daemon.service

Optimize systemd settings
sudo systemctl set-property service_name.service Restart=on-failure sudo systemctl set-property service_name.service RestartSec=5


#### Mini-Project: Performance Monitoring and Tuning Script

Create a script to monitor system performance and apply basic tuning recommendations:

\`\`\`bash
#!/bin/bash
# performance_tuner.sh - Monitor system performance and apply basic tuning

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
LOG_FILE="/var/log/performance_tuner.log"
EMAIL_RECIPIENT="admin@example.com"
THRESHOLD_CPU=80
THRESHOLD_MEM=80
THRESHOLD_DISK=90

# Function to log messages
log_message() {
    local message="$1"
    local timestamp=$(date "+%Y-%m-%d %H:%M:%S")
    echo -e "$timestamp - $message" | tee -a "$LOG_FILE"
}

# Function to send email alert
send_alert() {
    local subject="$1"
    local message="$2"
    
    if command -v mail > /dev/null; then
        echo "$message" | mail -s "$subject" "$EMAIL_RECIPIENT"
        log_message "Alert email sent to $EMAIL_RECIPIENT"
    else
        log_message "mail command not found, could not send alert"
    fi
}

# Function to check CPU usage
check_cpu() {
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2 + $4}')
    log_message "CPU Usage: $cpu_usage%"
    
    if [ $(echo "$cpu_usage > $THRESHOLD_CPU" | bc -l) -eq 1 ]; then
        log_message "${YELLOW}WARNING: CPU usage is high ($cpu_usage%)${NC}"
        send_alert "[$(hostname)] High CPU Usage" "CPU usage is at $cpu_usage% on $(hostname)"
    fi
}

# Function to check memory usage
check_memory() {
    local mem_used_percent=$(free | grep Mem | awk '{print int($3/$2 * 100)}')
    log_message "Memory Usage: $mem_used_percent%"
    
    if [ $(echo "$mem_used_percent > $THRESHOLD_MEM" | bc -l) -eq 1 ]; then
        log_message "${YELLOW}WARNING: Memory usage is high ($mem_used_percent%)${NC}"
        send_alert "[$(hostname)] High Memory Usage" "Memory usage is at $mem_used_percent% on $(hostname)"
    fi
}

# Function to check disk usage
check_disk() {
    local disk_usage=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    log_message "Disk Usage: $disk_usage%"
    
    if [ "$disk_usage" -gt "$THRESHOLD_DISK" ]; then
        log_message "${YELLOW}WARNING: Disk usage is high ($disk_usage%)${NC}"
        send_alert "[$(hostname)] High Disk Usage" "Disk usage is at $disk_usage% on $(hostname)"
    fi
}

# Function to apply basic tuning recommendations
apply_tuning() {
    log_message "${BLUE}Applying basic tuning recommendations...${NC}"
    
    # Adjust swappiness
    local swappiness=$(sysctl vm.swappiness | awk '{print $3}')
    if [ "$swappiness" -gt 60 ]; then
        log_message "Reducing swappiness to 60"
        sudo sysctl -w vm.swappiness=60
        echo "vm.swappiness=60" | sudo tee -a /etc/sysctl.conf
    fi
    
    # Adjust cache pressure
    local cache_pressure=$(sysctl vm.vfs_cache_pressure | awk '{print $3}')
    if [ "$cache_pressure" -gt 100 ]; then
        log_message "Reducing cache pressure to 100"
        sudo sysctl -w vm.vfs_cache_pressure=100
        echo "vm.vfs_cache_pressure=100" | sudo tee -a /etc/sysctl.conf
    fi
    
    log_message "${GREEN}Tuning recommendations applied${NC}"
}

# Main function
main() {
    # Check if running as root
    if [ "$(id -u)" -ne 0 ]; then
        echo -e "${RED}This script must be run as root${NC}"
        exit 1
    fi
    
    echo -e "${BLUE}========================================${NC}"
    echo -e "${YELLOW}      PERFORMANCE TUNER SCRIPT        ${NC}"
    echo -e "${BLUE}========================================${NC}"
    
    # Check system performance
    check_cpu
    check_memory
    check_disk
    
    # Apply tuning recommendations
    apply_tuning
    
    echo -e "${GREEN}Performance monitoring and tuning completed${NC}"
    echo -e "${YELLOW}Log file: $LOG_FILE${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# Run main function
main
Save this script as performance_tuner.sh, make it executable with chmod +x performance_tuner.sh, and run it with sudo ./performance_tuner.sh.

Day 9 Learning Outcomes
By the end of Day 9, you should be able to:

Use performance monitoring tools to identify bottlenecks
Tune CPU performance using CPU governors and affinity
Optimize memory management and usage
Improve disk I/O performance with disk schedulers and file system tuning
Tune network performance by adjusting network stack settings
Apply application-specific performance tuning techniques
Additional Resources for Day 9
Linux Performance and Tuning Guidelines
Brendan Gregg's Performance Checklist
Linux Performance Analysis and Tools
MySQL Performance Tuning
Nginx Performance Tuning
Day 10: Advanced Security
Security is a paramount concern for Linux engineers. In this section, we'll explore advanced security techniques to protect your systems from threats.

Intrusion Detection Systems (IDS)
Snort:

```bash

Install Snort
sudo apt-get install -y snort

Configure Snort
sudo nano /etc/snort/snort.conf

Start Snort
sudo snort -dev -i eth0 -c /etc/snort/snort.conf

Test Snort
ping -c 3 target_ip


**Suricata:**

\`\`\`bash
# Install Suricata
sudo apt-get install -y suricata

# Configure Suricata
sudo nano /etc/suricata/suricata.yaml

# Start Suricata
sudo suricata -c /etc/suricata/suricata.yaml -i eth0
OSSEC:

```bash

Install OSSEC server
sudo apt-get install -y ossec-hids-server

Install OSSEC agent
sudo apt-get install -y ossec-hids-agent

Configure OSSEC
sudo /var/ossec/bin/manage_agents

Start OSSEC
sudo /var/ossec/bin/ossec-control start


#### Security Information and Event Management (SIEM)

**ELK Stack (Elasticsearch, Logstash, Kibana):**

\`\`\`bash
# Install Elasticsearch
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list
sudo apt update
sudo apt install -y elasticsearch

# Install Logstash
sudo apt install -y logstash

# Install Kibana
sudo apt install -y kibana

# Configure Elasticsearch
sudo nano /etc/elasticsearch/elasticsearch.yml

# Configure Logstash
sudo nano /etc/logstash/conf.d/logstash.conf

# Configure Kibana
sudo nano /etc/kibana/kibana.yml

# Start ELK stack
sudo systemctl start elasticsearch
sudo systemctl start logstash
sudo systemctl start kibana
Graylog:

```bash

Install MongoDB
sudo apt-get install -y mongodb

Install Elasticsearch
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list sudo apt update sudo apt install -y elasticsearch

Install Graylog
wget https://packages.graylog2.org/repo/packages/graylog-4.0-repository_latest.deb sudo dpkg -i graylog-4.0-repository_latest.deb sudo apt update sudo apt install -y graylog-server

Configure Graylog
sudo nano /etc/graylog/server/server.conf

Start Graylog
sudo systemctl start graylog-server


#### Hardening SSH

**Disable Password Authentication:**

\`\`\`bash
# Edit /etc/ssh/sshd_config
PasswordAuthentication no
ChallengeResponseAuthentication no

# Restart SSH service
sudo systemctl restart sshd
Use Key-Based Authentication:

```bash

Generate SSH key pair
ssh-keygen -t ed25519 -C "your.email@example.com"

Copy public key to server
ssh-copy-id user@server_ip

Test SSH connection
ssh user@server_ip


**Disable Root Login:**

\`\`\`bash
# Edit /etc/ssh/sshd_config
PermitRootLogin no

# Restart SSH service
sudo systemctl restart sshd
Change Default SSH Port:

```bash

Edit /etc/ssh/sshd_config
Port 2222

Restart SSH service
sudo systemctl restart sshd

Allow new port through firewall
sudo ufw allow 2222


**Use Fail2ban:**

\`\`\`bash
# Install Fail2ban
sudo apt-get install -y fail2ban

# Configure Fail2ban for SSH
sudo nano /etc/fail2ban/jail.local

# Restart Fail2ban
sudo systemctl restart fail2ban
Firewall Configuration
UFW (Uncomplicated Firewall):

```bash

Enable UFW
sudo ufw enable

Allow SSH
sudo ufw allow ssh

Allow HTTP
sudo ufw allow http

Allow HTTPS
sudo ufw allow https

Deny all incoming traffic
sudo ufw default deny incoming

Allow all outgoing traffic
sudo ufw default allow outgoing

View UFW status
sudo ufw status


**Firewalld:**

\`\`\`bash
# Start and enable Firewalld
sudo systemctl start firewalld
sudo systemctl enable firewalld

# Allow SSH
sudo firewall-cmd --permanent --add-service=ssh

# Allow HTTP
sudo firewall-cmd --permanent --add-service=http

# Allow HTTPS
sudo firewall-cmd --permanent --add-service=https

# Reload Firewalld
sudo firewall-cmd --reload

# View Firewalld status
sudo firewall-cmd --list-all
